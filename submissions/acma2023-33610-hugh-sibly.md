# Comment on the Communications Legislation Amendment (Combatting Misinformation and Disinformation) Bill 2023

Dr Hugh Sibly

I appreciate the opportunity to offer a comment on the Communications Legislation Amendment
(Combatting Misinformation and Disinformation) Bill 2023. Thank you in advance for consideration of
my views.

I detail my thoughts on the proposed legislation are given below. However, to summarise, I think

1. the proposed legislation is ethically wrong,

2. the legislation will result in a multitude of unintended consequences, and therefore not achieve its
objective but will, in all likelihood, be counterproductive, and counter to the national interest

Nonetheless, there certainly instances for which government agencies legitimately wish to
communicate online various pieces of information. I also suggest an alternative policy approach
which does not suffer, to the same extent, from the above limitations as the approach taken by the
current legislation.

1. Ethical Issues

I, like everyone else, have a perspective on the ethical implications of all legislation, including the
proposed legislation. In the interests of transparency, I will begin by stating them now. I believe it is a
**fundamental right of all people to publicly express their views and opinion on all matters (that do**
not immediately and directly physically harm others), no matter how misconceived those views are.
Allowing views of some people to be suppressed necessarily implies that those doing the suppressing
have greater rights to expression to those whose views are being suppressed. This is unavoidably
unethical, no matter how justified the suppressors feel they are.

It is true that the extent to which a particular person’s views can be communicated depends on
technology, and social media has certainly increased the reach of individual expression. Nonetheless,
social media is now a very common method by which people and communities communicate. It is
thus unethical to limit individual expression on social media as, ethically, all individual should have
equal access to expression that is commonly available to others in the community. This implies that
social media platforms should be neutral in terms of political and social (but not necessarily their
commercial) issues.

I appreciate that the proposed legislation does not allow ACMA to directly remove specific content
(i.e. individual expression) from social media. But in practice this point is moot, as penalties will be
applied to social media companies that do not remove “offending” content. Thus, in effect, the
legislation will cause a suppression of legitimate views, and thus be unethical.


-----

I also wanted to note in passing that the High Court of Australia found that there is, constitutionally,
**an implied freedom of political communication in Australia. The legislation has been drafted to**
avoid conflicts with constitutional considerations (paragraph 60 of the bill). I am not a lawyer, so
won’t even attempt to offer a legal comment on these legal questions. Though it is certainly the case
that this freedom is not absolute. It can be traded off against other rights embedded in the
constitution, for example the constitutional rights of government to legislate on health issues. Thus
there is always a legal question of what are the limits an individual’s constitutional freedom of
political communication. Does this freedom protect those who argue against compulsory covid
vaccination, or indeed any vaccination? These are political issues where health related information
and disinformation play a role. It seems the line of what speech is constitutionally allowable is too
blurry to even hope to draw it (at least for non-lawyers). Such ambiguity is likely to make the
legislation’s exemption for political communication ineffective, and much communication which
should be protected would be censored: especially if it is necessary to go to the courts to argue
against specific instances of censorship.

It thus seems to me that, ethically, the legislation should simply be consistent with the spirit of the
**constitutional freedom of communication not just a technical legal interpretation. And ethically**
there should be no attempt to censor.

2. Practical Issues.

While the ethical issues are straightforward to identify and state, it is worthwhile to consider
whether the proposed legislation is beneficial to the community from a utilitarian (cost/benefit)
perspective. Indeed the underlying justification for the proposal is a utilitarian one: it is asserted that
the benefit of reducing harms outweighs any potential costs. In this section I wish to challenge this
assertion.

**I am sceptical that the legislation will have a substantial effect on reducing the spread of**
**misinformation, and thus the claimed benefits from it are overstated. Most obviously, people can**
readily use a vpn to access social media internationally. Indeed it is easy to imagine that users will
simply avoid social media companies that have an Australian presence, opting to use a vpn to access
companies that will not delete their posts (on the basis of grounds that are not fully justified or that
they do not understand). Such international companies are likely to be the ones that host users with
the most controversial/unappealing views. Indeed, it is even conceivable that utilising international
social media sites becomes a social movement in Australia, especially if users feel their activity is
being censored through the actions of their locally available social media companies.

**An implicit assumption underlying the purported harms from disinformation discussed in the ACMA**
report to government is that people are gullible, and simply accept whatever social media post they
read. Of course (as in fact indicated in some of ACMAs research) people are usually very sceptical of
information derived from social media, and rarely genuinely fall for disinformation.

Indeed it seems the proposed legislation, and its background material, mischaracterises social media
as a type of static formal publication, like book or newspaper. In fact, most social media is much


-----

**more like a conversation in which people are sharing and testing out their ideas and beliefs. It**
allows them to discuss topics with those outside their immediate social circle who are interested in
similar things. In this way many people use social media as an exploration of ideas, not some settled
statement of carefully conducted research. Indeed many will just use ‘outrageous’ posts as a form of
entertainment that is available on social media platforms, even if that content may not have been
produced (or could be argued not to have been produced) as a form of entertainment.

It also seems likely that the impact of social-media specific viral disinformation is often overstated.
Disinformation existed before the advent of social media, and there is no robust scientific evidence I
know of (and none has been presented) that indicates harms of disinformation have increase
because of the presence of social media. Indeed there is no quantification of the supposed costs of
these harms at all. On a different, but closely related topic, it is now conventional wisdom that social
media creates ‘echo chambers’ or ‘rabbit holes’ that ensnare the unwary. However recently Nyhan,
B., Settle, J., Thorson, E. et al. (2023) present evidence that this conventional wisdom is not
supported by data: people are not is readily malleable as many “experts” and commentators believe.

The bill obliges social media platforms to censor posts that have the potential to cause serious harm.
While this sounds like a worthwhile objective, the definition of harm in the bill is excessively wide
and thus almost guaranteed to have unintended effects. Outside the context of the bill, what is
considered harm is dependent on who defines it. And this leaves a lot to the judgement of whoever
is examining the content, in particular their political or ideological beliefs.

For example, the bill includes, in its definition of harm, the following “economic or financial harm to
Australians, the Australian economy or a sector of the Australian economy”. As an economist
including this in the definition of harm deeply concerns me. It could have the effect of disrupting and
limiting genuine, well-informed discussion of economic issues. For example, consider a proposal to
raise the wage level of workers. Some may argue that not raising wages imposes serious harm on
workers who do not receive a wage rise, and thereby struggle financially. This is true, so those
opposing wage rises are engaged in disinformation, because doing so imposes serious harm. But
others may argue that allowing a wage rise reduces employment, and therefore causes serious harm
on those who would have otherwise been employed. This is also true, so advocating a wage rise
imposes serious harm. Thus it is straightforward in this example (in which the facts are not even in
dispute) to paint advocates of either position as peddlers of misinformation. When the facts of the
issues are not readily available or in dispute this problem is exacerbated. Obviously there are a
innumerable such issues.

**The bill requires the digital platforms themselves to police “misinformation”. However digital**
platforms themselves have been accused of being partisan and/or exhibiting ideological bias. Even if
this is not true, it is dangerous to have the perception that the platforms are supporting one side of a
political or ideological argument in Australia, and that this support is encouraged or enabled by this
legislation. This problem is further exacerbated by the reality that most platforms are based
overseas. The platform companies’ world view, and that of their employees who would be charged
with identifying misinformation, would unavoidably differ from that of typical Australians. In
particular it is unlikely they would be sensitive to nuances of Australian discussions. This true even if
the social media companies employed local censors, as their choice of who they employ as a censor
will reflect their own cultural values.


-----

This aspect of the bill’s potential impact is particularly perplexing. There are strict controls on
**foreign media ownership in Australia. Yet this bill delegates identification of misinformation – in**
effect creating a type of editorial control – to entirely foreign own enterprises. I would have thought
that, at the least, if Australians were to be censored in their expression, it should be done explicitly
and transparently, by an Australian government agency. This approach would have, at least, all the
domestic democratic safeguards one would expect around censorship.

This highlights a key limitation of current online content moderation. It is either haphazard when
**done by AI (which is not good at understanding nuance in conversation) or expensive when done**
**by humans. As a result of this limitation, and the bias of fact-checkers (as all humans and their**
programmed AI have biases) it not uncommon to see situations where ‘fact checkers’ is that they
themselves often need fact checkers. At the very least it is not uncommon to find cases in which
posts have been labelled false, where they might better be described as debatable. The debate
around the origins of Covid-19 is a good example of this.

**The legislation exempts various institutions from its scope. Presumably it is believed these**
institutions are somehow better informed or more trustworthy than those not covered by the
exemptions. This need not, and is unlikely to be, true. For example, university academics might be
expected to be experts in their narrow field, but university administrators are not employed as
experts in any field (except possibly university administration). University administrators, who
typically speak publicly for their institution, are exempt from the legislation, even though their public
announcement are likely reflective of their institutional self-interest (like all businesses and
institutions) rather than any rigorous study. In fact it is not clear from the legislation that academics
posting from their own social media account (so not acting ‘officially’) are covered by the exemption.

Even experts, such as academics, don’t know everything (even about their own discipline) and often
get things wrong. Even when correctly reflecting the state of knowledge within their own narrow
fields, academic conclusion may be misleading if missing a wider context. It is necessary that if
democracy is to deliver the best outcome for the community, that if bad ideas arise in the academy
they are challenged. If the legislation reduces the visibility of dissenting opinion to narrow academic
opinions, then the democratic process will be impeded to the detriment of the broader national
interest.

It is also the case that the list of exemptions is not sufficiently large to cover many individuals and
**organisations who have valuable expert opinion. As a disclaimer, I am a former academic, yet still**
presumably a qualified expert. I thus feel somewhat slighted that my social media posts (if I were
ever to make one) would be subject to this legislation. This light-hearted observation touches on a
very serious issue. The legislation does not cover a range of organisations that have expert opinions
that may, in many instances, be of greater reliability than that of government agencies. For example,
professional bodies do not seem to be covered by the exemptions. Additionally consulting firms, tech
(including biotech) companies all employ experts with considerable experience in their fields, all of
whom may have valuable insights to share with the community. Similarly, there may be unaffiliated
individuals (such as medical experts) with considerable expertise in a field that are potentially
censored on controversial issues as a result of this proposed legislation. It can often be difficult for
these groups to secure meaningful or accurate reporting on traditional media.


-----

Furthermore, the proposed legislation entrenches the market position of so-called legacy media. It
creates a barrier to entry to new online media firms, particularly any established within Australia. If
implemented, there will now be additional up-front cost to develop mechanisms to monitor and
censor posts on any site. Additionally, there will be the ongoing cost of monitoring posts on the site.
These additional costs will deter the establishment of new and innovative online media firms.

As an economist I am concerned that this legislation artificially limits competition in this market.
There is a long and extensive economics literature that argues these types of barriers to entry and
limits on competition are decremental to the national interest. This limit on innovation in the media
industry has the potential to leave Australia with an expensive and outdated media industry.
Relatedly, it will hold up the ongoing transition of the broader society to the evolving online media
landscape. This adjustment has been, and will no doubt continue to be, rocky, but as a nation it can’t
be avoided. Though if implemented, this legislation could postpone or drag out the adjustment.

**The list of exemptions to content is relatively complex and somewhat nuanced. For example, how**
does a social media company tell whether a post is “produced in good faith for the purposes of
entertainment, parody or satire”? How can they tell whether an academic’s post is produced “by or
for an educational institution”? Indeed how is an international social media company to understand
what is covered by the constitutional right to freedom of political communication? It may be in the
social media company’s commercial interest to simply ignore exemptions and simply delete all posts
which may possibly come under the (very vague) definition of mis/dis information.

Organisations, including government agencies, are subject to so called ‘group think’. Group think is
often unsubstantiated by facts, and is resistant to challenge. It could be the case that agencies
advising ACMA may sincerely believe their advice about censoring online content, but their views
may be wrong or incomplete because of group think. This is also true of social media companies that
would be obliged by this legislation to monitor and censor content. This legislation risks entrenching
some false beliefs in the public discourse, to the overall detriment of the national interest.

The report commissioned by ACMA to research disinformation, Park, S., McCallum, K., Lee, J.,
Holland, K., McGuinness, K., Fisher, C. & John, E. (2022) is itself an example of the complexity of
**defining disinformation. On p. 133-4 of the report the authors outline how they define misinformed**
groups, which is as follows:

Those who are in general disagreement with the authoritative or factual advice are labelled
as ‘misinformed’. Of the five statements (in the copy of table 14 below), if a respondent is in
disagreement with one or two health advice, they are categorised as ‘misinformed (low)
(30%)’. If a respondent disagrees with three to five statements, they are recoded as
‘misinformed (high) (11%)’. The rest was recoded as ‘informed’ (60%).


-----

Source “Park, S., McCallum, K., Lee, J., Holland, K., McGuinness, K., Fisher, C. & John, E. (2022).

The figures in bold in this copy of table 14 from the report indicate the number of people assumed to
have been misinformed. Thus if a person agrees to the first statement one is assumed by the
researchers to be misinformed.

I want to spend a little time considering how problematic this definition of the misinformed is.
Consider the first of the five statements for which this measure is defined. If someone was sceptical
that wearing masks could prevent the spread of covid, this counts as being misinformed. However,
the recent authoritative meta study by the Cochrane Institute finds no robust scientific evidence that
masks are effective in influencing the spread of covid 19. See:

https://www.cochranelibrary.com/cdsr/doi/10.1002/14651858.CD006207.pub6/full

Consider the second statement. For this one, a person is considered misinformed if they are
concerned about the safety of covid 19 vaccinations. To be clear, I personally do not disagree with
this assessment, though it should be noted that AstraZeneca COVID-19 vaccine was withdrawn from
use. Additionally, booster shots of approved COVID-19 vaccines are not specifically recommended by
ATAGI for younger people without other health complications. Thus it is possible that a person might
interpret the second statement in such a way as to disagree with it, even while having beliefs that
conform with current Australian guidelines.

The third statement is similarly superficial. Mask mandates might be considered part of the official
medical guidelines, so a well-informed person (who views correspond with the Cochrane Review)
could well disagree. As for the fourth question, fans of the ABC’s tv program Utopia might
instinctively agree. In the last (fifth) question, a respondent may believe the symptoms of a mild
covid infection can be ameliorated with paracetamol, and agree with this statement.

Given all these problems in the report with the categorisation of misinformed people, and thus their
prevalence in the community, the report itself is an excellent example of misinformation. My own
assessment of this report is that it does not provide compelling evidence for, or establish the case for,
legislation to regulate Australian’s use of the internet. (Further I would argue that the methodology it


-----

used is not up to this task.) It has been conducted by people whose expertise is in news and media
studies, rather than any of the areas where they are trying to judge misinformation. This is not in any
way alleging any shortcoming of the authors or their efforts, rather it speaks to the virtual
impossibility of defining, identifying and policing misinformation in a just, comprehensive and
consistent manner.

**The world of information is so vast and dispersed, requiring a huge range of specialised expertise**
**to properly understand, that any attempts to control or contain it is doomed to failure.**
Furthermore, as already indicated, damage will be caused by those attempts.

The report raises national security concerns. It is difficult to assess how realistic the possible threats
to national security are because of social media use. Though I imagine if this legislation causes local
users to migrate to completely unregulated international online providers this may in itself cause
national security issues. In any event, it is misleading to confuse issues of national security with that
of mis/disinformation on social media. National security should be dealt with explicitly by security
agencies and their governing legislation, and not conflated with problems surrounding social media
use.

3. An ethical, practical, approach to misinformation and disinformation

Although I believe the proposed legislation is misguided, it is nonetheless important that
government agencies have to ability respond to, and correct, what they believe to be misinformation
or disinformation. This is especially true in cases where there is less of a political dimension and
more of rigorous scientific evidence available to counter the problematic claims. For instance, there
is a strong case for information campaigns to refute the false claim that the MMR vaccine causes
autism.

But in countering false information, it is important that the government adopts a strategy of
persuasion rather than one of censorship. The role of experts, in and outside government, is to
inform and persuade the public, not to dictate to them. Censorship will not change people’s minds,
in fact may entrench their false beliefs. And if censorship causes those users with false beliefs to go
overseas (or encrypt their communications), then government agencies have lost the ability to
persuade them to change their minds.

As an alternative to the approach in the proposed legislation, I suggest government adopt legislation
which would allow a government agency such as ACMA to require social media companies to
**provide links to official advice when deemed necessary to counter disinformation. This is a relatively**
small extension of the approach used for COVID 19. Such an approach would ensure that official
advice is always in the online conversation, but that online conversations are allowed to evolve
without the threat of censorship. Such a policy is more likely to persuade people of the government’s
view, and does not conflict with anyone’s right to expression.

This approach receives some support from some of the findings from ACMA’s “A report to
government on the adequacy of digital platforms’ disinformation and news quality measures”


-----

[https://www.acma.gov.au/report-government-adequacy-digital-platforms-disinformation-and-news-](https://www.acma.gov.au/report-government-adequacy-digital-platforms-disinformation-and-news-quality-measures)
[quality-measures](https://www.acma.gov.au/report-government-adequacy-digital-platforms-disinformation-and-news-quality-measures)

Specifically, the two findings of this report (p.38) are reproduced below (italics added):

Finding 10: Most Australians are aware of platform measures to remove or label offending
content, but few have direct experience. Early evidence suggests these steps have been
_somewhat effective in reducing amplification of misinformation on particular platforms._

Finding 11: Australians see the issue of misinformation to be one of joint responsibility – split
between individual users, platforms, and government. There is some scepticism in the ability
_of platforms to self-regulate, and concern about government’s role in regulating speech._

Finding 10 of the report suggest that information campaigns do influence opinion, and thus have the
potential to be an effective tool against disinformation. Finding 11 confirms that there is unease
surrounding censorship of online content, whether implemented by social media companies or
government. These concerns would be side stepped by the alternative type of legislation that I have
proposed above.

4. Summary

For reasons I have stated the proposed legislation is an overreaction to the problem of online
disinformation. There is no convincing evidence that there are greater harms caused by
disinformation on social media than were caused by disinformation in the era prior to social media.
Yet the proposed legislation will almost certainly result in a significant number of negative
unintended consequences.

Recent online experience suggests that there is a very serious risk that legitimate dissenting option
can be labelled misinformation and suppressed, to the detriment of the democratic process and the
national interest. When this occurs it often has the effect of enraging the censored when their
sincerely felt beliefs, expressed in posts, are deleted. The result will be the further undermining of
societal cohesion.

Ideally no individuals or groups should feel disenfranchised from the national conversation. Apart
from being unethical, such an outcome could increase the fragmentation and conflict within society,
with many retreating to their favoured information silos.

I propose that an alternative to the proposed legislation is less stringent legislation that requires
social media companies to provide links to government provided information. Such an approach
would avoid the negative consequences of the proposed legislation and would, in my view, be more
ethical and ultimately more effective in countering misinformation/disinformation.


-----

References:

Nyhan, B., Settle, J., Thorson, E. et al. Like-minded sources on Facebook are prevalent but not
polarizing. Nature 620, 137–144 (2023). https://doi.org/10.1038/s41586-023-06297-w

Source “Park, S., McCallum, K., Lee, J., Holland, K., McGuinness, K., Fisher, C. & John, E.
(2022). Covid-19: Australian News & Misinformation Longitudinal Study. Canberra: News &
Media Research Centre. p. 134“


-----

