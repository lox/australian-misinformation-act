# Inquiry into Misinformation and Disinformation 

 Submission of the Media Entertainment & Arts Alliance (MEAA)

 August 2023


1


-----

MEAA makes this submission in response to the Australian Government’s draft
_Communications Legislation Amendment (Combatting Misinformation and Disinformation)_
_Bill 2023._

MEAA is the leading voice in the media and cultural sectors and represents over 15,000
workers, over a third of which are journalists and media workers.

Throughout the COVID pandemic our members performed extraordinary work to inform and
educate Australians about a rapidly evolving global situation. Australians relied on the up-todate, accurate and verified reporting that our members provided but their work was
constantly undermined by misinformation and disinformation. Some of it was coordinated
and targeted, while some of it was unwittingly picked up by ordinary Australians who did not
check the source of the information nor question the motives of those posting it. While this
was an acute situation during the height of the pandemic, we continue to see deliberate
campaigns distributing incorrect, misleading, and damaging information, for example, as
part of The Voice to Parliament debate.

In combatting misinformation and disinformation, it is important to achieve a balance
between protecting the public from serious harm from misinformation and disinformation
and ensuring fundamental rights and freedoms are protected.

ACMA’s proposed powers would enable it to:

  - gather information from, or require digital platform providers to keep certain records

about matters regarding misinformation and disinformation;

  - request industry develop a code of practice covering measures to combat

misinformation and disinformation on digital platforms, which ACMA could register
and enforce; and

  - create and enforce an industry standard (a stronger form of regulation), should a

code of practice be deemed ineffective in combatting misinformation and
disinformation on digital platforms.

It is unclear to us whether ACMA has, or will have, the resources and expertise to determine
what constitutes “misinformation” and what does not.

**Serious Harm**

The proposed powers will only apply to misinformation and disinformation that is
reasonably likely to cause or contribute to “serious harm.”

The types of harm are captured by the legislation, including harm to the health of
Australians, and hatred against a group based on ethnicity, nationality, race, gender and the
like.

While many of the harms listed under Schedule 1, section 2 (“harm”) are vague and overly
broad (e.g. subclause (e) - “harm to the Australian environment”), subclause “(b) disruption
of public order or society in Australia” is particularly concerning.

2


-----

MEAA believes the inclusion of this “harm” is dangerous and open to misuse and
exploitation. Indeed, there is a long history of important social movements being considered
“disruptive” by governments and powerful interests.

Many of our journalist members are regularly subject to racist, sexist, and other
discriminatory based trolling while trying to do their jobs. We note that race or sex-based
discrimination (among other forms of discrimination) causing or contributing to serious
harm, while falling within the scope of the legislation, would not deal with a specific
individual who is the subject of such trolling (this would still fall within the remit of the
eSafety Commissioner).

**Scope**

The scope of the proposed legislation is wide, only excluding content produced in good faith
for the purposes of entertainment, satire or parody, and professional news content as well
as content produced by or authorised by, respectively, educational institutions and
governments.

While professional news content is excluded, it is essential in maintaining and renewing
trust in the media that news organisations be transparent about their stances on issues, and
ensure their own ethical codes and complaints procedures (including how they deal with
misinformation/disinformation) are easily accessible to consumers.

Moreover, it is important that these organisations are transparent in the information they
provide - by clearly labelling opinion and commentary pieces so that they are readily
distinguished from news and information content.

It is unclear whether freelancers and smaller digital, particularly independent, publications
would be excluded from the operation of the proposed laws. Many of these freelancers or
organisations may not necessarily be subject to the rules and codes that appear in the
current definition. However, our members working in this space are bound by MEAA’s
ethical code – the Journalist Code of Ethics - which was created in 1944 and applies to MEAA
journalist members, promoting a commitment to the highest standards of honesty, fairness,
independence, and respect for the rights of others.

MEAA suggests that the proposed definition “professional news content” in the Bill be
amended to specifically refer to adherence to MEAA’s Journalist Code of Ethics.

MEAA believes the exclusion of content produced by federal, state, territory or local
governments is concerning. It is simply unreasonable that the view of governments be
protected from the reach of this Bill’s definition of “misinformation” and paves the way for
government to politicise valid criticisms of it while engaging in misinformation of its own.

It is also unclear why the code and standard-making powers will not apply to authorised
electoral and referendum content. Disinformation and misinformation in these forms of
information has the capacity to contribute to the undermining of our democratic
institutions. By way of a current example, “Yes” and “No” vote documents are being

3


-----

distributed to voters by the AEC as part of the Voice to Parliament referendum process
without any independent fact-checking. It’s almost certain those documents will be posted
on digital platforms, but the creators (politicians and bureaucrats) would be exempt from
the provisions of the proposed law.

While the laws would apply to a broad range of digital platforms, their application in relation
to private messages appears more complex. ACMA powers would not apply to direct private
messages sent from one user to one or more other users or the content of a closed group
conversation, but group chats open to the public would be within scope. ACMA would also
still be able to use its information gathering and record keeping powers in relation to the
operations of private messaging services.

The Guidance Note at 3.1.2 (p14) states:

“While private messages are a key feature of instant messaging services, it is envisaged that
_the ACMA would use its information-gathering and record keeping powers to understand_
_more about platform measures to combat misinformation and how user complaints are_
_addressed. The registered codes and standards could have requirements that instant_
_messaging services have measures in places that help address the harm of misinformation_
_on their service without revealing the content of private messages. For example, this could_
_include a range of educative measures that platforms provide to assist their users to critically_
_assess information.”_

MEAA has long advocated for the importance of media literacy, particularly in relation to
misinformation and disinformation, and suggests this “range of educative measures”
contemplated in the Guidance note be applied across the board to all platforms.

These should include undertaking education campaigns and training programs relating to
media literacy, working with education institutions to share data, and partnerships with
independent fact-checking organisations.

**ACMA Powers**

ACMA has the power to have digital platforms keep records of misinformation and
disinformation on their platform and the measures implemented to prevent this occurring.

ACMA would also have powers to obtain other information from persons to assist it in
monitoring compliance, which could include fact checkers. MEAA believes that fact checkers
are an essential component of any processes digital platforms should put in place. MEAA
believes fact checkers should be a mandatory requirement of any code or standard
developed.

The Bill requires public consultation by the industry body or association producing a code
prior to ACMA registering it. If ACMA were to make a standard the Bill also provides for
consultation prior to this occurring. MEAA believes that as the union and professional body
for the media and cultural sectors, we should be part of any consultation process
undertaken.

4


-----

**Enforcement**

MEAA notes that formal enforcement actions in relation to non-compliance of information
gathering and record keeping rules and codes or standards are proposed to be applied in a
graduated manner.

It is important that civil penalties are utilised by ACMA to incentivise compliance and ensure
digital platforms take these obligations seriously. However, this presupposes that the other
concerns identified in this submission can be resolved satisfactorily.

**Privacy and Freedom of Speech**

While MEAA recognises the dangers of disinformation and misinformation and the corrosive
effects it has on the Australian polity, it is important that fundamental rights around privacy
and freedom of speech are protected in any legislation.

We note that ACMA will not have the power to request specific content or posts be
removed from digital platform services, and the Bill is directed at encouraging digital
platform providers to have appropriate systems in place to combat disinformation and
misinformation rather than directly regulating specific pieces of content.

Further, ACMA would have no role in determining truthfulness or requesting action
regarding individual pieces of content, instead focussing on systems and measures to
combat misinformation and disinformation.

However, these protections are undercut by ACMA being the ultimate decision maker as to
what constitutes “misinformation” and “disinformation.”

**Conclusion**

MEAA believes the Australian Government has a responsibility to combat the very real
problem of misinformation and disinformation. It is essential that digital platforms be
accountable for the often deliberately misleading or fabricated information online. These
lies undermine legitimate reporting and news organisations and the public’s faith in
democratic institutions.

However, we are concerned about the breadth of the legislation, particularly around what
constitutes “serious harm” as well as the scope of the Bill, and the protections around
freedom of speech.

Consequently, MEAA believes the Bill as currently drafted requires appropriate
amendments for it to properly realise is aims.

5


-----

