Centre for Theology and Ministry

Telephone:

Information Integrity Section
Department of Infrastructure, Transport, Regional Development,
Communications and the Arts
GPO Box 2154
Canberra ACT 2601
E-mail: [information.integrity@infrastructure.gov.au](mailto:information.integrity@infrastructure.gov.au)

## Submission by the Synod of Victoria and Tasmania, Uniting Church
### in Australia to the consultation on the Communications Legislation
## Amendment (Combatting Misinformation and Disinformation) Bill 2023

**20** **August** **2023**

The Synod of Victoria and Tasmania, Uniting Church in Australia, welcomes the opportunity
to make a submission to the consultation on the _Communications_ _Legislation_ _Amendment_
_(Combatting_ _Misinformation_ _and_ _Disinformation)_ _Bill_ _2023._

From its foundation, the Uniting Church in Australia upheld the need for truth in public life. In
its Statement to the Nation at its inaugural National Assembly of representatives of the
Uniting Church across Australia in 1977, it stated:

l/l/e _affirm_ _our_ _eagerness_ _to_ _uphold_ _basic_ _Christian_ _values_ _and_ _principles,_ _such_ _as_ _the_
_importance_ _of_ _every_ _human_ _being,_ _the_ _need_ _for_ _integrity_ _in_ _public_ _life,_ _the_
_proclamation_ _of_ _truth_ _and_ _justice,_ _the_ _rights_ _for_ _each_ _citizen_ _to_ _participate_ _in_ _decision­_
_making_ _in_ _the_ _community,_ _religious_ _liberty_ _and_ _personal_ _dignity,_ _and_ _a_ _concern_ _for_ _the_
_welfare_ _of_ _the_ _whole_ _human_ _race._

The OECD has emphasised that government responses to misinformation and
disinformation should focus on measures that prevent its spread.1

We continue to be of the view that material that it would be unacceptable to circulate through
other forms of media, such as print, radio and television, should also apply to the online
world.

There has been a growing body of behavioural science research showing that our interaction
with technology changes our behaviour as people. This branch of psychology has been
labelled cyber-psychology.2 Clinical psychologist Michael Seto has stated concerning our
engagement with the online world as a result of the technology companies rolling out
products that have not been tested for their behavioural impact. He stated "We are living
through the largest unregulated social experiment of all time...."3

Our instincts have evolved to handle face-to-face interactions, but once we go into
cyberspace, these instincts fail us. If you spend time online, you are likely to encounter a far

1 OECD, "Draft Principles of Good Practice for Public Communication Responses to Mis- and Disinformation",
2022, 7.

2 Mary Aiken, 'The Cyber Effect', John Murray Publishers, London, 2017, 4.

3 Ibid., 16-17.

1


-----

greater variety of human behaviour than you ever have before        - from the vulnerable to the
criminal, from the gleeful and altruistic to the sadistic and murderous.4

Some aspects of internet psychology have been studied since the 1990s and are well known
and documented. The effect of anonymity online       - or perceived anonymity       - is one example.
It is the modern-day equivalent of that superhero power of invisibility. It has been found to
fuel online disinhibition, that is doing whatever you feel like as you are not worried about the
disapproval of others. Disinhibition is fed by the perceived lack of authority online, the sense
of anonymity as well as the sense of distance or physical removal from others.5 Due to the
'online disinhibition effect', as it is known, individuals can be bolder, less inhibited, and
judgement impaired. Almost as if they were intoxicated.6 Disinhibition is likely to fuel the
willingness of people to spread misinformation and disinformation in a way that many would
not do in face-to-face conversations with others.

Psychologist Jamil Zaki points out that anonymity tempts people to “try on cruelty like a
mask, knowing it won’t cost them. It does, of course, cost their targets.”7

Not all the impacts of the online world on human behaviour are negative. Altruism, for
example, is amplified online, with people often being more generous and giving in
cyberspace than they are face-to-face. This has been seen in the enormous growth in online
crowdfunding.8

The online world has been shown to reduce people's empathy for others. Countries with
higher Internet usage also have lower average levels of empathy. People who spend more
time on the Internet, social media or gaming platforms report more significant trouble
understanding others.9 A lack of empathy again helps with the spread of harmful
disinformation and misinformation.

**Example** **of** **the** **online** **world** **reducing** **empathy10**
Iraqi artist Wafaa Bilal in the US invited people to shoot him with a remotely operated paint
gun. His brother, Haji, had been killed by a remotely operated drone-directed missile in
2004. He set up an all-white living space in Chicago's Flatfile Gallery with nothing but a bed,
a small computer desk, and a paintball gun. It was mounted on a small turret that could be
controlled by remote users, with a webcam affixed on its barrel. Users could log on, aim, and
fire as many times as they liked. Bilal turned it on and stayed in the room for the next 30
days.

During that time, the gun was fired around 60,000 times, or once every 45 seconds. Bilal
took shelter behind a Perspex barrier while he tried to sleep. Dozens of shooters vied for
control of the paint gun at the same time. Demand to use the weapon crashed the servers.
People shot at Bilal from 138 countries. They wrote comments like "die terrorist".

While some of these people would have probably shot Bilal face-to-face with a paint ball
gun, it is probably safe to assume the majority only did so due to the distance of the internet

4 Ibid., 12.

5 Ibid., 21.

6 Ibid., 5.

7 Jamil Zaki, 'The War for Kindness. Building Empathy in a Fractured World', Robinson, 2019,148-149.

8 Mary Aiken, 'The Cyber Effect', John Murray Publishers, London, 2017, 5.

9 Jamil Zaki, 'The War for Kindness. Building Empathy in a Fractured World', Robinson, 2019,147.

10 Ibid., 144-145.

2


-----

| and the safety of anonymity.

The online world has made it much easier for like-minded people to find each other than
relying on running into such people in the real world. This is positive when it means people
share hobbies or support each other, such as 'stay-at-home-mums'. Millions of people with
rare diseases have been able to go online and join Facebook groups and message boards
such as RareConnect.org. Sufferers from such illnesses can share tips on managing
symptoms, dealing with insurers, and exploring new therapies. Online illness communities
are wells of mutual empathy and understanding. Rare illness sufferers who feel isolated,
judged, or just "different" find solace in people they will never meet in person.11 However, it
has also made it easier for people with disturbing or harmful interests to find each other.
They are free from any social disapproval that may have previously inhibited their behaviour.

We all are subject to socialisation. Socialisation is the process where we acquire our
attitudes, values, beliefs and behavioural patterns in conformity with the demands of the
society or group to which we belong to.12 Successful socialisation of a person is marked by
acceptance of the society or group the person is part of. Anyone who has joined a hobby or
interest group or a church congregation knows that each such group has its own culture, its
own accepted norms in the group. You will often modify your behaviour to fit in. This has a
downside, as behaviours that were initially troubling to you, or made you feel uncomfortable,
may start to feel normal over time.13

In the online world, people with very disturbing or harmful behaviours are often able to forms
groups that amplify the problematic behaviour. They are free from being challenged by the
wider society. In the real world, fear of social isolation moderates what many people may say
if they know it will meet with the disapproval of others.14 That effect is dampened in the
online world.

You can easily stumble upon a behaviour online and immerse yourself in new worlds and
new communities, becoming cyber-socialised to accept activities that would have been
unacceptable just a decade ago. The previously unimaginable is now just at your fingertips        -
just waiting to be searched.15

One of the powers of the cyber environment is its ability to deceive and delude. It attracts
vulnerable individuals into strange communities where their desire for acceptance becomes
an obsession.16

Given the psychological effects of the online world on human behaviour, the spread of
seriously harmful misinformation and disinformation seems more likely than in the real world.
Thus, greater regulation of misinformation and disinformation in the online world is justified.

Therefore, the Synod supports the _Communications_ _Legislation_ _Amendment_ _(Combatting_
_Misinformation_ _and_ _Disinformation)_ _Bill_ _2023_ as a small step forward in addressing

11 Ibid., 164.

12 Mary Aiken, 'The Cyber Effect', John Murray Publishers, London, 2017, 37.

13 Ibid., 38.

14 Jorg Matthes and Andrew F. Hayes, 'Methodological Conundrums in Spiral of Silence Research', in eds.
Wolfgang Donsbach, Charles T. Salmon and YarivTsfati, 'The Spiral of Silence. New Perspectives on
Communication and Public Opinion' (New York: Routledge, 2014), 55        - 56.

15 Mary Aiken, 'The Cyber Effect', John Murray Publishers, London, 2017, 45.

16 Ibid., 153.

3


-----

misinformation and disinformation in the online world. However, much more will be needed if
the flood of misinformation and disinformation in the online world is to be seriously curbed. A
critical step forward would be empowering the ACMA or the eSafety Commissioner to
require standards of the algorithms of the social media and search engine corporations that
make recommendations of content to prevent the spread of cases of clear misinformation
and disinformation. The algorithms should also be designed to detect and prevent the
spread of misinformation and disinformation by bots and artificial intelligence services. Such
a measure would not stop individuals from manually spreading misinformation and
disinformation by posting it publicly or sending it to others, but the algorithms would not
amplify their efforts.

We agree with the definitions of "misinformation", "disinformation", and "serious harm" in the
Bill.

The Synod supports that the ACMA will have the power to register codes and make
standards to compel digital service platform service providers to act against misinformation
and disinformation on their services.

The Synod supports the range of enforcement actions that will be available to the ACMA for
non-compliance by digital platforms or individuals to the measures contained within the Bill.

The Synod strongly supports the addition to the _Broadcasting_ _Services_ _Act_ to include a new
object to encourage digital platform providers to protect the community against harm caused,
or contributed to, by misinformation and disinformation on digital platform services.

The Synod disagrees with the Government's preference that "an effective self-regulatory
scheme is the preferred approach." The Synod is concerned that digital platforms seek to
minimise their costs in dealing with harmful content of all types on their services. Chris Gray
outlines how such an approach harms both the content moderators and users of the services
in his direct experience as a content moderator.17 Further, the lag in content moderation
often means much of the harm misinformation and disinformation will cause will have
happened before the content is removed.

The Synod recently commissioned an investigation into content moderation Business
Processing Operation (BPO) corporations in the Philippines. The investigators reported that,
in general, subcontracted content moderators suffer from direworking conditions, being
overworked and underpaid. They continue to have inadequate support to address potential
psychological issues from overexposure to harmful and distressing content. BPO content
moderators are prevented from organising, which blocks them from launching a concerted
effort to have their rights as employees respected. Those who try to organise content
moderators are often terminated from their employment. Union organisers have also been
murdered. It is common practice for BPOs to compel employees to sign ironclad Non­
Disclosure Agreements to prevent outsiders from understanding the lack of training that
content moderators receive. Many of the content moderation operations in the Philippines
are under the oversight of the Philippine Economic Zone Authority, making it harder for
content moderators to have their work entitlements respected.

Further, Ong and Tapsell concluded after considering disinformation around Southeast Asia

17 Chris Gray, _The_ _Moderator_ (Gill Books, 2022).

4


-----

elections that:18

_It_ _is_ _also_ _abundantly_ _clear_ _that_ _big_ _tech_ _platforms_ _have_ _uneven_ _protocols_ _and_
_guidelines_ _in_ _their_ _social_ _media_ _content_ _moderation_ _practices_ _around_ _elections._
_Facebook_ _enjoys_ _positive_ _publicity_ _from_ _their_ _takedowns,_ _but_ _without_ _a_ _transparency_
_and_ _accountability_ _framework_ _that_ _invites_ _deliberation_ _around_ _these_ _decisions,_ _they_
_can_ _stand_ _accused_ _of_ _partisanship._

The point of raising these concerns is that the Commonwealth Government should be more
prepared to set and enforce regulations over digital platform providers to ensure that the
corporations meet expectations of dealing appropriately with harmful misinformation and
disinformation on their services. Digital platform providers should not be trusted to meet such
standards on their own.

The Australian Government needs to continue to develop further responses to the problem
of harmful disinformation and misinformation. The OECD and the Canadian Privy Council
Office's Impact and Innovation Unit have argued that there is no one-size-fits-all solution for
addressing misinformation and disinformation.19 They have argued that partnerships
between government, experts, academics and other non-government actors are necessary
for a coordinated response.

Dr Mark Zirnsak
Senior Social Justice Advocate
Justice and International Mission Cluster

Phone:
E-mail:

18 Jonathan Corpus Ong and Ross Tapsell, "Mitigating Disinformation in Southeast Asian Elections: Lessons
from Indonesia, Philippines and Thailand", (NATO StratCom Centre of Excellence, 2020), 25.

19 Chiara Varazzani, Michaela Sullivan-Paul, Lauryn Conway, Andrea Colasanti and Nicholas Diamond,
"Misinformation and Disinformation. An international effort using behavioural science to tackle the spread of
misinformation", (OECD and Canadian Privy Council Office's Impact and Innovation Unit), 27.

5


-----

