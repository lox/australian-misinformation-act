**Submission**

**Dr Paul M Taylor[1]**

**Communications Legislation Amendment (Combatting Misinformation and**

**Disinformation) Bill 2023 Exposure draft**

I am grateful for the opportunity to respond to the request for comments on the above Bill.

I respectfully recommend the Bill be abandoned.

**Introduction: Does the Government’s rationale fit the Bill? No.**

The Government’s rationale for the Bill, as explained by the Minister for Communications,
the Hon Michelle Rowland MP, is that “misinformation and disinformation pose a threat to
the safety and wellbeing of Australians, as well as to our democracy, society and economy”.
In a law of unintended consequences this Bill is itself likely to pose a threat of the very kind
that it purports to address.

Two obvious ways of reducing the prospect of severe unintended harm from the Bill are to
ensure that it is properly and narrowly targeted, and it preserves freedom of expression. This
Bill fails on both counts. It is excessive both in its grip and expansive reach. It targets
Australians by empowering digital platforms, instead of bringing those platforms to order. It
fails to uphold the freedom of expression to the standard protected by international
conventions. It is out of line with comparable overseas measures.

**Would ‘freedom of expression’ be protected? No. There isn’t the machinery for it in**
**Australia**

The Bill expresses an “intention” for regulation in a manner that “has regard” for freedom of
expression. This amounts to nothing.

Freedom of expression in its international law sense is not protected in Australia. The
necessary legal mechanisms do not exist in Australia for the Bill to preserve freedom of
expression in the way that overseas jurisdictions can and in this exact context do. The essence
of freedom of expression is the guarantee in law, of the right to access and express opinion
and information, and to resist incursion that is not fully justified according to strict standards,
with proper redress.

1 Honorary Senior Lecturer, and Fellow of the Centre for Public International and Comparative law, TC Beirne
School of Law, The University of Queensland; Adjunct Professor, School of Law, The University of Notre
Dame Australia. Author of A Commentary on the International Covenant on Civil and Political Rights: The UN
_Human Rights’ Committee’s Monitoring of ICCPR Rights (Cambridge University Press, 2020); and Freedom of_
_Religion: UN and European Human Rights Law and Practice (Cambridge University Press, 2005). This_
submission is made in a purely personal capacity and does not reflect the views of any institution with which I
am affiliated.

1


-----

Australian protection for free speech, such as it is, subsists in the implied freedom of political
communication under the Commonwealth Constitution, and in the liberties that exist merely
in the fact that particular conduct is not specifically rendered unlawful (e.g. by legislation,
such as this). Limited marginal protection is added by human rights charters in those
Australian jurisdictions which have enacted them, and by certain common law principles
which favour right-compatible principles of construction. All of this falls very far short of
“freedom of expression” in the international convention sense. The Bill would authorise
restriction of “freedom of expression”, measured against that international law standard.
Freedom of expression cannot be appealed to by Australians, and no mechanism exists in
Australia that could even test whether the necessary justification exists for restriction against
that standard.

The Bill refers to “freedom of expression” (to say that Parliament “intends that digital
platform services be regulated…in a manner that…has regard to freedom of expression”),
and so does the Guidance Note of the Department of Infrastructure, Transport, Regional
_Development, Communications and the Arts, several times. It gives the impression that_
freedom of expression has a substantive role in this legislative scheme. It does not, and for
reasons already given (the non-existence of substantive legal protection for “freedom of
expression” in Australia) it cannot. In my view, the Government should not mislead the
Australian public in this respect. It should make absolutely clear that under this Bill there is
no substantive protection for freedom of expression, and that the Bill authorises unjustifiable
incursions on that freedom. Nothing can be asserted against such incursion in the way
intended by international law. Whatever free speech protection exists in Australia is not
“freedom of expression”, in the sense used by international conventions, and in the sense
used in overseas jurisdictions when preserving that freedom in the context of misinformation
measures (see below, Is the Bill comparable to overseas initiatives? No.) This is an issue
which is of fundamental concern to the Australian public, inadequately explained in a
parliamentary process for a Bill intended in support of democracy.

The only real element of free speech which the Bill would preserve is the implied freedom of
political communication (as it must), which is not a right of the individual, and therefore
cannot be attributed to the freedom of expression, which is.

By excessive regulatory reach, the Bill would produce broad brush censorship on a mass
scale. The result would be that governmental authorities would hold the whip-hand in
controlling the dissemination of online content, including dissent from the official line on
crucial, sensitive issues of public importance which need to be openly debated.

An over-protective, harm-based rationale for content exclusion is bound to prevail in this
form of heavy-handed regulation, by a simple process of pointing to the types of harm
contemplated by the Bill, without any countervailing freedom of expression to assert against
it. The usual principles that need to be observed when restricting freedom of expression in an
individualised way (based on the necessity of restriction, on particular grounds, by the least
restrictive means etc) simply do not apply.

**Does this Bill achieve a specifically targeted regulatory purpose? No. And it is wrongly**
**aimed.**

2


-----

For some years, deep-seated concerns have been expressed officially in many jurisdictions
over the role of digital platforms in curating content. The task was initially thrust upon digital
platforms, largely out of practical necessity (since they were the ones controlling the flow of
digital traffic), well before the environment in which they operate was properly regularised.
Because of the scale of information flow, digital platforms supported their user policies with
a combination of automated and human processes to filter content. However, they also
readily exploited opportunities in their core and neighbouring markets. Over time they
suffered reputationally from allegations of anti-competitive conduct, violation of user
privacy, and political bias (among other distortions), and still do. They proved themselves to
be not as dependable as the system requires.

The cornerstone of any regulation of this kind should be to ensure that digital platforms
themselves are answerable for any political, viewpoint and other distortions which they
themselves introduce or allow in the carriage of content. For all the reasons outlined in my
article, ‘Uneven Platforms: The Press, Social Media, Search Engines and Freedom of
_Expression’,[2] it is necessary to acknowledge openly the power which digital platforms_
possess as the agents for such distortions. The Bill would empower them in this, not curb
them.

Because digital platforms are so influential in promoting, downgrading, slowing, excluding
and in other ways affecting the visibility of content, and in affecting its monetisation, it is
proper that any such abuse should attract severe turnover-based penalties. Penalties of a high
order of magnitude are warranted because the distortive manipulation of content can occur on
such a grand scale as to pose a “threat” to our democracy. In doing so, platforms may be
serving their own interests, or acting under private or governmental influence. In any case it
is extremely harmful.

However, that is not where this Bill is primarily targeted. The Bill contemplates a scheme
which would regulate the dissemination of the content produced and viewed by ordinary
Australians using a digital service. Dissemination of content is “misinformation” if the
content contains information that is false, misleading or deceptive, and the provision of it on
the digital service is reasonably likely to cause or contribute to serious harm. It is
“disinformation” if additionally, the person responsible intended the content to deceive.
“Content” is very broadly defined, as is “dissemination,” since it “includes” automated
dissemination and dissemination to one or more people. The application of the Bill is
therefore very wide.

“Harm” is described in terms which are capable of widely differing interpretations, to include
“hatred against a group in Australian society”, “disruption of public order or society”, or
“harm to the health of Australians”. The harm threshold is capable of being easily triggered.

It is interesting to contrast the existing Australian Code of Practice on Disinformation and
_Misinformation (December 2022) with the Bill, since this indicates the divergence between_
the two, and their differences in terms of effective targeting. The existing Code of Practice is
much more precise. Unlike the Bill’s definitions which capture “content” (and
“dissemination”) expansively, the Code of Practice only applies to “Digital Content”, i.e.

2 Paul Taylor, Uneven Platforms: The Press, Social Media, Search Engines and Freedom of Expression,
University of Tasmania Law Review Vol 39 No 2 2020, pp. 121-149.

3


-----

“content distributed online on a platform…that is targeted at Australian users and includes
content that has been artificially produced, manipulated or modified by automated means
such as through the use of an artificial intelligence algorithm”. The aspect of disinformation
that the Code of Practice focuses on is: “Digital Content that is verifiably false or misleading
or deceptive; is propagated amongst users of digital platforms via Inauthentic Behaviours;
and the dissemination of which is reasonably likely to cause Harm.”

The Code of Practice and the Bill may serve different purposes, but this comparison is
instructive in demonstrating the Bill’s profound lack of targeted precision, and the absence of
any real boundaries around the Bill’s capacity to censor. No government should seek or have
such power in the absence of legal protection for freedom of expression.

The Guidance Note is not helpful in explaining the specific impetus for this legislation, and
why it is needed beyond the existing Code of Practice, and indeed existing criminal and civil
law protection that already exists in legislative form, in areas of consumer protection, online
safety, election integrity, safeguards against foreign interference, and other security measures.
It should do so, particularly in view of the reach and impact which it will have on all
Australians.

The primary focus of the Bill is not on holding digital platforms to account for the harmful
distortions which they are improperly able to exert. Its impact is greatest in commissioning
digital platforms to implement new government-enforced standards concerning the content
carried, backed by the imperative of eye-watering sanctions.

The effect of the Bill is going to be felt by everyday Australians, rather than by digital
platforms, who should be constrained in their own conduct to avoid potentially extremely
harmful informational distortions, among the worst of which is the excessive removal, or
politically asymmetrical treatment, of content.

**Is the Bill comparable to overseas initiatives? No.**

It should be, but is not, fundamental to the design of the Bill that it is effective in eradicating
the mischief of misinformation, while preserving the free speech of Australians. In this
respect it fails, badly.

In European,[3] and UN,[4] measures combatting misinformation, a cardinal principle is the
preservation of freedom of expression. The treaty standards of the European Convention,
article 10, and the International Covenant on Civil and Political Rights (ICCPR) article 19,
are maintained. Measures addressing misinformation in other jurisdictions do not prejudice
freedom of expression as understood under those convention provisions.

3 E.g. European Commission’s Communication "Tackling online disinformation: a European approach",
COM(2018) 236; European Commission, EU Code of Practice on Disinformation, 26 September 2018; European
Democracy Action Plan (EDAP), COM(2020)790; The Strengthened Code of Practice on Disinformation 2022. (Of these
only EDAP mentions “hate speech”, referring to the proposal for extending the list of EU crimes to hate speech
and hate crime, COM(2021) 777, 9 December 2021).
4 E.g. Reports of the Special Rapporteur on the promotion and protection of the right to freedom of opinion and
expression, UN Doc A/HRC/38/35 (6 April 2018); UN Doc A/HRC/44/49 (23 April 2020); A/HRC/47/25, 13
April 2021; Report of the Secretary-General, Countering disinformation for the promotion and protection of
human rights and fundamental freedoms, A/77/287, 12 August 2022.

4


-----

The Bill contains no equivalent carve out. It is not surprising, since (as already noted)
substantive protection for “freedom of expression”, understood by those treaties, does not
exist in Australian law.

Worse still, the Bill adopts a far lower threshold of harm than is found in other jurisdictions.
Take the Bill’s treatment of “hatred”. There is obvious harm to free speech and democracy if
the principle of “hatred” is so vague and invocable at so low a threshold that it can be used to
silence the views of ideological, political or religious opponents. For this reason, the
convention standards of freedom of expression (missing from this proposal) strongly support
viewpoint diversity and plurality. It is essential to a functioning democracy.

Australian “hate speech” laws already restrict free speech, by criminal, and civil, provisions.
When the Bill includes “hatred against a group in Australian society” within its definition of
“harm” it may be taken to cover at least the breadth of Australia’s existing “hate speech”
laws, criminal and civil, and because of its vagueness an indeterminately wider category of
speech beyond that.

There is no question that hate speech caught by the Australian criminal provisions (often
termed “serious vilification”) should be prohibited.[5] It corresponds with “hate crime” and
“hate speech” recognised at international level, particularly the EU, operating at a very strict
threshold required for criminal law.

The Guidance Note which explains the Bill is inaccurate in claiming that the EU Digital
Services Act’s coverage of “illegal hate speech” (whatever that means) is wider than the Bill.[6]
In the EU, “hate crime” was defined by a 2008 Framework Decision on combating certain
_forms and expressions of racism and xenophobia to mean “any criminal offence, other than_
hate speech, committed with a racist or xenophobic motivation”. “Hate speech” was defined
as “the public incitement to violence or hatred directed against a group or a member of such a
group sharing a protected characteristic”. The Framework Decision, which adopted those
definitions, was “limited to combating particularly serious forms of racism and xenophobia
by means of criminal law.”[7] The EU Digital Services Act recognised that “hate crime” was
more recently expanded from its meaning in the Framework Decision, to cover a broader
range of hate crimes, by the 2021 Commission Communication, A more inclusive and
_protective Europe: extending the list of EU crimes to hate speech and hate crime.[8]_

In other words, the EU Digital Services Act covers hate crime and hate speech of such
severity that is appropriate for prohibition by the criminal measures. The Bill is therefore
wider, not narrower, than the EU Act, because it applies to non-criminal forms of “hatred
against a group in Australian society”, as well as criminal forms. In Australia, civil hate

5 _Criminal Code 2002 (ACT) s. 750; Crimes Act 1900 (NSW) s. 93Z; Anti-Discrimination Act 1991 (Qld) s._
131A; Racial and Religious Tolerance Act 2001 (Vic), ss. 24-25; Racial Vilification Act 1996 (SA) s.4;
_Criminal Code Act Compilation Act 1913 (WA) ss. 77 to 80H._
6 Guidance Note, p. 25: ‘The EU's Digital Services Act (DSA) was approved in October 2022 and regulates a
range of digital platform services such as social media, online marketplaces, and search engines. It covers a
wider range of harmful content than the ACMA powers such as illegal hate speech, child sex abuse material,
terrorist content, misinformation and disinformation.”’
7 Council Framework Decision 2008/913/JHA of 28 November 2008, recital (6).
8 Communication from the Commission to the European Parliament and the Council, A more inclusive and
_protective Europe: extending the list of EU crimes to hate speech and hate crime, crime COM(2021) 777, 9_
December 2021.

5


-----

speech provisions apply at a much lower threshold:[9] in some jurisdictions through the
operation of indistinct terminology like “revulsion” (ACT[10] and Victoria[11]); being “offended,
humiliated, intimidated, insulted or ridiculed” (Tasmania);[12] or by a test that it is “reasonably
likely, in all the circumstances, to offend, insult, humiliate or intimidate another person or a
group of people’ (federal).[13]” There are much more significant variations across jurisdictions
in civil than criminal provisions.

The Bill’s definition of “harm”, as including “hatred against a group in Australian society” is
therefore not comparable to European initiatives. If the Bill were to cover Australia’s current
“hatred” provisions (as indicated by the term “hatred” in the Bill and “illegal hate speech” in
the Guidance Note) it would operate at a low threshold which significantly diverges from the
misinformation measures in the EU or other major jurisdictions, for encroaching upon
freedom of expression. It is much more restrictive of free speech, without any effective
freedom of expression restraint. The Bill’s vague reference to “hatred against a group” would
extend even further than existing Australian provisions because of its lack of specificity.

The Bill also contemplates “harm” according to criteria that are susceptible to multiple,
inadequately constrained, interpretations. For example, there is excessive scope for
interpreting “harm to the health of Australians”, and “disruption of public order or society”,
according to different political perspectives.

**Are “harm” and freedom of expression balanced in the Bill? No.**

The Guidance Note indicates that “[t]he Bill excludes certain content from the definition of
misinformation to strike a balance between the public interest in combatting misinformation,
with the right to freedom of expression.”

There is an exclusion for satire. This is not a concession but is necessary as a matter of
definition, because satire does not correspond with the notion of “disinformation”.

Professional news content is also excluded, with the result that the Bill will be generally
protective of traditional news channels. Because of the lack of viewpoint diversity in the
mainstream media, alternative news sources have emerged but depend on digital platforms
where they would, under the Bill, be at greatest risk of censorship. The Bill would then place
a disproportionate burden on alternative news sources, which are among the most effective
means of exposing inadequacies in news reporting in the mainstream.

In spite of what the Guidance Note suggests, these items are not excluded in a “balancing” of
rights, such as freedom of expression against supposed harms.[14] They are excluded in part for

9 _Discrimination Act 1991 (ACT) s.67A; Anti-Discrimination Act 1977 (NSW) ss. 20C(1), 38S, 49ZT, 49ZXB;_
_Racial and Religious Tolerance Act 2001 (Vic), ss. 7 and 8; Anti-Discrimination Act 1991 (Qld) s. 124A; Anti-_
_Discrimination Act 1998 (Tas) ss. 17 and 19; Civil Liability Act 1936 (SA) s.73(1)._
10 _Discrimination Act 1991 (ACT) s.67A._
11 _Racial and Religious Tolerance Act 2001 (Vic), ss. 7 and 8._
12 _Anti-Discrimination Act 1998 (Tas) s. 17(1)._
13 Section 18C(1)(a) and (b).
14 EU measures regulating digital platforms have similar exclusions (e.g. the EU Code of Practice on
Disinformation) and additionally require protection for freedom of expression to be upheld.

6


-----

not being in the nature of “disinformation.” In any case, the balancing exercise required when
freedom of expression, in the convention sense, is engaged is missing.

**Will digital platforms have power and influence? Yes, and it is not a good thing.**

Since digital platforms will be required to apply the criteria which define “misinformation”,
particularly the element of “harm”, they will be entrusted with the task of interpretation. The
scope for discretion is expanded by the fact that they may intervene whenever the provision
of content on the service “is reasonably likely to cause or contribute to serious harm”.

The Bill establishes a scheme which commands and legitimises digital platforms’
engagement in censorship. This scope for censorship is enlarged unduly by the low threshold
at which the concept of “harm” may be engaged, and by the breadth and reach of the Bill
(e.g. compared with the existing Code of Conduct, which is relatively confined). This inflates
the propensity of digital platforms, without legitimacy, to engage in the manipulation of
content with subtle but far-reaching consequences, through asymmetries and distortions, with
which they have already been associated and which should itself be the subject of regulation.
Facebook and Twitter suspensions are notorious for constituting politicised censorship. The
force of the Bill should be effectively directed to that end, not at the expense of ordinary
Australians expressing themselves. What of the platforms themselves, and their capacity to
put a finger on the scales when apparently fulfilling their obligations assiduously?

The effectiveness of the Bill depends on digital platforms being scrupulously dependable and
accountable. And also the enforcing authority, the Australian Communications and Media
Authority (ACMA). Just before consultation began on the exposure draft of this Bill, Liberal
Senator for South Australia Alex Antic is said to have exposed a process of government
censorship similar to the one which Elon Musk opened up. (It was discovered that the US
government was using current and former officials from the FBI, the CIA, and the
Department of Homeland Security, working with NGOs and university think tanks, to censor
Americans on social media.) Senator Antic suggests that similar government collusion with
Big Tech is occurring in Australia to censor social media.[15] The propensity for such distortion
warrants further inquiry, and it is a matter of concern that it is widened by the Bill. What is
needed is far greater transparency that would expose any and all collusion between all
governmental authorities and digital platforms.

These issues are especially important during times when official narratives are being
protected by government when they most need to be exposed to challenge.

**Conclusion**

The legislation resulting from the Bill would act as an unneeded prophylactic against “harm”,
an already hyper-sensitised notion that is activated at such a low threshold as to enlarge the
scope for distorting the representation of viewpoints on digital platforms.

Politically sensitive content is at constant risk of being flagged as harmful and its frequency
noted, not because it is misinformation, but because it expresses a view which is disliked by

[15 Rebecca Weisser, WHO’s behind Australia’s censorship industrial complex: Orwell wouldn’t be surprised,](https://www.spectator.com.au/author/rebecca-weisser/)
The Spectator Australia, 27 May 2023.

7


-----

the mainstream. There is a popular tendency for one party to a difference of opinion to treat
what the other says as disinformation, and flag it as such. It only takes political or other selfinterest on the part of digital platforms to elevate some content categories over others to
produce distortions which undermine democratic freedoms. There is no objective control
mechanism against that.

The real mischiefs which the Bill should address are the anti-democratic distortions which
digital platforms are empowered to effect, by algorithmic and other manipulation of content.

An unacceptable side-effect of the Bill is the excessive restriction of freedom of expression,
which the Bill mentions but does not have the capacity to support.

I would respectfully suggest that before it is appropriate to enact any bill in Australia
addressing misinformation and disinformation Australia must first put its house in order in
three respects:

1. Australian law should give substantive effect to freedom of expression within its

international law meaning. Only then would the scheme which is meant to uphold
freedom of expression in the context of such a bill be capable of doing so in a way
that corresponds with overseas measures.

2. Digital platforms must demonstrate they are dependable to curate online content in

line with freedom of expression standards. They themselves should be kept under
close and constant scrutiny, not the Australian public. The Bill places too much
confidence, and entrusts too much, to digital platforms. Ordinary Australians will
suffer greatly, and basic democratic processes which depend on free speech will be
undermined.

3. Australian public authorities must prove themselves fit to be entrusted with

overseeing digital platforms in that function.

Since this is not readily achievable it is strongly urged that the Bill be withdrawn.

8


-----

