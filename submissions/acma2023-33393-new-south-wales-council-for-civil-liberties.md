# NSWCCL SUBMISSION

 Department of Infrastructure,
 Transport, Regional
 Development,
 Communications and the
 Arts

 Consultation regarding the
 exposure draft of the
 Communications Legislation
 Amendment (Combatting
 Misinformation and
 Disinformation) Bill 2023

## 20 August 2023


-----

**Acknowledgement of Country**

In the spirit of reconciliation, the NSW Council for Civil Liberties acknowledges the Traditional
Custodians of Country throughout Australia and their connections to land, sea and community. We pay
our respect to their Elders past and present and extend that respect to all First Nations peoples across
Australia. We recognise that sovereignty was never ceded.

**About NSW Council for Civil Liberties**

NSWCCL is one of Australia’s leading human rights and civil liberties organisations, founded in 1963.
We are a non-political, non-religious and non-sectarian organisation that champions the rights of all to
express their views and beliefs without suppression. We also listen to individual complaints and,
through volunteer efforts, attempt to help members of the public with civil liberties problems. We
prepare submissions to government, conduct court cases defending infringements of civil liberties,
engage regularly in public debates, produce publications, and conduct many other activities.

CCL is a Non-Government Organisation in Special Consultative Status with the Economic and Social
Council of the United Nations, by resolution 2006/221 (21 July 2006).

**Contact NSW Council for Civil Liberties**

[http://www.nswccl.org.au](http://www.nswccl.org.au/)
[office@nswccl.org.au](mailto:office@nswccl.org.au)
Correspondence to: PO Box A1386, Sydney South, NSW 1235


-----

The NSW Council for Civil Liberties (NSWCCL) welcomes the opportunity to make a submission to the
Department of Infrastructure, Transport, Regional Development, Communication and the Arts (the
**_Department) in regard to the exposure draft of the Communications Legislation Amendment_**
(Combatting Misinformation and Disinformation) Bill 2023 (the Draft Bill).

**1** **Introduction**

1.1 The NSWCCL acknowledges the harms caused by misinformation and disinformation,
particularly as they relate to: the erosion of trust in democratic processes; the weakening of trust
generally between and among public and private entities; and, the undermining of an informed
populace. However, the NSWCCL is concerned that the Draft Bill does not sufficiently consider
freedoms of expression and assembly, nor take into account the potential for misinformation to
be spread by means and entities that are outside the Draft Bill's scope.

1.2 This submission will comment on the Draft Bill's proposed changes to the Broadcast Services
_Act 1992 (Cth) (BSA), including submissions relating to:_

(a) the exclusion of educational providers, governments, certain electoral and referendum
content and private messages from the application of the regime;

(b) the definitions of harm, misinformation and disinformation;

(c) the determination of serious harm;

(d) the lack of appeal rights for affected individuals; and

(e) additional measures that should be considered to minimise misinformation and
disinformation on digital platforms.

**2** **Excluding some sources undermines the policy objectives of the Draft Bill**

2.1 The NSWCCL is concerned that excluding particular content from the definition of
misinformation based solely on its source risks undermining the policy objectives of the
legislation. It is our view that the key factor in determining the application of this Bill is the harm
that might be caused by the misinformation or disinformation, rather than where the
misinformation or disinformation originated from.

2.2 Concerningly, the exclusion of content authorised by government from the meaning of
misinformation carries the implication that such content is truthful by definition, without
exception. This is a dangerous proposition for any free society.

2.3 Separately, we note that authorised electoral and referendum material is excluded from the
ACMA's standard and code making powers. While we acknowledge the importance of protecting
freedom of political communication, we note that misinformation and disinformation in
democratic matters can cause significant harm and would expect this to be dealt with in a Bill of
this nature.

2.4 Similarly, the NSWCCL takes the view that content produced for accredited educational
institutions should be subject to all of the ACMA’s powers. Given the vital role that education
plays in civil society, it is imperative that mechanisms are in place to protect against situations
like those alleged to have occurred in relation to misinformation about sexual health in some
NSW schools.[1]

1 L Milligan, S Zillman and M Fallon, ABC News (31 Jan 2023, online newspaper) <https://www.abc.net.au/news/2023-01-28/opus-dei-alignedschools-praised-ahead-of-four-corners/101903470>.


-----

**3** **Private messaging services are known vectors of disinformation and misinformation and**
**it is important mechanisms are in place to minimise harm (with appropriate regard to**
**privacy concerns)**

3.1 The NSWCCL notes that the ACMA, in its report to government on the adequacy of digital
platforms' disinformation and news quality measures (the ACMA Report), observed ‘increasing
concern about the propagation of disinformation and misinformation’ through private messaging
services.[2] It took the view that including messaging services within the code, with appropriate
caveats to protect user privacy, would provide important consumer protections.

3.2 Maintaining the privacy of conversations held over private messaging services is of utmost
importance to the NSWCCL. We are pleased to see that the content of private messages will be
exempt from the scope of the ACMA’s powers. However, given the above issues highlighted in
the ACMA Report, NSWCCL is concerned that messages sent over a connective media service
will be completely excluded from the Act. While we appreciate that messages among friends
and family should not be monitored, a key means of spreading misinformation and
disinformation is through large broadcast groups with thousands of members – a very different
proposition to family groups, and one far similar to a public square.

3.3 Importantly, we note that only the content of private messages is exempt and it is open to the
ACMA to require connective media services to put in place mechanisms to prevent the spread of
misinformation and disinformation. These might include a restriction on the forwarding of
messages (as WhatsApp has previously done)[3] or the introduction of misinformation reporting
tools, as has been proposed in Europe.[4]

3.4 We strongly encourage the ACMA to take steps to ensure that connective media services which
have a private messaging function, implement mechanisms (such as those discussed above) to
combat misinformation and disinformation. Ideally, such mechanisms would be required by an
industry code, however in the absence of such requirement, the ACMA should develop a
standard to ensure these mechanisms are implemented.

**4** **The definition of harm could limit the ability of individuals to protest**

4.1 The inclusion of 'disruption of public order or society in Australia' and 'economic or financial
harms to ... a sector of the Australian economy' in the definition of harm may have a chilling
effect on the right to protest, stifling debate and freedoms of assembly and association.

4.2 Disruption of public order is a consequence of many permitted peaceful protest activities. For
example, marching on the street in a registered protest is likely to disrupt public order by
stopping traffic. Similarly, 'economic or financial harms to ... a sector of the Australian economy'
may be a desired outcome for boycott or divestment activities. For example, individuals and
organisations have called for divestment from fossil fuels, including removal of money held at
banks that invest in fossil fuel projects, which may cause economic or financial harm to the
banking and resources sectors in Australia.[5]

4.3 While NSWCCL does not condone the use of misinformation or disinformation by individual
protestors and groups, we express concern that those seeking to use protest strategies that

2 ACMA Report, p 3.
3 ‘More changes to forwarding’, WhatsApp (19 January 2021) <https://blog.whatsapp.com/more-changes-to-forwarding>.
4 Measure 17.1, 2022 Strengthened Code of Practice on Disinformation, European Commission.

5 C Grieve, 'How the global fossil fuel divestment push is testing Australia's resolve', The Sydney Morning Herald (7 March 2020, online
newspaper) <https://www.smh.com.au/business/banking-and-finance/how-the-global-fossil-fuel-divestment-push-is-testing-australia-s-resolve20200305-p5475t.html>.


-----

would disrupt the public or cause certain economic outcomes would more likely be targeted by
digital platform providers under the proposed regime. Digital platform providers could be obliged
(through a misinformation code or standard) to monitor and address content that may cause
these outcomes. It would be far more cost efficient for a digital platform provider to
algorithmically de-prioritise content including words such as 'boycott' or 'divest' than to make
determinations as to the veracity of claims made in each post. This would have a severely
detrimental effect on the ability for individuals to protest in online and physical spaces.

4.4 The NSWCCL is particularly concerned about the rights of individuals and community groups
being targeted as the Draft Bill does not provide an avenue to seek appeal from a decision of a
digital service provider that misclassifies content as misinformation (discussed further below in
section 8).

4.5 The NSWCCL submits that 'disruption to public safety and security' should be adopted instead
of 'disruption of public order or society in Australia', which would align with the current voluntary
Australian Code of Practice on Disinformation and Misinformation (Voluntary Code). In
addition, 'a sector of the Australian economy' should be removed from the list of items to which
economic or financial harms may apply.

**5** **The definition of misinformation and disinformation should not include 'harm'**

5.1 For content to be defined as misinformation and disinformation, the provision of that content
must be ‘reasonably likely to cause or contribute to serious harm’.[6]

5.2 The inclusion of the harm element within these definitions may limit the type of content governed
by a misinformation code or standard to the matters listed in the definition of harm (including
protected attributes, public order, democratic processes, health, environment, and economic or
financial concerns). In addition, the nature of the consequence (ie, the harm) resulting from the
misinformation or disinformation may not be immediately understood when first assessing the
content.

5.3 NSWCCL submits that the determination of whether misinformation or disinformation may
contribute to serious harm should be considered separately, at the point at which an action is
taken (or not) in relation to that content.

**6** **The determination of serious harm is unclear**

6.1 Serious harm is not defined in the Draft Bill, rather it provides a list of matters to be considered
when making an assessment. The NSWCCL finds that many of the considerations do not relate
to the severity of a 'harm' (as defined), but rather are concerned with whether or not the content
is misinformation or disinformation.[7] For example, whether or not the content has an attributed
source does not have bearing on the severity of damaged caused to matters listed under the
definition of harm (eg, the Australian environment or the health of Australians).[8]

6.2 NSWCCL submits that more clarity should be provided as to what constitutes a 'serious' harm
so that digital platform providers and content creators will have a better understanding of the
Draft Bill's application.

**7** **Service providers have the power to determine the seriousness of harms**

7.1 The Draft Bill proposes that the determination of 'serious harm' and the classification as
misinformation or disinformation will be made by the digital platform providers. Under this model,

6 Proposed Broadcast Services Act 1992 (Cth) (BSA) sch 9, s7(1)(d) and s7(2)(d).
7 The considerations at proposed BSA sch 9, s 7(3)(b)-(d) and (i) could be used to determine the seriousness of harm.
8 Proposed BSA sch 9, ss 2, 7(3)(g)


-----

there is no way for an individual posting content to know whether an assessment of serious
harm or classification of misinformation or disinformation has been made correctly, or indeed
whether such a determination has occurred at all.

7.2 Without an appropriate means for individuals to appeal a determination of 'serious harm' or
classification of misinformation (discussed below at section 8), the NSWCCL is concerned that
this aspect of the Draft Bill could limit public discourse with unchecked powers.

**8** **Individuals who have been adversely affected have no means to appeal a decision or**
**seek compensation**

8.1 The Draft Bill does not propose a mechanism for individuals who have been adversely affected
by the application of a misinformation code or standard to appeal a decision made (eg, if content
has been incorrectly identified as misinformation) or to seek compensation if that decision had
damaging consequences (eg, such as loss of income resulting from removal of an
advertisement). Under the proposed regime, decisions that could cause adverse effects for
individuals (ie, what is in a code and how it is applied) are largely made by private sector
entities, removing the usual checks and balances that apply to government entities (such as,
administrative and judicial review).

8.2 The Draft Bill provide examples of matters that may be dealt with by a misinformation code or
standard, which includes a digital service provider's 'policies and procedures for receiving and
handling reports and complaints from end-users'.[9] However, this is merely an example not a
requirement of the proposed regime, and it does not specify whether these are complaints of
misinformation and disinformation or complaints by adversely affected parties. In addition, the
quality of the complaints mechanism is not addressed, nor is there regard for whether or not the
digital platform provider is required to respond to or act upon a complaint made.

8.3 Once a decision is made by a digital platform provider, assuming the affected individual knows
of the decision (which is not guaranteed), the avenues by which a person may challenge this
determination, or any processes that may have been implemented to manage misinformation
and disinformation, are not clear.

8.4 The NSWCCL acknowledges that the ACMA would have power to compel information, a
document or evidence from a digital platform provider regarding misinformation and
disinformation on the service, which may include a decision made to classify and act with regard
to that content.[10] However, the ACMA is not required to seek this information upon the request
of an individual, to publish it, or to act on it. In addition, this power also falls far short of an
individual's right to make a freedom of information request from an entity like ACMA.

8.5 The Department should consider the possible adverse impacts on individuals and mitigate
against potential misuse of decision making power that is effectively incontestable by
individuals.

**9** **Combating misinformation and disinformation will require more than a reporting**
**mechanism**

9.1 Finally, the NSWCCL would like to highlight the approach of the European Council (the EC) to
dealing with disinformation. In addition to the reporting of the style contemplated by the Draft
Bill, the EC has also called for improved detection analysis and exposure of disinformation (eg,
fact checkers), the introduction of alerts on disinformation campaigns and improved societal

9 Proposed BSA sch 9, s 33(3)(i).
10 Proposed BSA sch 9, s 18.


-----

awareness (ie, education).[11] We think there is great merit in these ideas and argue that these
would provide more thorough protections than solely a reporting mechanism.

The NSWCCL hopes that this submission will be of assistance to the Department and would be happy
to participate in further discussion.

Yours sincerely,

**Sarah Baker**
**Secretary**
**NSW Council for Civil Liberties**

Contact in relation to this submission: Anne Charlton
[Email: anne.charlton@nswccl.org.au Mobile: 0400 433 743](mailto:anne.charlton@nswccl.org.au)

[11 See, for example, the EC Code of Practice on Disinformation: 2022 Strengthened Code of Practice on Disinformation | Shaping Europe’s](https://digital-strategy.ec.europa.eu/en/library/2022-strengthened-code-practice-disinformation)
[digital future (europa.eu)](https://digital-strategy.ec.europa.eu/en/library/2022-strengthened-code-practice-disinformation)


-----

