**_Submission to the Australian Department of Infrastructure, Transport, Regional Development,_**

**_Communications and the Arts_**

Feedback on Exposure Draft of the Communications Legislation Amendment (Combatting

Misinformation and Disinformation) Bill 2023

Professor Ullrich Ecker (University of Western Australia)

**_The author_**

1. My research is concerned with how people respond to misinformation and misinformation

corrections, and why misinformation sometimes lingers in memory. I have published extensively
on this topic over the last 16 years. Full biographical information at www.emc-lab.org.

2. My expertise and research findings converge on the following conclusions:

**_Understanding the fundamentals of social media_**

3. Social media are a driving factor of the “attention economy.”[1] Human attention has become a

precious commodity online with platforms vying for user engagement. Social media thus rely on
algorithmic customisation to present users with content that they find engaging, in order to
increase time on platform and exposure to advertising.

4. This creates conducive conditions for the spread of misinformation, including conspiracy

theories and other types of misleading content.[2] These types of information can be very high in
engagement potential as they are often emotive and not bound by constraints of evidence or
veracity; further, accuracy of information is of no relevance to platforms’ bottom line.[3]

**_Impact of online misinformation_**

5. Misinformation represents only a fraction of the information people are exposed to, and most of

it has small to negligible impacts on people’s beliefs, let alone behaviours. However, even small
effects can be of concern at scale. For example, during the early stages of the COVID-19
pandemic, endorsement of conspiracies and exposure to misleading information was associated
with reduced compliance with public-health measures (e.g., social distancing, mask wearing).[4]

1 Wu (2017). The attention merchants. London, Atlantic Books.

2 Note that while misinformation is sometimes framed as an “online problem,” misinformation on traditional
media—characterised in Australia by a high level of ownership concentration—is at least of equal concern.

3 Lorenz-Spreen, Lewandowsky, Sunstein, & Hertwig (2020). How behavioural sciences can promote truth and
autonomy and democratic discourse online. Nature Human Behaviour, 4, 1102-1109.
http://dx.doi.org/10.1038/s41562-020-0889-7. Kozyreva, Lewandowsky, & Hertwig (2020). Citizens versus the
internet: Confronting digital challenges with cognitive tools. Psychological Science in the Public Interest, 21(3),
103–156. https://doi.org/10.1177/1529100620946707

4 Freeman et al. (2020). Coronavirus conspiracy beliefs, mistrust, and compliance with government guidelines
in England. Psychological Medicine, http://dx.doi.org/10.1017/s0033291720001890. Simonov, Sacher, Dubé,
& Biswas (2022). The persuasive effect of Fox News: Noncompliance with social distancing during the COVID19 pandemic. Marketing Science, 41(2), 230–242. https://doi.org/10.1287/mksc.2021.1328


-----

6. The most concerning effects of online misinformation arise from its ability to influence public

debate or promote social division.[5] Vocal minorities spruiking misinformation can lead to
pluralistic ignorance, e.g. people holding an accurate majority position perceiving themselves as
in the minority, which can lead to shifts in beliefs and attitudes towards the minority position.[6]

7. There is strong evidence that once people have acquired beliefs, they often continue to rely on

them even after they are shown to be false.[7] This continued reliance on misinformation and false
beliefs can occur even when people acknowledge a correction and recognize that they have
been misinformed. This presents a barrier for retroactive fact-checking efforts, and thus
exposure prevention is key.

8. One way to respond to online misinformation is with regulation of content, which can range

from removal of information to algorithmic downranking or non-amplification, to context
enrichment (e.g., provision of relevant context, counterviews, or evidence). As a general rule,
removal is inadvisable in all but extreme cases (e.g., incitement to hatred) because of the
obvious risk of censorship.

9. That being said, I believe there is merit for some form of content regulation when it comes to

disinformation that is (i) objectively false and (ii) clearly disseminated with an intention of harm.

a. Re (i): While there is much online information (including questionable or likely

misleading information) that is neither verifiable nor falsifiable, it must be acknowledged
that there are objectively established facts (e.g., based on reliable measurement or
strong expert consensus) and, therefore, objective falsehoods.

b. Re (ii): This includes repeated dissemination of politically motivated disinformation

where a pathway to harm and/or a clear agenda can be established.

10. In more general terms, I believe there is merit in supporting platforms to be more proactive by

requiring greater transparency and openness, as proposed in the present bill. Given that social
media have become a significant source of news,[8] it seems pertinent to request platforms to
formulate and adhere to a code of conduct, and outline what steps they are taking to identify
and potentially regulate misleading content. For example, platforms can easily implement
mechanisms to create “friction” that makes engagement with and sharing of misleading content
more difficult (e.g., by requiring an additional click to view or share content deemed as likely
misleading, or by querying people to clarify their intentions). There is evidence that relatively
simple prompts can “nudge” people into being more accurate in their sharing behaviour.[9]

5 Lewandowsky, Ecker, & Cook (2017). Beyond misinformation: Understanding and coping with the “posttruth” era. Journal of Applied Research in Memory and Cognition, 6, 353-369,
https://doi.org/10.1016/j.jarmac.2017.07.008

6 Lewandowsky, Facer, & Ecker (2021). Losses, hopes, and expectations for sustainable futures after COVID.
_Humanities and Social Sciences Communications, 8, 296. https://doi.org/10.1057/s41599-021-00961-0_
7 Ecker, Lewandowsky, Cook, Schmid, Fazio, Brashier, Kendeou, Vraga, & Amazeen (2022). The psychological
drivers of misinformation belief and its resistance to correction. Nature Reviews Psychology, 1(1), 13–29.
https://doi.org/10.1038/s44159-021-00006-y
8 Schulz, Fletcher, & Nielsen (2022). The role of news media knowledge for how people use social media for
news in five countries. New Media & Society, 14614448221108956.
https://doi.org/10.1177/14614448221108957
9 Fazio (2020). Pausing to consider why a headline is true or false can help reduce the sharing of false news.
_Harvard Kennedy School Misinformation Review. http://dx.doi.org/10.37016/mr-2020-009_


-----

