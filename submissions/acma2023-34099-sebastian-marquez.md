_Sebastian Marquez_

20 August 2023

The Hon Michelle Rowland

Minister for Communications
Department of Infrastructure, Transport, Regional Development, Communications and the Arts

Online submission

Dear Minister,

**_Independent submissions on the Communications Legislation Amendment (Combatting_**

**_Misinformation and Disinformation) Bill 2023_**

I refer to the invitation for submissions on the proposed draft for the Communications Legislation
Amendment (Combatting Misinformation and Disinformation) Bill 2023 (the Proposed Bill).

The Proposed Bill is an acknowledgement that misinformation and disinformation pose a security
threat to Australia and our democracy, society, and economy and that the existing framework is
insufficient to deal with this.

Misinformation and disinformation pose an existential threat to Australian democracy. They are
fundamentally incompatible with democracy which presuppose informed participation through the
vote. The need for the vote to be freely cast and informed is fundamentally undermined by
misinformation and disinformation. The High Court of Australia has consistently expressed the view
that the implied freedom of political communications which is implicitly expressed in our
constitution protects the exercise of a free and informed choice as electors.[1]

Misinformation and disinformation are so fundamentally incompatible with Australian democracy
that it should be actively stamped out. The Proposed Bill (which goes some way to improving the
current framework) does not go far enough to address this fundamental issue.

One of the key tenets of this submission is that an appropriate regulatory scheme is one that
promote healthy and robust disclosure of information and social discussion and it does this by
providing a framework that Australians can trust and that holds bad faith actors seriously
accountable for intentionally breaching the trust placed on them. The Proposed Bill appears to be a
small step in this direction.

This submission comprises eight (8) individual submissions on deficiencies and technical concerns
relating to the Proposed Bill.

**Submission one (1): The Proposed Bill does not take suitable steps to address this deleterious issue**

The existing framework is deficient because it relies on industry to create and adopt voluntary codes
of practice to manage disinformation and misinformation. The Proposed Bill would afford ACMA the
power to create industry standards and thereby give ACMA greater influence in this regulatory
space. The concern is that this does not go far enough.

1 _Clubb v Edwards [2019] HCA 11, at [29], [235], [356]._

Page 1 of 4


-----

_Sebastian Marquez_

The Proposed Bill contains several carveouts. I refer in particular to schedule 1, section 7 and the
proposed definition for ‘excluded content for misinformation purposes’ in schedule 1, section 2.
These carveouts imply that misinformation and/or disinformation have a place in Australia society.
Of particular concern is the carveout for “professional news content”.

This submission acknowledges that it is important not to unduly restrict freedom of expression. But
for the reasons already discussed, above, there is no entitlement in a functioning democracy to
misinform or disinform. Many of the carveouts in the Proposed Bill fundamentally undermine the
purpose.

The submission is that unnecessary carveouts, such as the “professional news content” exception in
the definition of ‘excluded content for misinformation purposes, should be removed.

**Submission two (2): the Proposed Bill should introduce a blanket prohibition on the knowing**
**dissemination of misinformation and disinformation**

This submission is an extension of submission one (above).

The Proposed Bill does not outright express a view on the legality or illegality of misinformation or
disinformation. The Proposed Bill seeks to restrict the pernicious subject matter without
acknowledging the social harm that it can cause through the imposition of illegality.

We already have the benefit of a statutory provision in the Criminal Code 1995 rendering foreign
interference in the political or governmental process a serious crime. Why is it that we can
acknowledge the severity of misinformation and disinformation when it comes in the form of a
foreign threat, but not when it arrives in the form of an internal threat.

This submission is that the Proposed Bill should be amended to incorporate a new provision,
amending the Criminal Code 1995 that renders the knowing dissemination of misinformation or
disinformation a serious crime.

**Submission three (3): the expression ‘adequate protection’ in relation to division 5, subdivision A**
**should be defined**

The Proposed Bill would give ACMA the power to create and enforce an industry standard should a
code of practice be deemed ineffective in combatting misinformation and disinformation on digital
platforms.

This is an extension of the powers of ACMA in relation to broadcasting services into the digital space.
The powers in schedule 1, division 5, subdivision A of the Proposed Bill provide various
circumstances where ACMA may intercede to create industry standards. The exercise of these
powers in each case relies on an exercise of discretion by ACMA that the community is not being
provided with ‘adequate protection’.

This submission is that in interpreting if ACMA has power to make an industry standard, it would be
desirable to provide an outline of the considerations that might govern the expression ‘adequate
protection’.

**Submission four (4): section 48 is too prescriptive**

Section 48 would provide ACMA with an ability to create an industry standard if an industry code is
“totally deficient”. Section 48(6), which defines the code as “totally deficient if, and only if, the code

Page 2 of 4


-----

_Sebastian Marquez_

is not operating to provide adequate protection for the community from misinformation or
disinformation…”

By introducing an arbitrary standard for when ACMA can impose an industry standard, its powers
are unnecessarily diluted. The subject matter of the Proposed Bill is of significant national interest.
The underlying framework (for the creation of codes) already emphasises industry consultation and
feedback.

The submission is that section 48 should be discretionary and that the expression ‘is totally deficient’
should be removed and replaced with words to the effect of “may have deficiencies” so that the
mere subjective belief of ACMA is sufficient to trigger the operation of section 48.

**Submission five (5): Section 35(2)(c) in the Proposed Bill should be deleted entirely**

Schedule 1, section 35 imposes a limitation on electoral and referendum matters. It is a carveout
that precludes regulation of misinformation and disinformation it constitutes ‘authorised content’.
‘Authorised content’ is defined in section 35(2) of the Proposed Bill.

Section 35(2)(c) provides an inroad for misinformation and disinformation. It appears that the
provision exists to mitigate the risk of constitutional challenges.

The submission is that a section 51(v) or 51(xxxvii) workaround should be considered so that
misinformation and disinformation may be delegitimised at every level of political debate in
Australia.

**Submission six (6): an actionable private right should be created against entities that misinform or**
**disinform members of the Australian Public in relation to political matters**

The current framework the subject of the Proposed Bill is voluntary. The emphasis of the regulatory
scheme also appears to go toward content sharing platforms. This fails to acknowledge the root of
the problem: the content creators are the persons who generate and then seek to use content
sharing platforms to disseminate misinformation and disinformation.

The regulatory focus on content sharing providers is only part of the picture. But at the same time,
there is an acknowledgement that the regulator will never have sufficient resources to regulate
misinformation and disinformation at a broader social level due to the sheer number of private
actors.

A person that is misinformed or disinformed by an entity (corporation or individual), particularly
where this is a political matter, should have an entitlement to hold the culpable entity (content
creator) directly to account. Thus the actionable right which would necessitate a meaningful
financial penalty.

A private actionable right set within an appropriate framework would create a unique financial
disincentive that is decoupled from the ordinary regulatory scheme and that would be selfenforcing: as it shifts the costs and responsibility of enforcement to the private individual. However
for this to work the private actionable right would have to establish appropriate statutory damages
sufficient to make the exercise cost-effective.

**Submission seven (7): ‘excluded content for misinformation purposes’ (a) definition should look at**
**purpose for which it is disseminated as opposed to purpose for which it is produced**

Page 3 of 4


-----

_Sebastian Marquez_

We have previously touched on the section 2 definition of ‘excluded content for misinformation
purposes’ in respect of ‘professional news’. This submission goes to a technical issue in the definition
in subsection (a).

Subsection (a) outlines an exclusion for ‘content produced in good faith… for the purposes of
entertainment, parody or satire’. However content that is produced with a particular purpose in
mind may be later disseminated for a separate purpose. This is particularly true if the content is
disseminated by a third-party that was not responsible for its production.

Technically the exemption provided in this clause would allow the third-party to argue that because
the content was produced for an accepted purpose, its ultimate use is of no relevance.

This submission is that the definition of ‘excluded content for misinformation purposes’ (a) should
be amended to incorporate the words ‘or disseminated’ after the word ‘produced’.

**Submission eight (8): Section 7 does not deal with links to information that are misinformative or**
**disinformative**

Schedule 1, section 7(1)(a) and 7(2)(a) defines misinformation and disinformation. It refers to the
dissemination of content that contains information that is false, misleading, or deceptive. The
expression ‘content’ does not on its face extend to URL links which are a common way to share
information in the digital space.

The submission is that linking to misinformative or disinformative content can be just as harmful as
presenting the content itself. Thus section 7(1)(a) and section 7(2)(a) should be amended to
incorporate the words ‘or directs the user to’ after the words ‘the content contains’.

**Closing remarks**

The Australian Government has explored the use of voluntary codes of practice to address
misinformation and disinformation for several years. This existing framework together with the
Proposed Bill, are an explicit acknowledgement of the severity of the issue which is continuously
evolving.

The issue is fluid and adaptive, characteristics of the digital space. This makes industry managed
codes of practice and delegated powers to create industry codes a helpful solution in the short term.
However the size of the problem and its impacts on our social fabric necessitate an
acknowledgement that this is a serious issue and that it needs to have serious consequences. The
Proposed Bill leaves too much up for self-regulation. There needs to be a real, possibly existential
threat to any entity that would seek to undermine the Australian political discourse through
misinformation or disinformation. That threat cannot come from self-regulation or industry codes, it
needs to come through express amendments to the penal codes and potentially statutory civil
causes of action by persons affected.

Thank you again for the opportunity to make submissions on this matter.

Yours sincerely,

Sebastian Marquez
20 August 2023

Page 4 of 4


-----

