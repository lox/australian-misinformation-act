# New ACMA powers to combat mis- and disinformation

## Submission to the Department of Infrastructure, Transport, Regional Development, Communications & the Arts


### Friday 25 August 2023


-----

#### 1 Introduction

The Public Interest Journalism Initiative (PIJI) welcomes the opportunity to provide feedback to
the Department of Infrastructure, Transport, Regional Development, Communications and the
Arts on the exposure draft of the Communications Legislation Amendment (Combatting
Misinformation and Disinformation) Bill 2023 (the Bill).

PIJI’s interest lies in the health and long-term sustainability of public interest journalism and the
public benefit it generates for all. PIJI is platform-neutral and size-neutral with respect to news
media and with no commercial interests, our activities focus on optimal fiscal and regulatory
measures to support a diverse news marketplace and enable news media to innovate, grow and
serve in its role as a public good for the Australian community.

This submission is structured as follows:

1. Section 1 provides this brief introduction
2. Section 2 provides general comments
3. Section 3 responds to the terms of reference
4. Section 4 summarises PIJI’s recommendations
5. Section 5 summarises PIJI’s recommendations
6. Section 6 outlines how this submission was prepared
7. Section 7 provides further information about PIJI

We would be pleased to provide further comment and engage in any future consultations on
the proposed legislation.

In preparing the following comments, PIJI is guided by the key defining principles that inform all
our work: to act in the public interest; to ensure plurality of news production and neutrality of
support; and to be independent, practical and evidence-based in consideration of any option.


-----

#### 2 General comments

PIJI commends the Australian Government’s commitment to new regulatory approaches in
response to the changing market dynamics brought about by digital platforms and in
recognition of the importance of quality information and news to our democracy and broader
civil society.

The spread of online misinformation and disinformation is having a profound effect on society
and its potential harm is of great concern. Access to accurate, reliable information alongside
freedom of speech, inclusive of a diversity and plurality of views, are integral to a working
democracy.

PIJI welcomes efforts to measure and mitigate the problem through the proposed legislative
framework and to this extent, broadly supports the focus of extended Australian
Communications and Media Authority (ACMA) powers on the processes and systems of digital
platform services, rather than on assessment of individual content on digital platform services.

PIJI has previously engaged on the development and release of the Voluntary Code of Practice
on Misinformation and Disinformation (the Code), launched by the Digital Industry Group
Incorporated (DIGI) in 2021. PIJI’s submission to the Draft Voluntary Code of Practice on
Disinformation in November 2020 made several recommendations, including that the draft be
expanded to cover misinformation on platforms as well as disinformation, as subsequently
adopted. Further, PIJI recommended the promotion of public interest journalism content within
the Code as an explicit strategy to assist in combatting misinformation.[1]

While this Bill seeks to exclude professional news content from its operation, we take this
opportunity to reinforce the need for robust, news media industry standards that meet
community expectations and accommodate changing technologies, for example a disclosure
requirement on the use of generative AI in professional news content.

PIJI supports the underlying principle of the Bill for greater transparency and accountability on
how all parties regulate mis- and disinformation on digital platforms. Improved record-keeping
and reporting obligations will assist, as will information gathering powers that generate
longitudinal and publicly available data to better understand the impacts of, and responses to,
mis- and disinformation in Australia. It is important that these powers also permit aggregate
data sharing and analysis by academia, civil society and other researchers[2].

Furthermore, the fast-changing nature of digital platforms and technologies requires regulation
be built to stay fit for purpose and therefore, mandated reviews should be embedded in the
framework.

1 Public Interest Journalism Initiative. 2020. Submission on the Draft Australian Code of Practice on Disinformation.
<https://piji.com.au/wp-content/uploads/2023/07/201125-disinformation-code-submission.pdf>
2 With the explicit safeguards against sharing of private data.

2


-----

#### 3 Response to the terms of reference

##### 3.1 Definitions of key concepts

Some conceptual confusion persists around mis- and disinformation. The Bill presents different
definitions of key concepts from those used in the existing, voluntary Australian Code of
Practice on Disinformation and Misinformation (the Code). Given the Code predates the draft
Bill, we have examined the main definitions below to provide insight on issues for consideration
or clarification.

We also note some definitions that appear in other existing legislation, such as ‘digital platform
services’, may benefit from harmonisation.

3.1.1 Mis- and disinformation

The Bill defines misinformation on digital platform services as ‘content that contains
information that is false, misleading or deceptive and … which is reasonably likely to cause or
contribute to serious harm.’[3] The Code defines misinformation as ‘digital content (often legal)
that is verifiably false or misleading or deceptive...propagated by users of digital platforms...
which is reasonably likely (but may not be intended to) cause harm.’[ 4] The Bill’s coverage
therefore expands from content that ‘is’ false information to content that ‘contains’ false
information. However, it does not clarify how much of a content piece needs to be false before
the ‘contains’ standard is met i.e. does the presence of any false information that could cause
serious harm mean that content is deemed ‘misinformation’ or is there a minimum threshold?
Further clarity is sought on this point.

The Bill defines disinformation as a subset of misinformation but with the addition of ‘intent’ i.e.
where ‘the person disseminating, or causing the dissemination of the content, intends that the
content deceive another person.’[5] Under the Code, disinformation is differentiated by the
actions of the user sharing the content i.e. disinformation is ‘propagated amongst users of
digital platforms via inauthentic behaviours’,[6] meaning ‘spam and other forms of deceptive,
manipulative or bulk, aggressive behaviours’.[7] The Code’s ‘inauthentic behaviours’ seems to
exclude intentional disinformation sharing by ordinary users with mal intent within the ordinary
use of a platform. Research has shown little evidence of inauthentic behaviours spreading
coronavirus conspiracy theories, and instead, found social networks of people largely
responsible.[8]

There are conceptual and practical challenges to using ‘intent’ to differentiate disinformation
from misinformation. Bruns et al (2021) and Carson et al (2021) have observed that the same
false, misleading or deceptive content can move between mis- and disinformation, both of
which result in the further spread of harmful content, regardless of whether it was intentional

3 Exposure draft. Communications Legislation Amendment (Combatting Misinformation and Disinformation) Bill 2023. Schedule
1.7.1 p. 12
4 Code of Practice 3.2B; 3.6 p. 5-6.
5 Ibid. Schedule 1.7.2 p. 12
6 Code of Practice 3.2B; 3.6 p. 5-6.
7 Code of Practice 3.5 p. 6.
8 Bruns, A., Harrington, S. & Hurcombe, E. 2021. Coronavirus Conspiracy Theories: Tracing Misinformation Trajectories from the
Fringes to the Mainstream. Communicating COVID-19: interdisciplinary perspectives, p. 229 – 249.

3


-----

or not.[9] [10] The establishment of a user’s intrinsic motivations for sharing content also cannot be
determined from an assessment of content alone. Significant investigative resources are
required and even then, findings may prove inconclusive as to the intent to deceive. The Bill’s
guidance note does not provide instruction on how intent will be verified. Further, the Bill’s
explicit reference to intent ‘to deceive’ does not take into consideration other intentions, such
as causing confusion or undermining trust.

The Bill characterises both mis- and disinformation against a likelihood of causing or
contributing to serious harm. Indeed, it sets out information powers and code and standard
powers as applicable to mis- and disinformation as interchangeable terms with the exception of
Subclause 35(1)(a) in relation to unauthorised electoral or referendum content. The guidance
note acknowledges this general interchangeability of terms.

Various ideas were explored through PIJI’s consultations with academia (see Section 6) on the
difficulties associated with verifying intent – the primary factor for determining disinformation
from misinformation. Given a key regulatory objective is to strengthen measures against the
circulation of harmful content, the focus on harm with the intent behind harmful content less
relevant for the purposes of the Bill, was discussed. PIJI is supportive of the approach suggested
by the Digital Media Research Centre at the Queensland University of Technology that looks to
remove the distinction between misinformation and disinformation from the Bill and instead,
‘make the central criterion whether the continued circulation of content could cause or
contribute to serious harm.’[11] PIJI believes this may be a more practicable and refined approach
that emphasises action against the harmful content, over action against the actors spreading
such content. While both elements are important to address, PIJI agrees with QUT that faster
responses to harmful content should be a priority, which this approach may help facilitate.

As QUT also notes, the adoption of this streamlined definition in the Bill does not preclude
related industry codes or standards from considerations of intent in measures taken against
harmful content and the actors who disseminate such content. It is reasonable to apply
proportional measures that distinguish between malicious, bad faith actors and social media
users who unintentionally spread misinformation.

In the event separate definitions of misinformation and disinformation are retained in the Bill,
PIJI recommends that guidance be developed on how intent is established and operationalised
under the Bill and that this guidance be released for public consultation prior to the passage of
these powers. PIJI also notes that unauthorised electoral or referendum content may be subject
to different powers, depending on whether it is assessed as misinformation or as
disinformation.[12]

9 Ibid. p. 249.
10 Carson, A, Gibbons, A. & Phillips, J. B. 2021. Recursion theory and the ‘death tax’ Investigating a fake news discourse in the
2019 Australian election. Journal of Language and Politics, 20(5), p. 696 – 718.
11 Queensland University of Technology Digital Media Research Centre. Submission in response to the exposure draft of the
Communications Legislation Amendment (Combatting Misinformation and Disinformation) Bill 2023. p. 3 (Draft).
12 Guidance note. Attachment 2. P. 29.

4


-----

Recommendations

1. Provide more guidance on the applicable ‘contains’ false information standard within the
definition of misinformation.

2. Consider the removal of the distinction between misinformation and disinformation in the Bill
but retain the concept of ‘intent’ in measures for harmful content and actors circulating harmful
content.

3. If separate definitions of mis – and disinformation are maintained, develop guidance on how
user intent will be established and operationalised and release this guidance for further public
consultation. Provide additional guidance around the instances where mis- and disinformation
are covered differently under the new ACMA powers.

3.1.2 Harm

The Bill adopts the term ‘serious harm’ (Clause 2), where the dissemination of misinformation is
reasonably likely to either ‘cause or contribute to’ serious harm as distinct to the Code’s
narrower harm standard[13] that addresses misinformation reasonably likely to ‘cause’ harm.[14]

The Bill also broadens the categories of people and things that can be harmed from the Code.
The guidance note outlines different types of harm including hatred according to protected
attributes such as race, gender or sexual identity, religious beliefs or health.[15] As an example, it
is unlikely that most Christian religious beliefs in Australia are ‘marginalised or vulnerable’ as per
the Code’s protection[16], but these appear protected from serious harm under the draft Bill. We
suggest some consideration be given to whether hatred or vilification is the appropriate term
according to existing legal frameworks, such as the Racial Discrimination Act 1975[17], Racial and
Religious Tolerance Act 2001 [Vic][18] and that consistent language be adopted accordingly.

Another type of harm, the ‘disruption of public order or society’[19] in Australia appears to greatly
expand the ‘public safety and security’ category[20] from the Code of Practice. The example of
serious harm that is provided against this type of harm is ‘misinformation that encouraged or
caused people to vandalise critical communications infrastructure’, which would appear to refer

13 Code of Practice 3.4 p. 6.
14 Code of Practice 3.2C; 3.6C p. 5-6.
15 Guidance note 2.1.2 p. 11
16 Code of Practice 3.4B p. 6
17 Racial Discrimination Act 1975 <https://www.legislation.gov.au/Details/C2016C00089>
18 Racial and Religious Tolerance Act 2001 <https://www.legislation.vic.gov.au/in-force/acts/racial-and-religious-tolerance-act2001/011>
19 Guidance note 2.1.2 p. 11
20 Code of Practice 3.4B p. 6

5


-----

to a spate of arsons of 5G mobile towers[21] due to conspiracy theories.[22] PIJI supports this
example of a misinformation-caused, serious harm as actionable, however, it does not clearly
align with the presented type of harm. Are telecommunications towers ‘public order or
society’? That term could be interpreted far beyond critical infrastructure, potentially into social
and political issues. Some further consideration may be necessary for the terminology of this
harm type to avoid overreach into social and political issues not related to protected attributes
or democratic processes and institutions.

PIJI notes and supports the inclusion of democratic processes, public health, and the
environment as types of harm covered under the Bill, as well as coverage of ‘economic or
financial harm to Australians, the economy or a sector of the economy’.

Recommendations

4. While supportive of the expanded definitions of harm, determine language around hatred
and vilification that is consistent with existing legal frameworks.

5. Exclude social and political issues not related to protected attributes or democratic processes
and institutions from the Bill.

3.1.3 Instant messaging messages

The challenge of responding to mis- and disinformation in instant messaging services while
preserving a user’s reasonable expectation of privacy remains.

Our understanding of the Bill is that instant messaging services fall under the category of
‘connective media services’, which are within scope of the proposed new powers. However, the
content of encrypted private messages, meaning ‘an instant message sent using a digital
platform service from one end-user…to one or more other end-users…where the message is
only observable to end-users…selected by the sender or any of the recipients,’[23] is out of scope.
PIJI notes the increased use of instant messaging services as larger-scale distribution platforms
beyond their original function.[24] We echo concerns of a La Trobe University submission that the
guidance note needs to provide definitions for key terms such as ‘group’, ‘social media’ and
‘publicly open conversation’.[25]

21 See Alexander H. 2021. Police investigate fire at Vaucluse phone tower. It turns out it wasn’t 5G. Sydney Morning Herald. 20
October. <https://www.smh.com.au/national/nsw/police-investigate-fire-at-vaucluse-phone-tower-it-turns-out-it-wasn-t-5g20211019-p591cf.html>; Yim N. 2022. Telstra tower vandalism deprives flood-stricken town of service. news.com.au. 18 March.
<https://www.news.com.au/national/nsw-act/crime/telstra-tower-vandalism-deprives-floodstricken-town-of-service/newsstory/f47d7e756d758618ecc089d181009a44>
22 Satariano A. and Alba D. 2020. Burning cell towers, out of baseless fear they spread the virus. New York Times. 10 April.
<https://www.nytimes.com/2020/04/10/technology/coronavirus-5g-uk.html>
23 Exposure draft. Communications Legislation Amendment (Combatting Misinformation and Disinformation) Bill 2023. Schedule
1.7.1 p. 7
24 A case study in Indonesia published by Carson and Fallon (2021) shows instant messaging services being used to spread
misinformation on a larger distribution sale, prompting Facebook (owner of WhatsApp) to limit the number of people to which a
message can be forwarded to.
25 La Trobe University. 2023. Academic feedback on an exposure draft of the Communications Legislation Amendment
(Combatting Misinformation and Disinformation) Bill 2023. p. 4.

6


-----

Recommendations

6. Consider the definition of ‘connective media services’ with regards to the use of instant
messaging services as larger-scale distribution platforms.

7. Provide further definition on key terms such as ‘group’, ‘social media’ and ‘publicly open
conversation’.

##### 3.2 False information that isn’t misinformation

The Bill grants the ACMA powers to gather information and make records about the prevalence
of false, misleading or deceptive information that may not be ‘seriously harmful’ and therefore
does not meet the definition of misinformation. The guidance note explains this as an additional
metric necessary to make complete assessments of false information.[26] PIJI noted during the
development of the voluntary Code that ‘the accumulation of small amounts of misinformation
disseminated over time can culminate in serious threats to the democratic process and
community safety.’[27] PIJI also promoted transparency around Code record-keeping and
reporting as a key accountability measure, which would also produce a longitudinal, evidencebase to better inform policy. However, this proposed expansion of the ACMA’s informationgathering powers from misinformation to any information that is false, misleading or deceptive,
warrants further examination as to its exact purpose and to avoid any regulatory overreach. The
inclusion of some examples in the guidance note may assist understanding.

Recommendations

8. Examine the necessity for the proposed expansion of the ACMA’s information-gathering
powers from misinformation to any information that is false, misleading or deceptive. If
necessary, include examples in the guidance note to assist understanding.

##### 3.3 Professional news content 

As expressed in PIJI’s submission to the Draft Voluntary Code of Practice on Disinformation in November
2020, the production and distribution of high-quality, public interest journalism is essential to the
functioning of a democratic society, and as an antidote to the spread of mis- and disinformation harmful
to that goal.

PIJI emphasises the role of improving visibility of public interest journalism in combatting online mis- and
disinformation and points to news quality as a separate but related issue to this Bill.

We welcome the proposed Bill’s definition of ‘professional news content’ as ‘news content produced by a
news source who is subject to certain rules and has editorial independence from the subjects of the news

26 Guidance note. Footnote 2. p. 15.
27 Public Interest Journalism Initiative.. 2021. PIJI concerned by disinformation code. Media release. <https://piji.com.au/pijimedia-releases/piji-concerned-by-dis-misinformation-code/>

7


-----

source’s news coverage’.[28] We note and support the intention to exempt news content for the purposes
of misinformation, provided certain criteria are met by the Australian professional news organisations
that produce the content, consistent with the professional standards test in the News Media and Digital
Platforms Mandatory Bargaining Code Act 2021. Analogous rules and editorial standards apply for
international professional news producers on exemption of content. PIJI recommends the definition of
professional news businesses be strengthened with the addition of an external complaints process to the
professional standards test, a criterion repeatedly recommended by PIJI although yet to adopted under
the Bargaining Code.[29]

Robust, professional news industry standards are needed to address the challenges of mis- and
disinformation. News production is held accountable to professional standards, regulation and public
scrutiny. It plays an essential part of any effort to improve the quality of digital information ecosystems.
Such standards should also meet community expectations and accommodate changing technologies, such
as a disclosure requirement on the use of generative AI in professional news content. Improvements to
news industry standards can be undertaken separately, given the Bill’s specific focus on the processes and
systems of digital platform services.

Recommendations

9. Adopt the proposed definition of professional news content but add the oversight of an
external complaints process to the professional standards test.

#### 4 Regulatory framework review

The digital platforms and the spread of mis- and disinformation are changing rapidly as are market
conditions. Technologies including generative AI continue to emerge and evolve. It is essential the
regulatory framework remains fit-for-purpose. To do so will require a mandated review after a specified
time period, such as after an initial 12 months.

PIJI also recommends that any related codes and industry standards are required to undergo
mandatory review for their effectiveness and any unintended consequences within a short time
frame after enactment.

Recommendations

10. Any regulated frameworks, codes and industry standards require a mandated review after a
specified time period.

28 Guidance note. p12.
29 Public Interest Journalism Initiative. 2022. Review of the News Media and Digital Platforms Mandatory Bargaining Code.
<https://piji.com.au/wp-content/uploads/2023/05/nmbc-review_piji-submission_may-2022.pdf>

8


-----

#### 5 Summary of recommendations

1. Provide more guidance on the applicable ‘contains’ false information standard within the
definition of misinformation.

2. Consider the removal of the distinction between misinformation and disinformation in the Bill
but retain the concept of ‘intent’ in measures for harmful content and actors circulating harmful
content.

3. If separate definitions of mis – and disinformation are maintained, develop guidance on how
user intent will be established and operationalised and release this guidance for further public
consultation. Provide additional guidance around the instances where mis- and disinformation
are covered differently under the new ACMA powers.

4. While supportive of the expanded definitions of harm, determine language around hatred
and vilification that is consistent with existing legal frameworks.

5. Exclude social and political issues not related to protected attributes or democratic processes
and institutions from the Bill.

6. Consider the definition of ‘connective media services’ with regards to the use of instant
messaging services as larger-scale distribution platforms.

7. Provide further definition on key terms such as ‘group’, ‘social media’ and ‘publicly open
conversation’.

8. Examine the necessity for the proposed expansion of the ACMA’s information-gathering
powers from misinformation to any information that is false, misleading or deceptive. If
necessary, include examples in the guidance note to assist understanding.

9. Adopt the proposed definition of professional news content but add the oversight of an
external complaints process to the professional standards test.

10. Any regulated frameworks, codes and industry standards require a mandated review after a
specified time period.


-----

#### 6 Preparation of this submission

In preparation of this submission, PIJI has engaged with industry, government agencies and academia
including participation in the Department’s briefing session on July 7, 2023, and the Digital Industry
Group Inc. and University of Technology Sydney hosted Mis- and disinformation: content moderations
and policy approaches on July 27, 2023. We also thank the following organisations for their comment:

Australian Associated Press
Copyright Agency Limited
Croakey Health Media
Google Australia
Department of Politics, Media and Philosophy, La Trobe University
Digital Media Research Centre, Queensland University of Technology
Centre for Media Transition, University of Technology Sydney

2


-----

#### 7 About the Public Interest Journalism Initiative

The Public Interest Journalism Initiative (PIJI) is a specialist think tank advancing a sustainable
future for public interest journalism in Australia. Through our research and advocacy, we seek
to stimulate public discussion and establish optimal market pre-conditions in investment and
regulation that will sustain media diversity and plurality in the long term.

PIJI is a registered charity with the ACNC under the charitable category of ‘advancing education’
(ABN 69 630 740 153). It is a philanthropically funded, non-profit company limited by guarantee
governed by a Board of independent directors, advised by an Expert Research Panel and Policy
Working Group and regulated by the ACNC, ATO and ASIC.

Board of Directors
Professor Allan Fels AO (Chair)
Virginia Haussegger AM (Deputy Chair)
Eric Beecher
Richard Eccles
Leslie Falkiner-Rose
Mette Schepers
Professor Simon Wilkie

Policy Working Group
Richard Eccles (Chair)
Professor Allan Fels AO
Virginia Haussegger AM
Professor Simon Wilkie

Expert Research Panel
Professor Derek Wilding (Chair), University of Technology Sydney
Associate Professor Jason Bosland, University of Melbourne
Professor Axel Bruns, Queensland University of Technology
Professor Andrea Carson, La Trobe University
Associate Professor Andrew Dodd, University of Melbourne
Professor Kristy Hess, Deakin University
Professor Sora Park, University of Canberra
Dr Margaret Simons, University of Melbourne
Professor Glenn Withers AO, Australian National University

Project team
Anna Draffin, Chief Executive Officer
Gary Dickson, Head of Research
Maia Germano, Research Coordinator

3


-----

CONTACT US

Public Interest Journalism Initiative
ABN 69 630 740 153

info@piji.com.au
www.piji.com.au

@piji_journalism

linkedin.com/company/public-interest-journalism-initiative

/publicinterestjournalisminitiative


-----

