### c) TikTok

TikTok Australia

Level 10, 68 Pitt Street

Sydney, NSW 2000, Australia

Pauline Sullivan

First Assistant Secretary

Online Safety, Media and Platforms Division

###### Department of Infrastructure, Transport, Regional Development, Communications and the Arts

By email: I

Copied to:

Director, Information Integrity Section, Platforms and News Branch

Online Safety, Media and Platforms Division

###### Department of Infrastructure, Transport, Regional Development, Communications and the Arts

By email

Dear Ms Sullivan,

###### Communications Legislation Amendment (Combatting Misinformation and Disinformation) Bill 2023

We welcome the opportunity to provide feedback on the exposure draft of the _Communications_

_Legislation_ _Amendment_ _(Combatting_ _Misinformation_ _and_ _Disinformation)_ _Bill_ _2023_ (the draft Bill).

TikTok is the world's leading destination for short-form mobile video, and is home to a community of

over 8.5 million Australian users and more than 350,000 Australian businesses. As a founding

###### signatory of the Australian Code of Practice on Disinformation and Misinformation, TikTok shares the

Australian Government's commitment to combating mis- and disinformation, and welcomes the

Government's statements in support of strengthening the voluntary code arrangements currently in

place. The feedback contained in this submission is intended to add to the comments and

recommendations provided by our industry association, the Digital Industry Group Inc (DIGI), into

whose submission we have provided input.

While misinformation is not a new phenomenon, misinformation law remains novel. Many of its core

concepts are inherently contestable, or involve making difficult trade-offs over which reasonable

people can and will disagree. For platforms such as TikTok, keeping our global community of users

both safe and vibrant is important work that requires our team of 40,000 Trust & Safety professionals
###### to strike the right balance between enabling free expression and preventing harm.


-----

### c) TikTok

###### in light of the Government's focus on ensuring digital platform providers have robust systems and

measures in place to address these issues on their services, we have also taken this opportunity to

provide an update, contained in Part 2 of our submission, on TikTok's continued efforts to keep our

###### community and our platform safe from harmful mis- and disinformation. As industry participants in

Australia's successful existing misinformation code, and as global platforms currently tackling the

propagation of harmful misinformation at scale, the digital industry has important experience and

expertise for Government to draw upon as it approaches this important area of law reform.

We trust that the feedback we have provided will assist the Government in its deliberations and again

extend our thanks to the Department for its open and collaborative approach to the consultation

process to date.

Yours sincerely,

Ella Woods-Joyce

Director of Public Policy

###### TikTok Australia and New Zealand


-----

## © TikTok

##### I TikTok Australia's Submission on the Communications Legislation Amendment
###### (Combatting Misinformation and Disinformation) Bill2023

 1. Strengthening Australia's industry code

Our feedback on the draft Bill has been informed by our experience as a signatory of Australia's

existing voluntary misinformation code framework, _the_ _Australian_ _Code_ _of_ _Practice_ _on_ _Disinformation_

###### and Misinformation (the Australian code). Now in its third year of operation, the Australian code is a
 blueprint for addressing the complex and multifaceted challenge of harmful online mis- and

disinformation at scale. At the core of the framework are the signatories' commitments under the

code to:

###### • publish and implement policies on misinformation and disinformation;

 • provide users with a way to report content against those policies; and

 • implement a range of scalable measures that reduce misinformation's spread and visibility.

Each signatory has also agreed to publish annual transparency reports about those efforts to improve

understanding of both the management and scale of mis- and disinformation in Australia, in addition

###### to opt-in commitments that platforms adopt where relevant to their business model.

The eight major technology companies that together comprise the signatories of the code represent

a diverse array of platforms and businesses, from news and content aggregation services to hardware

manufacturers, e-commerce marketplaces and entertainment apps, each with their own unique

service offering and risk profile. As the Government considers options for future reform in this field,

maintaining the flexibility, transparency and principles-based approach that have been hallmarks of

###### the voluntary Australian code will help ensure that regulation keeps pace with new technologies as
 they emerge, that the rules are relevant and adaptable to diverse platforms, and that our digital

economy continues to foster innovation and free expression while protecting Australians from harm.

To this end, and noting the Government's statement that "the [draft] Bill seeks to incentivise and

strengthen the voluntary framework" currently in place, we would welcome further clarification from

Government regarding the status and future of the Australian industry code, including whether

Government wishes for DIGI to apply to the ACMA for the current code to be registered, and whether

its intention is to eventually supersede the voluntary code via one of the mechanisms available to

Government in the draft Bill.

###### 2. Departures from the existing Australian code should be supported by evidence

While we appreciate the Government's expressions of support for the existing voluntary framework,

we note that a number of the draft Bill's key definitions depart from those contained in the Australian

code. To the extent that the draft bill departs from Australia's existing misinformation framework in

3


-----

# c TikTok

how it defines core concepts, we would welcome clarification from Government on the rationale for

doing so.

###### Of particular note are the draft Bill's definitions of "disinformation" and "harm". In the case of

 "disinformation", we note that the draft Bill has defined this as misinformation that is intentionally

disseminated with the intent to deceive or cause serious harm. By contrast, the existing Australian

code distinguishes between mis- and disinformation by reference to whether the verifiably false,

misleading or deceptive content "is propagated amongst users of digital platforms via Inauthentic

Behaviours". "Inauthentic Behaviour" is further defined as including:

_spam_ _and_ _other_ _forms_ _of_ _deceptive,_ _manipulative_ _or_ _bulk,_ _aggressive_ _behaviours_ _(which_ _may_

_be_ _perpetrated_ _via_ _automated_ _systems)_ _and_ _includes_ _behaviours_ _which_ _are_ _intended_ _to_

_artificially_ _influence_ _users'online_ _conversations_ _and/or_ _to_ _encourage_ _users_ _of_ _digital_ _platforms_

_to_ _propagate_ _Digital_ _Content._

In our view, the existing Australian industry code's focus on harmful misinformation propagated via

inauthentic behaviours should be preserved in any future legislation. This would provide a clearer

legislative basis for digital platforms to take action against content which exhibits the observable

features of inauthentic behaviour, rather than requiring them to speculate about the state of mind of

individual platform users. It is also a definition that signatory platforms have already demonstrated

can be operationalised and reported against in a meaningful way, and would enable continuity of

reporting for participating signatories to the industry code.

With respect to the proposed definition of "harm", we note that the exhaustive list of captured conduct

set out in s 2 of the draft Bill includes "(a) hatred against a group in Australian society on the basis
###### of ethnicity, nationality, race, gender, sexual orientation, age, religion or physical or mental disability".

While we agree that combatting hate speech is a legitimate public policy goal, just as we prohibit

hateful speech and behaviour in our Community Guidelines, we would query whether the draft Bill,

which is confined to addressing certain categories of "false, misleading or deceptive" information, is

###### the best vehicle for accomplishing this goal.

 3. Free speech-preserving safeguards should be enshrined in legislation

We note that the guidance material released alongside the draft Bill refers to a number of free speech­

preserving safeguards, including:

          - that the ACMA "would have no role in determining truthfulness", and will instead "focus on

ensuring digital platform providers have systems and measures in place to combat

###### misinformation and disinformation on their services which pose a risk of serious harm";

          - that the ACMA will adopt a "graduated approach" to exercising its proposed new powers; and

          - that Government intends for the regulator to "generally use the minimum power or

###### intervention necessary to achieve compliance".

4


-----

# c TikTok

We agree with Government that the proper focus of any harmful mis- and disinformation framework

should be on ensuring platforms have strong integrity measures in place, rather than assuming the

role of "arbiter of truth". We also agree that the law must contain robust safeguards and strike an

###### appropriate balance between protecting Australians from harm while ensuring strong protections for

privacy and free speech. As a general principle, the public should not have to rely upon the maturity

or discretion of the regulating authority to have confidence that their rights will be protected. For this

reason, we are concerned at the extent to which the draft Bill appears to rely on the regulator's

subjective judgement alone in determining whether its significant powers may be exercised, rather

than enshrining objective safeguards and criteria that must be satisfied in the text of the legislation.

For example, while the guidance material stipulates that the ACMA will be able to request an industry

code "where voluntary efforts provide inadequate protection and the ACMA is satisfied that it is

necessary to address systemic issues in relation to misinformation or disinformation on digital platform

services", s 38(3)(a) of the draft Bill provides that, in addition to addressing systemic issues, the

regulator may also make such a request if it considers it "necessary _or_ _convenient"to_ "prevent or

respond to misinformation or disinformation on digital platform services".

Similarly, while the guidance material only contemplates that the regulator will exercise its power to

develop a mandatory industry standard "in the event of industry failing to develop a code, or if a code

is failing to protect Australians", and only "as a last resort", s 50 of the draft Bill provides that the

ACMA may determine a standard to respond to "emerging circumstances" where it is satisfied that:

          - it is "necessary or convenient" to do so in order to provide adequate protection for the

###### community;

          - that "there are exceptional and urgent circumstances" justifying such a determination; and

          - that "it is unlikely that a code dealing with that matter or matters could be developed...within

a reasonable period in the circumstances".

In the absence of objective criteria that must be satisfied before the regulator can claim that

"exceptional and urgent circumstances" exist to warrant a standard, it is unclear what, if any, legal

limitations exist that would prevent the regulator from bypassing the "graduated approach" that

Government clearly intends to implement.

In our view, empowering the ACMA to impose a code or standard whenever it deems it "convenient"

###### to do so is overly broad, and does not accurately reflect the Government's stated intention for the

regulator to "generally use the minimum power or intervention _necessaryto_ achieve compliance." We

would also welcome clarification from Government as to how it envisages that the ACMA will be able
###### to deem it "necessary or convenient" to respond to misinformation on a digital platform service

 without first determining the truthfulness or otherwise of individual pieces of content on that service.

In order to more closely align the draft Bill with the Government's stated intention for the code- and

standard-making provisions to function as genuine "reserve powers", the ACMA should first be

required to satisfy objective, legislated criteria in order to compel platforms to regulate legal speech

5


-----

# c TikTok

via a code or standard, rather than merely forming a view that exercising its power would be

"necessary or convenient" in the circumstances. While we note that the ACMA has described its

intended approach to regulation through its Statement of Intent, generally speaking, we do not

consider unenforceable statements of this nature, or broad references to regulatory priorities, to be

a sufficient legal safeguard against the risks to freedom of expression that could result from their

misuse at some point in the future.


-----

## © TikTok

##### II Our work to keep our community and our platform safe

We treat misinformation with the utmost seriousness and take a multi-pronged approach to stopping

###### it from spreading, while elevating authoritative information and investing in digital literacy education to help get ahead of the problem at scale. Set out below is a detailed summary of the policies,

partnerships and other initiatives we have progressed to counter misinformation and coordinated

inauthentic behaviour on our platform.

###### 1. Our misinformation policies

The rules and standards for using TikTok are set out in our Community Guidelines. Within these

guidelines, our Integrity and Authenticity policies prohibit content that could mislead our community

###### about civic processes or that may cause significant harm to individuals or society. For instance, we

do not allow misinformation about voting, or content that undermines public trust in civic institutions

and processes such as elections and scientific bodies. These policies can be applied to a wide range
###### of content, and that's by design; this content is constantly changing, often based on what's happening

in the world.

###### At TikTok, a combination of technology and more than 40,000 safety professionals based in Australia

and across the world work together to enforce our Integrity and Authenticity policies and our broader

###### Community Guidelines. To do this effectively at scale, we continue to invest in technology-based

flagging as well as human moderation. However, we also recognise that misinformation is different

###### to many other content issues. Context and fact-checking are critical to consistently and accurately

enforce our Misinformation policies. So while we use machine learning models to help detect potential

misinformation, ultimately we rely on our moderation teams to assess, confirm and remove

###### misinformation violations.

We have more than a dozen fact-checking partners around the world that review content in over 40

languages. All of our fact-checking partners are accredited by the International Fact-Checking

Network as verified signatories of the International Fact-Checking Network's code of principles. In

Australia, our fact checking partners are al es (AAP), Australia's only

independent newswire service.

Along with our policies prohibiting harmful misinformation, we also remove content and accounts that

involve spam, fake engagement, impersonation or coordinated inauthentic behaviour, such as the

use of multiple coordinated accounts to exert influence and sway public opinion while misleading

individuals, our community or our systems about the account's identity, location, relationships,

###### popularity or purpose.

We know there is no finish line when it comes to building a safe and secure platform for our users,

which is why we continually work to improve our tools and settings with safety and user experience

7


-----

# c TikTok

in mind. Over the past year, we undertook the most comprehensive updates to our Community

Guidelines to date, to strengthen our rules and respond to new threats and potential harms. Key

changes we've made include:

          - Advancing our rules for how we treat synthetic media, which is content created or modified

by AI technology, including through dedicated policies to support moderation efforts where

###### content is detected or reported;

          - Adding 'tribe' as a protected attribute in our hate speech and hateful behaviour policies; and

          - More detail about our work to protect civic and election integrity, including our approach to

###### government, politician and political party accounts.

 2. Election integrity and political accounts

TikTok has long prohibited political advertising, including both paid ads on the platform and creators

being paid directly to make branded content. We apply these restrictions at both an ad policy and an

account level. This means accounts belonging to politicians and political parties will have their access

###### to advertising features turned off, which helps us to more consistently enforce our strict policies.

These restrictions are complemented by our policies regarding state-affiliated media, which we apply

###### where there is evidence of clear editorial control and decision-making by members of the state. We

use the policy to label accounts run by entities whose editorial output or decision-making process is

subject to control or influence by a government, providing context and transparency around

###### information sources to TikTok users.

However, we also recognise that there will be occasions where governments may need access to our

ad services, such as to support public health campaigns. We will continue to allow government

organisations to advertise in those and similar circumstances, working alongside a TikTok

representative to ensure compliance with our strict platform integrity policies.

To ensure potential misinformation can be addressed in a timely way during periods of heightened

political activity in Australia, TikTok has established dedicated escalation channels with the Australian

Electoral Commission (AEC) and State and Territory electoral commissions. During the 2022 Federal

Election, TikTok worked with the AEC to deliver our in-app election guide. The guide promoted the

importance of enrolling to vote, and provided detailed, authoritative information on the election

process, including information on where and how to vote and preferential voting explainers developed

by the Commission.

Along with Microsoft, TikTok is a founding signatory to the Electoral Council of Australia and New

Zealand (ECANZ)'s Statement of Intent concerning election management arrangements with social

media and other digital services companies (online platforms). The Statement is designed to support

Australian electoral management bodies and online platforms to address breaches of Commonwealth,

State and Territory electoral-related laws and breaches of online platforms' terms of service related
###### to electoral integrity.

8


-----

## © TikTok

###### 3. Transparency and misinformation reporting

As noted above, TikTok Australia is a founding signatory to the _Australian_ _Code_ _of_ _Practice_ _on_

_Disinformation_ _and_ _Misinformation._ Over the life of the Code, we have been active participants in the

associated reporting processes, including through engagement with the ACMA. Our three

transparency reports under the existing code are available online, and provide considerable additional

###### information about our approach to mis- and disinformation on our platform.

In addition to our reporting under the _Australian_ _Code_ _of_ _Practice_ _on_ _Disinformation_ _and_

_Misinformation,_ _we_ also publish quarterly Community Guidelines Enforcement Reports to provide

regular updates and insights into the volume and nature of content and accounts removed from our

###### platform. Our most recent Community Guidelines Enforcement Report for Q1 2023 provides a detailed

summary of a range of issues related to authenticity and platform integrity, including detected spam

account activity, fake engagement and covert influence operations.

As well as publishing detailed periodic enforcement reports, in order to give outside experts and

policymakers an insight into how our safety teams go about the day-to-day work of moderating

###### content on our platform, we provide virtual and in-person tours of our Transparency and

Accountability Centre. These tours provide an opportunity for participants to see up close how we

moderate and recommend content, TikTok's user privacy and platform security measures, as well as

###### our source code and how our algorithm operates. We have one such centre currently operating in

 the United States, with another centre in Singapore under construction. We would welcome the

 opportunity to provide DITRDCA and the ACMA with a tour of the centre, as has already been

undertaken by a range of Australian Government officials and parliamentarians.

We are continually working to build on our transparency efforts, and to improve ease of access to

public and anonymized data about content and activity on our platform and our moderation system.

In 2022, we announced a range of updates and initiatives to support this goal. This includes providing

API access to research the TikTok platform. We've also continued to build on our efforts to provide

###### our community with additional transparency around our recommendation system, including through

 the introduction of a 'why this video' tool, building on a range of existing features that enable our

users to understand and make adjustments to their experience on TikTok.


-----

