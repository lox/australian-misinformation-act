Australian Feminists for Women’s Rights (AF4WR) welcome the opportunity to provide
input into this Review of the legislation governing ACMA. We are a feminist group whose
object is research-based advocacy on women’s rights.

In preparing this submission, we have consulted, in addition to the Communications
Legislation Amendment (Combatting Misinformation and Disinformation) Bill 2023:
Exposure Draft (hereinafter the Bill), the following documents:

  - Guidance Note and Fact Sheet accompanying the Bill

  - Digital Platforms Inquiry: Final Report (ACCC, 2019)

  - A Report to government on the adequacy of digital platforms’ disinformation and

news quality measures (ACMA, 2021)

  - Relevant legislation in other comparable jurisdictions.

We also attempted to consult the Attorney General’s 2023 Report of its Review of the 1988
Privacy Act, but were unable to access the documents via the website.

We focus on three key, and somewhat related, problems with the proposed legislation:

1) The omission of sex as a protected category in Schedule 9, Part I(2): Definition of

_harm;_

2) the conceptual vagueness of the terms harm and hatred; and
3) the potential of the Bill to place limits on freedom of information and expression.

**1. Omission of sex as a protected category**

In Schedule 9, Part I(2) ‘Definitions’, the Bill offers the following definition of harm to mean
‘any of the following’:

(a) hatred against a group in Australian society on the basis of ethnicity, nationality,
race, gender, sexual orientation, age, religion or physical or mental disability;

(b) disruption of public order or society in Australia;

(c) harm to the integrity of Australian democratic processes or of Commonwealth,
State, Territory or local government institutions;

(d) harm to the health of Australians;

(e) harm to the Australian environment;

(f) economic or financial harm to Australians, the Australian economy or a sector of
the Australian economy.

Some elements of this definition, which is referred to throughout the Bill, are problematic
and we will return to another major problem area below, but the first of them is the inclusion
of gender and sexual orientation but not of sex. Misogyny continues to have material impacts
on Australian women’s lives—that is, the lives of people of female sex—whether we are
talking about:

  - the pay gap (women earn 87 cents for every $1 earned by men [Workplace Gender

Equality Agency 2023]) ;

  - sexual violence and sexual harassment (one in three women experience physical

violence and 22% experience sexual assault [ABS 2023]);

________________________________________________________________________
P.O. BOX 497 MARRICKVILLE NSW 1475 info@af4wr.org


-----

  - the significantly higher risk of living in poverty (ACOSS 2023);

  - discrimination in health care (such as the alarming rate of obstetric violence in

Australia [Keedle et al 2022]); or

  - simply the everyday impacts of prejudice against women in our culture.

It is because of this misogyny and its deleterious material consequences for women, which
range from everyday humiliation to assault and indeed death (one woman per week murdered
in Australia by a current or former partner), that the 1979 UN Convention on the Elimination
of all forms of Discrimination Against Women (CEDAW) was drawn up and signed,
including by Australia. Women experience these acts of violence and discrimination not
because of gender, which is a social construct, but because of their sex, as CEDAW clearly
states: in fact, the sex-role stereotypes we understand as gender are identified by CEDAW as
instrumental in discrimination against women (UN 1979, Article 5).

Moreover, in the current political context, sex and gender identity are coming into conflict as
concerns, among other things: the right to freedom of expression and to protected spaces;
freedom from vilification, harassment and violence; health; and child welfare. The conflation
of both sex and gender identity under the non-defined term gender presumes a common
interest between women (that is, people of female sex) and people with a gender identity
(usually known as transgender). This is far from being the case, as is evidenced by often
heated public debate over such matters as the transgendering of children; access of malebodied people with a “woman” gender identity to, among others, women’s hospital wards,
toilets and changing rooms, domestic violence shelters, women’s sports, and prisons; and
even over whether sex is a biological reality or a persona one individually identifies into.

If one of the Bill’s main objectives is to protect specific rights constituencies as established
by the UN treaties to which Australia is a signatory, then the term gender must be replaced by
the terms sex and gender identity, and Australia’s other human rights instruments (such as, it
is hoped, a future Federal Human Rights Act) must concurrently provide guidelines for
addressing actual or perceived conflicts of rights.

**2. The conceptual vagueness of the terms harm and hatred**

In its 2021 Report, ACMA raised concerns that

the scope of the [existing voluntary] code is limited by its definitions. In particular, a
threshold of both ‘serious’ and ‘imminent’ harm must be reached before action is
required under the code. The effect of this is that signatories could comply with the
code without having to take any action on the type of information which can, over time,
contribute to a range of chronic harms, such as reductions in community cohesion and a
lessening of trust in public institutions (ACMA 2021, 3).

The notion of ‘chronic harm’ is an interesting one and worthy of reflection. Its cumulative
impact is, however, difficult to assess, as women the world over who deal with everyday
sexism, including humiliation, marginalisation and vilification can attest. The cumulative
effect of such everyday sexism can have extremely deleterious, even debilitating, even fatal,
impacts on women, yet how to address it has never met with full consensus among either
political or civil society actors, or even, for that matter, among feminists.

This does not mean that nothing can be done, but it is not certain that the problem can be
addressed by penalising every instance of displays of such sexism (for example, wolf


-----

whistles and catcalls), even if such displays can reasonably be assessed as contributing to a
pattern of chronic harm to women. What is needed is a much broader ranging and more indepth culture change, and it is not certain that immediate censorship of all sexist remarks,
albeit desirable from a feminist-utopian point of view, will get that job done effectively. For a
start, who would decide what is sexist and what is not, and what is sexist enough to warrant
censorship? In any case, as we discussed above, sex is not considered a protected category in
the current draft of the Bill, so the argument is perhaps moot at this stage.

What, then, would constitute ACMA’s ‘tipping point’ at which presumably milder ‘harms’
become ‘chronic harms’ that undermine community cohesion and lead to a lessening of trust
in public institutions? And who would make that assessment? And is suppression of
information and opinions that might be deemed to lead at some stage to ‘chronic harm’ the
correct instrument to address the problem? In our view, it is a rather blunt instrument, of
which one should be wary.

We again refer to the above-cited definition of harm (the term serious harm is also used
elsewhere in the Bill but the difference between harm and serious harm is not specified). The
term is defined to mean ‘hatred’ without further qualification. Yet, ‘hatred’ on its own is not a
sufficient criterion for establishing harm, as, first, it is impossible to identify and define in
any meaningful or legally sustainable way, and second, it is not reasonable to submit simple
_emotions to sanction. In comparable jurisdictions such as the EU or the US, and indeed,_
following the guidance provided by the UN itself, ‘hate speech’ must do more than be
hateful:

Addressing hate speech does not mean limiting or prohibiting freedom of speech. It
means keeping hate speech from escalating into something more dangerous,
particularly incitement to discrimination, hostility and violence, which is prohibited
under international law (UN Secretary-General António Guterres, May 2019).[1]

Simply defining harm as ‘hatred’ does not contain this element of incitement to ‘something
more dangerous’ such as discrimination or violence. It is worrying that the Bill does not
include this element, because it leaves the way open, first, to vexatious complaints, which at
the very least are time-wasting. In this respect, we are reassured to note that both the
Australian Human Rights Commission and the Federal and High Courts have set a high bar
for demonstration of ‘insult’ or ‘harm’ with regard to the Racial Discrimination Act, as noted
in several submissions to the 2016 Inquiry concerning this Act, in particular its Clause 18(C).
That said, the thing about movable bars is that they are, precisely, movable, and while AHCR
case history and the case law of the country’s highest courts encourage confidence, there is
nothing to stop ideological interpretations of vaguely worded laws creeping in with regard to
specific types of complaint or complainant.

The second opening created by this minimalist definition wherein production of an emotion
(hatred) is provided as the sole defining evidence of harm, is for ideologically-driven agendas
to be pushed. Already, we have seen social media platforms use algorithms as a blunt
instrument to apply ideologically-defined ‘community standards’ in censoring the posts of
individual users. To cite a recent example, in July 2023 a Facebook group related to a class
taught by a US academic on ‘Privilege: Race, Class, Gender and Nation’ was disabled by

1 https://www.un.org/en/hate-speech/understanding-hate-speech/hate-speech-versus-freedom-of-speech.
Accessed 24 July 2023.


-----

Meta because it ‘did not follow community standards’.[2] Even if the platforms themselves
rather than individuals or groups using them are targeted by the Bill, the platforms may, in
response to the proposed increases in ACMA powers to target misinformation and
disinformation, set up even more ridiculously restrictive algorithms to censor users (see also

[3] below).

More generally, statements of scientific fact can and currently are framed as ‘hateful’ and
thus, according to the Bill’s proposed definition, ‘harmful’ by some groups, such as the fact
that humans cannot change sex. A Bill that fails to exclude statements of fact from its
interpretation of ‘harm’ and ‘hatred’ has serious flaws.

As for the term serious harm, used several times in the Bill, it is not defined at all. If harm is
something that causes ‘hatred’, then is serious harm something that causes some extreme of
hatred? And how serious is ‘serious’? Without more rigorous or even intelligible definitions
of these terms, it is impossible to understand where, exactly, the bar might be set for
assessing misinformation or disinformation.

**3. The potential of the Bill to place limits on freedom of information and expression**

The above discussion leads to our third concern, that of limitations on freedoms of
information and expression. Although the Bill makes it clear that individuals are not targeted,
but digital media and social platforms themselves, there is nothing in the Bill to stop such
platforms using the law to set their own restrictive ideological agendas involving censorship
of individuals, in a country that currently has weak legal protections of freedom of opinion
and expression. A positive reading of the Bill could suggest that digital platforms could be
required to be more transparent and accountable to users concerning the algorithms used to
censor certain opinions, but our experience suggests the contrary will be the case.

Our concerns are reinforced by the fact that there is nothing in the Bill to stop the government
itself pushing an ideological agenda, because unfortunately, governments are also frequently
agents of misinformation and disinformation, the recent Robodebt affair being but one
example. It is arguable, even demonstrable, that a proportion of existing legislation and
regulations at federal, state and local levels is driven by ideology rather than hard evidence:
laws are only ever as good and as neutral as those who make and apply them. The fate of
laws on women’s reproductive rights is a case in point. Exempting all Australian
governments and educational institutions including their accredited foreign partners from the
scope of this Bill means misinformation and disinformation from these sources provides
these actors an undeserved appearance of legitimacy. It is a cornerstone of democracy that in
our digital world, the government itself be open to public scrutiny and diverse critiques, and
be held accountable for the information it provides.

In its February, 2023 submission to the Senate Select Committee on Foreign Interference
through Social Media, the Australian Human Rights Commission (AHRC) raised concerns
with regard to the potential for harsher crackdowns on misinformation and disinformation to
place unreasonable limits on freedoms of information and expression. ‘[I]f we fail to ensure
robust safeguards for freedom of expression online,’ the AHRC warned, ‘then the very
measures taken to combat misinformation and disinformation could themselves risk
undermining Australia’s democracy and values’ (AHRC 2023, 8–9). It further warned of

2 Judith Ezekiel, personal communication (ironically, via Facebook), 26 July 2023.


-----

dangers inherent in allowing any one body—be it government, a government taskforce,
or a social media platform— to become the sole arbiter of ‘truth’. There is a real risk
that efforts to combat online misinformation and disinformation by foreign actors could
be used to legitimise attempts to restrict public debate, censor unpopular opinions and
enforce ideological conformity in Australia. All efforts to combat misinformation and
disinformation need to be accompanied by transparency and scrutiny safeguards to
ensure that any limitations imposed upon freedom of expression are no greater than
absolutely necessary and are strictly justified (AHRC 2023, 9).

AF4WR shares this concern, given our experience of federal or state governments, as well as
social media platforms, having intervened on several occasions to shut down public debate in
a range of areas, whether we are speaking of the raft of post-9/11 anti-terrorism and antisedition legislation or of the current wave of censorship of views critical of the ideology of
gender, accompanied by vilification and even potentially actionable defamation of the
individuals expressing such views, by media and political actors alike.

We are keenly aware of the extent to which certain individuals and organisations can
intervene in digital platforms to influence public opinion through disinformation campaigns.
The Russian trolls and bots and Cambridge Analytica scandals are two of the most notorious
examples, but we have also seen the influence of social media contagion in spreading
disinformation among young people, impacting severely on their self-image and mental
health. We thus do not contest the need to address such disinformation, but we are not
convinced that the Bill provides sufficient counterbalancing protections of freedom of
information and expression through the sorts of scrutiny and safeguards the AHRC suggests.

Once again, we are concerned that the Bill as it stands is likely to multiply the already large
number of blunt instruments restricting freedom of expression on digital platforms, at times
idiosyncratically and at times, it would appear, for deeper ideological reasons.

**References**

ABS (Australian Bureau of Statistics). 2023. Personal Safety, Australia. Data release, 15 March.

https://www.abs.gov.au/statistics/people/crime-and-justice/personal-safety-australia/latestrelease. Accessed 6 August 2023.

ACCC (Australian Competition and Consumer Commission). 2019. Digital Platforms Enquiry. Final

Report. Canberra: ACCC.

ACMA (Australian Communications and Media Authority). 2021. A report to government on the

adequacy of digital platforms’ disinformation and news quality measures. Canberra, Melbourne
and Sydney:L ACMA.

ACOSS (Australian Council of Social Services) and UNSW (University of NSW). 2023. Poverty in

Australia 2023: Who is Affected. Sydney: ACOSS.

AHRC (Australian Human Rights Commission). 2023. Inquiry into the risk posed to Australia’s

democracy by foreign interference through social media: Submission to Senate Select Committee
on Foreign Interference through Social Media. Sydney: AHRC.

Keedle, Hazel, Warren Keedle and Hannah G. Dahlen. 2022. Dehumanized, Violated, and Powerless:

An Australian Survey of Women's Experiences of Obstetric Violence in the Past 5 Years.
_Violence Against Women, 30 November. https://doi.org/10.1177/10778012221140138._

United Nations. 1979. Convention on the Elimination of all forms of Discrimination Against Women.

https://www.un.org/womenwatch/daw/cedaw/cedaw.htm. Accessed 3 May 2023.

Workplace Gender Equality Agency. 2023. Media release. 23 February.

https://www.wgea.gov.au/newsroom/media-release-national-gender-pay-gap-february-2023.
Accessed 6 August 2023.


-----

