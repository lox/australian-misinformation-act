### S U B M I S S I O N 

 Submission to the Department of Infrastructure, Transport, Regional Development, Communications and the Arts

# Submission to the Communications Legislation Amendment (Combatting Misinformation and Disinformation) Bill 2023 Exposure Draft

## 6 August 2023


**The Australian Academy of Technological Sciences and Engineering (ATSE) is a Learned Academy**
**of independent, non-political experts helping Australians understand and use technology to solve**
**complex problems. Bringing together Australia’s leading thinkers in applied science, technology**
**and engineering, ATSE provides impartial, practical and evidence-based advice on how to achieve**
**sustainable solutions and advance prosperity.**


-----

An ongoing flood of misinformation and disinformation through online platforms risks damage to Australian
democracy, institutions and society. ATSE applauds the Australian Government for seeking mechanisms to
stymie the flow of misinformation[1] online rather than entrusting this to voluntary industry codes of practice.
[ATSE’s joint 2022 submission with the Australian Academy of Science to the Australian Code of Practice on](https://www.atse.org.au/research-and-policy/publications/publication/atse-and-aas-submission-to-australian-code-of-practice-on-misinformation-and-disinformation-acpdm-2022-review/)
Misinformation and Disinformation recommended better inoculation mechanisms and the inclusion of
professional news content with the scope of the code. These recommendations would go a long way to
strengthening Australian resistance to misinformation.

Misinformation belief is fed by trust in the source of misinformation and by a lack of trust in those providing
accurate information (Butler & Ecker, 2023). It is therefore crucial that reforms designed to tackle
misinformation are seen publicly to build trust in the Government’s response and are effective at limiting
misinformation from trusted sources and support individuals to identify misinformation. The reforms should
also be expanded to include traditional media sources, which can both amplify and produce misinformation.

ATSE makes the following recommendations:

**Recommendation 1: Engender trust in the legislation by providing clear, plain-English guidelines for the**
legislated industry standards that details when they will be enforced and limits on their powers.

**Recommendation 2: Amend the legislation to ensure researchers at Australian universities have access to**
data collected by ACMA under the legislation.

**Recommendation 3: Use industry guidelines to prioritise measures that increase friction for spreading or**
accessing misinformation.

**Recommendation 4: Include private messaging services within the scope of code of practice and industry**
standards powers of the Act, subject to controls to prevent the invasion of user privacy or weakening of
encryption.

**Recommendation 5: Expand ACMA powers to enable enforceable industry standards on traditional media**
sources, including print news media.

**Recommendation 6: Implement media literacy training within schools to help students learn how**
misinformation is used and how to detect it.

#### Ensuring trust in Australia’s misinformation controls
Trust is a central factor in determining whether corrections of misinformation are believed and continue to
influence beliefs and behaviour (Butler & Ecker, 2023). Trust in social media companies and the
government is already low in Australia compared to other institutions and is falling (Edelman, 2023), so it is
essential that legislation designed to tackle misinformation does not undermine what trust remains. This is
reinforced by the fact that Australians are particularly concerned about misinformation from the government
and politicians (O’Neil & Jensen, 2020).

The scope of the proposed ACMA powers, while limited in targeting the content or encryption of private
messages and authorised content relating to elections and referenda, provide little guidance on what may
be included in industry standards or codes of practice. This vacuum of information makes scaremongering
regarding these changes easy to manufacture, reducing trust and endangering the efficacy of measures to
combat misinformation. This presents a risk that this legislation could be perceived as government
overreach, as seen by some recent commentary (e.g., Chandler, 2023; Down & Ison, 2023).

Governments overseas have given themselves vast powers to tackle misinformation that require platforms
to remove information that the government deems to be misleading[2]. This level of government interference
in communications runs counter to democratic values and may be unacceptable to Australians. It must
therefore be clear that politicians or bureaucrats in Australia will not have the power to act as arbiters of the
truth under the proposed legislation. Publishing clear language guidelines for the use of the new ACMA
powers, that outlines when the powers can be used, and how they are limited, prior to passing the
legislation may help to foster public trust in this legislation.

1 As disinformation is defined as misinformation with an intent to cause harm, this submission will collectively refer to
both as misinformation.
2 For example, the Singaporean Protection from Online Falsehoods and Manipulation Act 2019


-----

**Recommendation 1: Engender trust in the legislation by providing clear, plain-English, guidelines for the**
legislated industry standards that details when they will be enforced and limits on their powers.

#### Developing evidence-based guidelines
The data that will be collected under the proposed legislation could provide a rich resource for better
understanding and reducing the prevalence of misinformation. Allowing researchers access to what would
be the best misinformation dataset in the nation, would allow for better targeting of misinformation mitigation
strategies, facilitating a greater reduction in misinformation spread over the long term. This could be used to
build an evidence base for industry codes of practice. The advantages of giving researchers access to
misinformation data has been recognised and codified in the European Union’s Code of Practice on
Disinformation (European Commission, 2022). The European Union’s Code protects privacy by ensuring
that data is anonymised and aggregated. Australia should follow the lead of the European Union and
enshrine the right for researchers to access the data collected under the legislation.

Guidelines developed under this proposed legislation should prioritise evidence-based interventions for
reducing the efficacy and spread of misinformation online. Many social media companies now employ
techniques that flag, remove or blur potential misinformation. Crucially, these forms of correction do not
prevent users from accessing the content (reducing censorship concerns), but instead provide a key point of
friction – supporting users to identify misinformation and apply critical thinking. When implemented correctly,
these friction points can be highly effective at reducing the influence of misinformation. However, large
amounts of harmful content are often missed by these moderation techniques, and many flags simply
identify misinformation as potentially false without providing any context or refutation of the content (Butler &
Ecker, 2023). Corrections and flags need to be specific, outlining why information is wrong and providing
alternative explanations. Where possible this corrective information should be made available in-language,
as this increases trust of the information provided. Industry standards should focus on improving the content
of refutations online and ensuring potentially misleading content is appropriately flagged to establish
increased friction for users sending, receiving or accessing this content. As a broader evidence base is
developed, platforms and industry bodies should utilise this to improve their practices and guidelines.

**Recommendation 2: Amend the legislation to ensure researchers at Australian universities have access to**
data collected by ACMA under the legislation.

**Recommendation 3: Use industry guidelines to prioritise measures that increase friction for spreading or**
accessing misinformation.

#### Slowing the spread of misinformation through private messaging services
Users of private messaging services rightfully expect that their conversations will remain private. No
regulator, including ACMA, should intrude on user's privacy without proper judicial oversight. This presents
a challenge for regulators of misinformation, which have struggled to balance maintaining privacy with
tempering the ability of private messaging services to spread misinformation. For this reason, both the
existing Australian Code of Practice on Misinformation and Disinformation and the proposed legislation
have excluded private messaging services.

Despite this, actions can be taken that can slow the spread of misinformation through private messaging.
Private messaging platforms can use design elements and functionality nudges to slow misinformation
spread. For example, WhatsApp has introduced limits on the number of people a message can be
forwarded to. This change does not require the breaking of encryption or the violation of user privacy and,
while it does not stop the spread of misinformation, it has been shown to slow its spread (de Freitas Melo et
al., 2020). Such design and functionality changes have the bonus of reducing the spread of spam and
scams through these platforms. While it is critical that private messaging platforms are not treated the same
way as other digital platforms and privacy is maintained, there is a role for ACMA in ensuring industry best
practice to prevent misinformation is implemented at the design level of platforms. Private messaging
platforms should therefore be included within the scope of the Act’s powers to create codes and standards.

**Recommendation 4: Include private messaging services within the scope of code and standards powers of**
the Act, subject to controls to prevent the invasion of user privacy or weakening of encryption.


-----

#### Targeting misinformation at its source
While the recommendations above will help the proposed legislation to engender greater trust and efficacy
in regulating the spread of misinformation online, the focus solely on misinformation shared through digital
platforms misses some of the more insidious forms of malicious communications. The legislation would be
far more impactful if it were to target misinformation at the source. Dedicated fake news purveyors typically
have a very limited reach. As little as 1%-10% of the population are exposed to fake news sites, yet false
claims are often propagated through traditional (print and broadcast) media sources (Tsfati et al., 2020).
Some Australian news providers have been shown to be havens for science denialism and science
misinformation (Lowe, 2018), while other media outlets can unintentionally amplify misinformation in wellmeaning attempts to debunk it (Tsfati et al., 2020). Furthermore, it is much harder for digital platforms to
police information coming from traditional media sources, as these sources may produce a mix of
misinformation and factual information. Given this oversized role of traditional media in spreading
misinformation, any attempt to fight misinformation that does not address the role of traditional media will be
insufficient. Extending ACMA’s powers to require misinformation standards in traditional media, including
print media, will help to minimise misinformation stemming from the source most people receive it from.

To complement this, classroom training that explains the techniques and intentions of misinformation
purveyors is needed to build a media literate nation. Evidence shows that this kind of inoculation is most
effective prior to exposure to misinformation, with training after exposure not completely mitigating the
continued influence of that misinformation (Lewandowsky & van der Linden, 2021). Furthermore, this kind of
media literacy training can help to teach people to identify other types of deceptive communication practices
and improve critical thinking. It is therefore essential that students are taught to identify misinformation
techniques before exposure to misinformation. While outside the scope of the proposed legislative changes,
the Government should consider introducing media literacy training in schools to help individuals learn to
detect harmful information and engage with information online in a more sceptical manner.

**Recommendation 5: Expand ACMA powers to enable enforceable industry standards on traditional media**
sources, including print news media.

**Recommendation 6: Implement media literacy training within schools to help students learn how**
misinformation is used and how to detect it.

_ATSE thanks the Department of Infrastructure, Transport, Regional Development, Communications and the_
_Arts for the opportunity to respond to the Communications Legislation Amendment (Combatting_
_Misinformation and Disinformation) Bill 2023 exposure draft. For further information, please contact_
_academypolicyteam@atse.org.au._


-----

#### References
Butler, L. H., & Ecker, U. K. H. (2023). Misinformation in Open and Closed Online Platforms: Impacts and

_Countermeasures (pp. 279–303). https://doi.org/10.1007/978-94-024-2225-2_15_

Chandler, C. (2023). Labor’s censorship bill a threat to democracy.

https://www.senatorchandler.com.au/op_ed_labor_s_censorship_bill_a_threat_to_democracy

de Freitas Melo, P., Vieira, C. C., Garimella, K., de Melo, P. O. S. V., & Benevenuto, F. (2020). Can

_WhatsApp Counter Misinformation by Limiting Message Forwarding? (Vol. 1, pp. 372–384)._
https://doi.org/10.1007/978-3-030-36687-2_31

Down, R., & Ison, S. (2023, July 11). ‘Dangerous and Orwellian’: Tech giants and lawyers warn on Labor

misinformation bill. The Australian. https://www.theaustralian.com.au/nation/politics/dangerous-andorwellian-tech-giants-and-lawyers-warn-on-labor-misinformation-bill/newsstory/2291f419b6745bf37430945635f7eb89

Edelman. (2023). 2023 Edelman Trust Barometer Australia Report.

https://www.edelman.com.au/trust/2023/trust-barometer

European Commission. (2022). 2022 strengthened code of practice on disinformation - factsheet.

https://doi.org/10.2759/03984

Lewandowsky, S., & van der Linden, S. (2021). Countering Misinformation and Fake News Through

Inoculation and Prebunking. European Review of Social Psychology, 32(2), 348–384.
https://doi.org/10.1080/10463283.2021.1876983

Lowe, I. (2018). Climate of denial. Focus Magazine. https://www.atse.org.au/news-and
events/article/climate-of-denial/

O’Neil, M., & Jensen, M. J. (2020). Australian perspective on misinformation.

https://www.canberra.edu.au/research/faculty-research-centres/nmrc/research/australianperspectives-on-misinformation

Tsfati, Y., Boomgaarden, H. G., Strömbäck, J., Vliegenthart, R., Damstra, A., & Lindgren, E. (2020). Causes

and consequences of mainstream media dissemination of fake news: literature review and synthesis.
_Annals of the International Communication Association, 44(2), 157–173._
https://doi.org/10.1080/23808985.2020.1759443


-----

