# Submission to the exposure draft of the Communications Legislation Amendment (Combatting Misinformation and Disinformation) Bill 2023.

In Summary I suggest that this Bill fails to provide procedural fairness and denies natural justice on
several counts. The legislation ultimately provides the government to quell any opposing views and
to ensure that freedom of speech and online discussion are unfairly limited in a democratic society. It
does nothing to prevent accusations of hatred being used by some as a blunt instrument to restrict
others with different positions. In requiring platform providers to ensure compliance with codes of
practice that have non defined thresholds of harm and what is considered misinformation, the
legislation would unreasonably deny users to engage in freedom of speech expressions on these
platforms.

## Clause 7.
Disinformation only differs from Misinformation if, under 7 (2) (e) the person disseminating, or
causing the dissemination of, the content intends that the content deceive another person.

It is impossible to be clear whether a person intends to deceive or whether, in their opinion they are
trying to inform. This is more notable when there is some uncertainty over the validity of a fact.
There are so many scenarios where a member of the public, publishing on a digital service could be
considered to be providing misinformation. For example, the promotion of a product or service, or
the publication of a review of a product or service.

7 (1) (a) and 7 (2) (a) require the content to “contain information that is false, misleading or
deceptive” Note that Misinformation, as defined, includes misleading and deceptive content, even if
the publisher does not intend to be deceptive. The person publishing may be acting in good faith but
if some other person considers it to be misleading or deceptive, then the publisher could be liable
under this legislation.

7 (1) (e) and 7 (2) (e) require, for a breach that the provision of the content on the digital service is
reasonably likely to cause or contribute to serious harm. I would contend that the words
“reasonably likely to cause or contribute to serious harm” are far too loose a definition so that it
precludes anyone (unless exempt) from expressing an opinion or making a statement on anything
without potentially being accused of breaching the legislation. It is impossible for anyone making a
statement on anything to be guaranteed that their statement does not cause or contribute to serious
harm to another person. This legislation goes far beyond the legal structure of Duty of Care.

7(3) attempts to provide guidance on when content is likely to cause serious harm but in my opinion
it fails completely to give anyone making a statement any guidance.

## Definition of Harm at 2.
Harm is defined as


-----

**_harm means any of the following:_**

(a) hatred against a group in Australian society on the basis of ethnicity, nationality,

race, gender, sexual orientation, age, religion or physical or mental disability;

(b) disruption of public order or society in Australia;

(c) harm to the integrity of Australian democratic processes or of Commonwealth,

State, Territory or local government institutions;

(d) harm to the health of Australians;

(e) harm to the Australian environment;

(f) economic or financial harm to Australians, the Australian economy or a sector of

the Australian economy.

I would contend that this definition is so ill defined that it would enable anyone to claim that another
person’s statement had caused them harm. Only (a) equates harm to a person or group of people
which raises the question of who is going to accuse the publisher of causing harm? The answer
would seem to imply that the government or a government body would be the most likely accuser.

Considering (a) first, recent history shows that “hatred” is a nebulous term which allows individuals
or other groups to make the accusation of hatred as a legal weapon when there was no intent by the
accused party. This proposed legislation would give certain activists the ability to severely restrict
others who may have different beliefs or opinions from communicating with similarly minded
people. The legislation potentially will lead to extremely large amounts of litigation that cause far
more “harm” to the parties involved, with the only “winners” being the legal profession. “Hatred” is
an accusation increasingly being used by some in the community to attack others who hold differing
positions and the stricter levels of harm in libel and defamation cases should be used as a threshold
instead. Also there is no measure of relative harm between opponents (example animal activists
against sectors of the agricultural industry, where statements of each party cause harm to the other)

In (b) to (f) there is no clarification as to what level of harm is required for it to be considered that an
offence has occurred. Given the list of excluded content for misinformation purposes, discussed
below, one might reasonably assume that the government is intending to severely restrict the ability
of anyone outside the government from making any statements on a digital service that varies from
what the government of the day intends to be “not harmful”. Thus, any contrary views expressed by
others on health, the environment, economic issues or government body integrity can be silenced by
the government under this legislation. The vagueness of these terms is reminiscent of legislation in
some foreign countries that enables governments to detain its citizens for making statements or
taking actions deemed “not in the National interest”. Such legislation has no place in a democratic
nation.

## Clause 10 and the Public

Clause 10 and the definition of Immediate Circle – Telecommunications Act (s23) essentially provide
no ability for members of a community or faith organisation, and even individuals in a private group
to claim immunity from the legislation on the basis that their communication was for within the
group. This legislation will severely impede the ability of many faith practitioners to share and discuss
the beliefs that their faith upholds. Other groups would be similarly impeded from sharing and
discussing topical issues. As one example, a craft group that makes recommendations suggesting a


-----

preference for materials made overseas would be technically in breach of the legislation for
reasonably likely to contribute to severe financial harm to a sector of the Australian economy. This
example highlights again that there is no defined threshold for what constitutes harm and severe
harm. Another example might be a farmers forum that discusses the use of certain chemicals or
practices that others consider reasonably to harm the environment or the health of Australians. The
result of this legislation would be to remove such for a, potentially resulting in greater harm

## Excluded Content
This is defined at section 2 and it stands out that main publisher of excluded content is from
government bodies, professional news content and educational institutions. Thus, one of these
bodies can publish whatever information they like, and this legislation offers the parties to whom
serious harm may be done no remedy.

Professional news content only remains exempt if it
_a) is subject to specified codes of practice and_
_b) has editorial independence from the subjects of the news source’s news coverage._
This definition gives media outlets relief from the legislation provided it maintains its “editorial
independence”. Given recent cases on the independence of the media it would seem likely that if the
government became averse to material published by a news provider that it would allege the
provider was no longer independent and thus its content was no longer excluded, allowing the
government to use this legislation against the news provider. Also, this legislation would prevent any
interactive comments from readers on content platforms as feedbacks and comments are not
excluded content.

c) excludes content provided by or for an educational Institution. This exclusion would potentially
allow anyone intent on making misinformation to associate with an educational institution and use
that institution as a shield to protect them from this legislation. It would also be possible, if an
educational institution published material that the government did not agree with, for that
institution’s accreditation to be cancelled or be threatened with cancellation if the material was not
removed.

## No provision for review or appeal

The only mention of a review process that appears in the draft is

### After subsection 204(4)

Insert:

_Decisions under the digital platform rules_

(4A) Applications may be made to the Administrative Appeals Tribunal for review of

decisions of the ACMA under the digital platform rules, so long as those rules provide
that the decision is a reviewable decision for the purposes of this section.

This provision is very narrow and the legislation provides no review process for what might be

“reasonable”, “serious harm” or what constitutes harm in (a) to (f). Anyone charged
with breaching this legislation would need to engage in extensive legal advice and


-----

endure prosecution to clarify what is the threshold for an offence to occur. The only
defence that can be made is that it is Excluded Content, (a) material that is content
produced in good faith for the purposes of entertainment, parody or satire; offers other
non excluded content providers a relief if they claim their statements were for
entertainment, parody or satire.

## Onerous duties placed upon content platform providers.
The legislation may result in platforms severely limiting their users to make any statements because
any statements might contravene the legislation. The general public is in no position to ascertain the
extent of any harm that their statements might produce, and neither is the platform provider able to
ascertain the complexities of any statements made in relation to the codes. This will result in many
providers excessively restricting the content that non exempt persons can create. Platform providers
will be unable to review all created material and will of necessity have to use algorithms that filter
out harmless content or block many users from using the platform without course for appeal by the
user being blocked.

In conclusion the draft legislation appears to be missing clarity on several critical terms and gives the
government in particular inequitable powers in determining what is considered misinformation or
disinformation, while concurrently protecting itself from accusations of providing misinformation and
disinformation itself. It does not address the issue of “hatred” being used by some as a blunt
instrument to silence and attack those of different positions. This legislation, if enacted, would
excessively restrict those who are not exempt from expressing any views on an interactive forum for
fear of prosecution.


-----

