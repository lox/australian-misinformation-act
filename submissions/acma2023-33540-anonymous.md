# General comments
This law is too general, too vague, too far reaching, and essentially unnecessary. Definitions of true,
false, harm, platform and other key concepts are all either missing or extremely loose, which would
create uncertainty and room for abuse/overreach.

As it is, this Bill can make any Australian citizen who posts “outside its immediate circle” subject to
this Bill. Individuals right to freedom of speech and freedom of expression is far too important to be
infringed up on. If such a law really should exist, it should exclusively target platforms of a certain
size, never individuals. It is good that news is exempt, but the definition of news coupled to
professional news organizations is too limited and creates an odd situation where a journalist is
excluded/protected when working for a newspaper, but not if working independently. Clearly a
journalist should have the same protections regardless.

Platform providers are already monitoring and moderating content today. Creating more
transparency around the policies (and algorithms) used would be a good thing. Creating codes with
mandatory interventions subject to heavy fines risk making the platforms overly cautious, removing
“normal” material as risk mitigation.

The reporting in the bill seems aimed at monitoring the amount of mis/disinformation “out there”. A
far more valuable reporting would pertain to transparency. Requiring platforms to be transparent,
what content (categories, subjects, types) has been subject to interventions, such as removal,
algorithmic downgrading, and de-monetization, and why, would be very valuable. Start with a bill
**that requires this reporting and use the data to determine if something further needs to be done.**

Misinformation is probably a problem that needs some attention. But the solution is to create
awareness, foster critical thinking, and support open debate. Everyone should be made aware that
anything you read, hear, or see on the Internet is just like something you hear over a beer, you
should not believe anything just because someone said so! This bill is an invitation to abuse and
mechanisms to censor freedom of expression. Finally, the real antidote would be to force the big
tech companies to change their business model, by restricting what personal information they are
allowed to collect, store, use (abuse) and share. This way our privacy would be protected while
sensational posts (potentially misinformation) would not go viral. It would create an environment of
opt-in, giving the public much more control over what they see, read and hear.

**Please vote against this bill, it is not the right way forward!**

# Specific comments
If the lawmakers disagree, and think that a law like this is necessary, then it should at least be
amended before it is considered! Below are some of the points that need to addressed, but it is not
an exclusive list.

1. **What is the definition of True and False? Who decides, True or False? Must be clarified.**

a. We cannot have a government agency that can decide what is true and false. (Nor

can we leave it in the hands of private companies.)

i. It is a very dangerous idea, prone to abuse, prone to mistakes, even in the
most benevolent interpretation.

ii. **How many statements will be "acted upon" that later turns out to be true?**


-----

b. In many, or even most cases there is no such thing as clear true or false, especially

when it comes to interpretations. So, who decides? Think of scientific debate,
various hypothesis are debated, even in the STEM sciences disagreements are
abundant. Debates, especially over controversial topics must not be stifled!

c. Information can be reasonably believed to be true with one set of facts available,

but later, with additional information, it turns out to be false (and vice versa). How
does this law and codes deal with those situations, does the same information
change from being ok to being misinformation, and misinformation suddenly change
to become non-misinformation? How is harm done by interventions remedied??

2. Definitions of harm should be made clear unambiguous

a. There is no clear definition of harm.

i. There must be a clear victim of the harm. If there is, there are other laws,
like the privacy Act, defamation laws etc that can deal with the issue.

ii. If the victim is not possible to clearly define, then who would this law
protect?

b. What is the scale of harm. What is “serious” harm?

3. Exclusion of professional news content MUST be extended

a. ANY news content should be excluded (if anything really should be included…).

Journalists should be considered to be producing professional news whether they
are part of a news organization, newspaper or TV-station etc. An independent
journalist and their content should be excluded just like a journalist working for The
Australian or ABC.

b. (The fact that it will be hard to define who is a journalist is not a problem with the

fact that news should be excluded, it is a problem with the whole idea of this law).

4. If something is "wrong", how can we be sure that the best way to deal with it is through

intervention?

a. Should we ban astrology just because we know that it is a random scam, and when

people listen to their horoscope - they can be seriously harmed by making the
wrong decisions?

b. If someone believes or is borderline believing a wacky conspiracy theory, the best

promotion possible is government intervention. Seen again and again!

c. It is perfectly possible for platform service to voluntarily remove dangerous, illegal

content from their platform without this law or the registered codes, and in fact
they might be under obligations to do so under other laws

d. Competition will be hurt (including competition over ideas)!! If all platforms abide by

the same code, then in theory all platforms would "censor" or restrict the same
content. That means that if a true idea is banned on one platform, it will most likely
be banned on all other platform as well. If one platform start to restrict or promote
certain content over other (could be for commercial reasons, value based, culture
based) it is healthy that other platforms might have different policies.

5. Reporting


-----

a. Specifying detailed reporting is actually a good thing, but what is to be reported is

convoluted and non-precise in the proposed bill.

b. Suggest that the following (not exclusive list) be mandatory reporting:

1. Exactly how many content entries have been subject to what intervention,

and under what policy provisions, what topic and category.

1. Categories should be well defined, and easy to understand
2. Topics (for instance under public debate) should be easily

recognisable.

3. Sources of “complaints” should be quantified, for instance,

algorithmic detection (including AI), general public, organizations,
corporations, government, foreign government etc

4. Types of content, for instance video, audio (including podcasts), text

etc

5. This reporting should be public


-----

