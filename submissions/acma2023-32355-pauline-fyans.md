As an Australian citizen I am providing my feedback to the proposed
Communications Legislation Amendment (Combatting Misinformation and
Disinformation) Bill 2023.

**I DO NOT CONSENT to this proposed legislation.**

My concerns/questions are listed as follows:

  - The premise of the draft Bill seems to be based on misinformation

and disinformation being a growing challenge that poses a threat to
the safety and wellbeing of Australians. It also states that
_“……Misinformation is online content that is false, misleading or_
_deceptive, that is shared or created without an intent to deceive but_
_can cause and contribute to serious harm….” and that “…Serious_
_harm is harm that affects a significant portion of the Australian_
_population, economy or environment, or undermines the integrity of_
_an Australian democratic process…”. This is very vague and no_
examples of content that could be classified as
misinformation/disinformation are provided in the Bill. Can you give
examples of actual content posted in the last few years on social
media platforms that resulted in serious harm that affected a
significant portion of the Australian population?

  - What do you deem as “…a significant portion of the Australian

_population…”? Greater than 20 percent/30 percent/40 percent/etc of_
the total Australian population?

  - In terms of “…serious harm….” related to health, does this include

psychological harm also?

  - If the rules will apply to digital media platforms such as Facebook,

Tiktok, etc, which are internationally owned, how can the Australian
government dictate what international owners do? Why would they
be subject to Australian legislation? Would it be up to those platforms
to apply the scrutinization only to content posted by Australian
citizens?

  - My understanding is that the platform providers themselves must

apply whatever methods they choose to prevent and monitor
misinformation/disinformation on their platforms according to the
rules set by ACMA. How will they do this, for example:

`o` Will they have programs performing auto key

word/phrase/expression/etc searches on content published on
the platforms, with people hired by the platform provider to
manually evaluate anything highlighted by the key
word/phrase/expression/etc search results?


-----

`o` If the people hired by the platform providers to do the

monitoring and evaluation do not have expertise in the topic of
the content, how will they determine whether it is false
information or not? For example, if it is a health-related topic,
would they consult a ‘professional’ individual/organisation in
the health industry to verify the accuracy of the content? How
do we know if those they consult have the necessary ‘expertise’
to determine if content is accurate or not?

- Does content include written word posts, videos, images, sound?

- My understanding is that government bodies, approved educational

bodies, and ‘professional’ news services are exempt from the rules.
Why should they be exempt? Why should the public accept that
these entities never provide misinformation, intentionally or
otherwise? If misinformation is deemed as “……online content that is
_false, misleading or deceptive, that is shared or created without an_
_intent to deceive but can cause and contribute to serious harm…”,_
then if a professional news service disseminates misinformation but
without an intent to harm, why should they be exempt? An example
is the dissemination of information regarding the covid vaccine,
whereby governmental agencies promoted the vaccine as ‘safe and
effective’ when clearly it was not on account of the significant injuries
and deaths that occurred as an outcome. Do professional news
agencies have an obligation to tell the truth to the public, given that
most of them are privately owned organisations?

- Professional news services, just like medical services, must obtain a

license to practice and must follow their own industry rules and
regulations, which is fair enough since they supposedly have a duty
of care to the public and earn revenue from their services. But the
public are not paid for content they post on online social media
platforms, nor are they obliged to ‘serve the public’, so why should
their posts be censored? Isn’t the idea of social media platforms to
provide the public with a platform to have freedom of expression and
post whatever they like?

- Surely people should have the right to determine for themselves

what is misinformation/disinformation without a Big Brother
censoring what they can access?

- Misinformation/disinformation is already rampant throughout other

forms of communication available to the public such as
documentaries on Netflix, public speeches, lectures, etc, so are social
media platforms only being targeted? Will the next step be the
government sending representatives to these type of events to
censor content?


-----

This proposed Bill is preposterous in my opinion, for the following reasons:

    - It is infantilising the public, having the government as a parental

figure dictating what information everyone has access to for their
‘welfare’ rather than the allowing people to decide for themselves
what is misinformation and what is true or otherwise and what is
best for their welfare

    - It will shut down Free Speech and any chance for an open debate

sharing opinions that conflict with the official government narrative

    - It will lead to an atmosphere of censorship, fear and silence rather

than a healthy one of freedom of thought and expression that
Australia has been previously known for

Again, I am stating that I DO NOT CONSENT to the proposed
Communications Legislation Amendment (Combatting Misinformation and
Disinformation) Bill 2023, and I demand that it be wholly rejected.

Yours sincerely,

Pauline Fyans


-----

