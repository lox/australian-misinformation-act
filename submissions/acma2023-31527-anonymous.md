# disinformation Bill 2023

## Submission by: But use Anonymous.

### I disagree with all the proposed powers in the new Bill

 I am going to write directly on the fact sheet all of my reasoning in Red.

# Communications Legislation Amendment (Combatting Misinformation and Disinformation) Bill 2023—Fact sheet

**June 2023**

## Key points

- Misinformation and disinformation pose a threat to the safety and wellbeing of Australians, as well
as our democracy, society and economy.

- The Australian Government has released the draft Communications Legislation Amendment
(Combatting Misinformation and Disinformation) Bill 2023 (the Bill) to address this growing
challenge.

- The Bill would give the Australian Communications and Media Authority (ACMA) reserve powers to
act, if industry efforts in regard to misinformation and disinformation are inadequate I do not agree
this should occur.

- The proposed powers would:

`o` enable the ACMA to gather information from, or require digital platform providers to keep
certain records about matters regarding misinformation and disinformation

This is pointless, because they have the records anyway, once online, we all know it tends to
exist for good. So why do they need to do extra, unless they have been asked by the police?

`o` enable the ACMA to request industry develop a code of practice covering measures to
combat misinformation and disinformation on digital platforms, which the ACMA could
register and enforce

So basically this point is mute, because if ACMA disagree at any stage, then they just enforce
the next point.

`o` allow the ACMA to create and enforce an industry standard (a stronger form of regulation),
should a code of practice be deemed ineffective in combatting misinformation and
disinformation on digital platforms. So ACMA will define what they decide is the truth,
whether they are wrong or not and will enforce, by their means. There will be no way to


-----

justify what has been said, so no freedom of speech, thought or discussion. This is not
Australian…

- The ACMA will not have the power to request specific content or posts be removed from digital
platform services. Again, not Australian if there is no recourse to debate or even disagree with a
ruling. Censorship around the world has been proven multiple times to be wrong over the last 3
years. People in the UK were blocked from social media for posting about the deaths of their family
members that were caused from the vaccine. This was deemed to be misinformation, but they
even had death certificates from the government where death was said to be from the vaccine.
Many people around the world were censored for discussing their vaccine injuries. This was
disgusting behaviour and done because of governments pushing the lies.

- The Bill defines misinformation and disinformation as follows:

`o` Misinformation is online content that is false, misleading or deceptive, that is shared or
created without an intent to deceive but can cause and contribute to serious harm.

The government pushed more lies than the general public about the covid vaccines and the
threat of covid itself. The government told the public that children should get the vaccine to
protect the elderly, when they never had evidence it stopped transmission. This has been
proven to be lies, yet they continued to misinform the public for a long time.

Because of this clear misinformation, mandates were put in place that forced many to get
the jab they never needed, they were not at risk of covid. The Australian Health department
had stated ongoing research is required to determine whether the vaccines prevent
transmission or asymptomatic disease and It is not yet known how long the protection of
the COVID-19 vaccine will last.

The government intentionally misled the population into abusing people who made their
choice not to get the jabs, by calling them nasty names, lying about it being a pandemic of
the unvaccinated, saying only unvaccinated went to hospital or even died. All proven to be
lies, but people who stated this, were censored without the right to disagree.

`o` Disinformation is misinformation that is intentionally disseminated with the intent to deceive
or cause serious harm.

The jabs have caused serious harm to many people, yet the government is not taking
responsibility for putting out the misinformation of saying it stopped transmission, so
everyone should have to have it.

People were censored for saying things like, if the first 2 jabs didn’t work, what makes you
think 3 will. People ridiculed others who said that you would need to take a jab every 6
months. This turned out to be true, but was classified as conspiracy theories.

The TGA did not officially read through the any of the documents prior to approving

the vaccines, they relied on the CDC from America, who in turn relied on the Pharmaceutical
companies. This has only been released recently in Senate hearings in this country and
America. There was definitely intent to deceive, which has caused serious harm to many
people, many who are still being gaslit by the government and health departments. Many of
these people who reported injuries were deplatformed on the concept that they were
spreading misinformation or disinformation, whatever you wish to call it. They had every
right to reach out and try to find support and help from others, instead the governments
around the world have lied about what has occurred.


-----

`o` Serious harm is harm that affects a significant portion of the Australian population, economy
or environment, or undermines the integrity of an Australian democratic process.

Many others who chose not to get the jab were forced out of jobs, based on misinformation
the government pushed. The jabs did not stop transmission (this was known), but they
forced people to choose jobs or personal rights/freedom because the government lied about
it stopping transmission and infection. Even if it lowered it, they never stated how much the
risk was lowered for healthy working age people. Knowing there was no risk assessment
done for healthy working age people contracting the virus, vs getting the jab and the virus,
the mandates were unjustly forced on people based on the government misinformation.

- The powers apply to digital platform services that are accessible in Australia. Some examples
include social media, search engines, instant messaging services (although the content of private
messages will be out of scope), news aggregators and podcasting services.

- The Bill includes strong protections for privacy and freedom of speech:

`o` the Bill is directed at encouraging digital platform providers to have robust systems and
measures in place to address misinformation and disinformation on their services, rather
than the ACMA directly regulating individual pieces of content

`o` the ACMA will not have the power to request specific content or posts be removed from
digital platform services, they will just expect it to be done, or they will fine the digital
platform service, therefore they do have the power to request specific content or posts be
removed. This whole point is an oxymoron.

`o` rules made under the Bill may require digital platform services to have systems and
processes in place to address misinformation or disinformation that meets a threshold of
being likely to cause or contribute to serious harm

`o` the code and standard-making powers will not apply to authorised electoral and referendum
content and other types of content such as professional news and satire

`o` private messages sent on instant messaging services will not be within scope of the powers.

- You are invited to comment on the draft Bill before it is finalised and introduced in Parliament later
this year to ensure that it strikes an appropriate balance in protecting Australians from harm.

## Why these powers are needed

Misinformation and disinformation spread via digital platform services is a major issue worldwide. The
rapid spread of false, misleading and deceptive information online has resulted in a multitude of harms
from disrupted public health responses to foreign interference in elections and the undermining of
democratic institutions.

In 2021, the ACMA produced its Report to government on the adequacy of digital platforms’ disinformation
_and news quality measures:_

- The report noted existing efforts by signatories to the voluntary industry code (the Australian Code
of Practice on Disinformation and Misinformation) were a good first step in efforts to tackle
misinformation and disinformation on digital platform services. None of this helped, it just
convinced more people that they were right. If an argument can’t be refuted by facts, how is it
wrong? The amount of facts that were just shot down over the last 3 years by the government just


-----

calling it misinformation or disinformation is amazing. Anytime someone says something the
government doesn’t agree on, they resort to name calling and deplatforming of the person. This
does not convince anyone that they are wrong, or the government is correct.

- However, the ACMA recommended the government provide it with a graduated set of new powers
to combat misinformation and disinformation across the sector. These powers would increase
transparency and ensure that digital platform services are held to account if voluntary industry
efforts prove to be inadequate.

As a key principle, the proposed ACMA powers will support the success of the voluntary industry code
currently in place. Digital Industry Group Inc. (DIGI), the industry body responsible for the current code,
has expressed in principle support for the proposed powers outlined in the ACMA’s report.

## What’s in scope

#### Misinformation and disinformation


**Misinformation is:**



- content disseminated using a digital service that is false, misleading or deceptive; and



- the content is provided on the digital service to one or more end-users in Australia; and



- the provision of the content on the digital service is reasonably likely to cause or contribute to
serious harm; and



- the content is excluded for misinformation purposes, with that content being:



- content produced in good faith for the purposes of entertainment, parody or satire



- professional news content, who decides what is professional news? We have seen over the
last 3 years, plenty of news reporter services being censored, not allowed to do their job, ie
Rebel News, who reported on many unjust situations throughout the covid pandemic,
actually showed footage of protests, which the so-called mainstream media ignored.
Mainstream news reporters spread more misinformation, including how bad Covid was in
the first place. They used fear mongering to report facts, daily about the number of deaths,
but not once did they point out that healthy working age people were at a super low risk of
dying. They would highlight 1 death, to say all children were at risk. They did not share the
actual risk of young people, but the overall risk included old, sick, frail people, which
automatically made it look worse than what it was for the majority.

No News service should be excluded, and if you pass this bill, should be held to a higher level
or requiring proof and evidence of what they claim. The also need to stop sensationalising
and lying about stories and start telling the bare facts with out all the embellishments that
half the time, tell a different story to what occurred. They also never tell both sides of a
story, instead only telling part of it, which lying by omission is still lying.



- content authorised by the Australian or a, State, Territory or Local Government


Again, no government authority should be exempt, especially when they have told the
biggest lies, as stated above. Not once were any departments able to do a risk assessment
for a healthy working age person and Covid infection. The risk was so low, that it never
justified forcing a vaccine, that did not stop transmission or infection.

###### The main thing I disagree about the whole Bill is the fact you want to give indemnity to the
 government and mainstream media outlets. They will be excluded, and I think that they are the worse culprits. I have never been given a straight answer, the senate rarely


-----

###### provides justification or answers to questions in a timely manner, they only have a 20% compliance rate to answering questions, so at what stage are they ever going to admit that they got it wrong. They won’t even hold a royal commission which was promised. Government departments are not transparent, and they never admit when they are wrong.

 So I do not trust that the government is looking after the best interest of the people. I am
 pretty sure most Australians would agree on this. They will lie, and if they are excluded from Mis/dis information laws, then you are basically saying we might as well be China and they can say and do whatever they want. They should be held to the highest account, not no account.



- content produced by or for an accredited education provider.


NOTE: Content made in response to the above excluded types of content is not automatically also
excluded for misinformation purposes (i.e. comments on a professional news article).

**Disinformation is: basically the same as Misinformation, obviously the powers to be couldn’t decide at**
**the start what to call all of the scientific studies that proved what they didn’t want it to prove.**

- content that fulfils the criteria for misinformation;, So Disinformation is the same as
Misinformation, they are just made up words used to describe comments and ideas that went
against what the government was pushing.



- and



- the content is disseminated with intent to deceive, including through automated processes and
foreign interference. This captures content that is purposefully or maliciously disseminated
disinformation.

#### Serious harm

The proposed powers will only apply to misinformation and disinformation that is reasonably likely to
cause or contribute to serious harm. The matters that are relevant to determining whether the content is
reasonably likely to cause or contribute to serious harm are outlined in section 2.1.2 of the Guidance
Note to the Bill, and clause 7 of the Bill.

The types of ‘harms’ captured, and some examples of what could be serious harm, are set out below:


-----

**Type of harm** **Example of serious harm**


Hatred against a group in Australian society on
the basis of ethnicity, nationality, race, gender,
sexual orientation, age, religion or physical or
mental disability


Misinformation about a group of Australians
inciting other persons to commit hate crimes
against that group


Disruption of public order or society in Australia Misinformation that encouraged or caused people
to vandalise critical communications
infrastructure
So if they have evidence and justification for why
they are doing it, it’s ok?


Harm to the integrity of Australian democratic
processes or of Commonwealth, State, Territory
or local government institutions


Misinformation undermining the impartiality of an
Australian electoral management body ahead of
an election or a referendum


Harm to the health of Australians Misinformation that caused people to ingest or
inject bleach products to treat a viral infection


So when the government tells the people they
need a vaccine to stop them getting covid or
spreading covid, this should be classified as
misinformation, especially when the risks of the
jab, were clearly not shared, and peoples rights to
choose were taken away through mandates.

The fact that the majority of healthy working aged
people and people under the age of 30 were
never at risk of death in the first place, meant the
whole government continued to spread
misinformation over the last 3 years. They shared
the statistics to prove this, but never allowed the
people to make their own decisions.

People were censored for questioning lockdown
laws around the world, including Australia. There
was significant evidence and discussion about the
fact that they would cause more harm to the
health of Australians than Covid. Yet that was
counted as misinformation. People saying that we
should look at our diet and exercise levels, to
improve them and decrease our risk from
Covid/other sicknesses were labelled conspiracy
theorists. Not spreading this information for 3
years on the health department websites was also
lying by omission.

Health departments spread information that was
detrimental, telling people to stay indoors and not
get fresh air was not helpful in making peoples
immune systems strong.


Harm to the Australian environment Misinformation about water saving measures
during a prolonged drought period in a major
town or city


-----

**Type of harm** **Example of serious harm**


Economic or financial harm to Australians, the
Australian economy or a sector of the Australian
economy


Disinformation by a foreign actor targeting local
producers in favour of imported goods

Yet the government used a foreign basketballer and
actors to try and push the YES vote? This is all
misinformation produced by the government, this is
designed to impact All Australians, so foreign people
should not be weighing into the discussion at the
request of the government.


###### Would the powers address the targeting of an individual such as racist trolling? 

The proposed powers are designed to encourage digital platform services to be accountable for
improving and implementing measures to counter the spread or misinformation and disinformation
online (i.e. they have a ‘systems’ focus rather than an individual content focus).

Widespread, race-based misinformation and disinformation that caused or contributed to serious harm
would fall within the scope of the new ACMA powers.

For cases where a specific individual is subject to race-based harassment, abuse or trolling, this would be
a matter for the eSafety Commissioner to consider in the context of the Commissioner’s powers to
address adult cyber abuse under the Online Safety Act 2021. In such instances, when platforms have
failed to remove abusive content, an individual can report it to the eSafety Commissioner at
esafety.gov.au. The eSafety Commissioner has powers to require digital platform services to remove adult
cyber abuse content.

#### Digital platform services in scope

The powers would apply to a broad range of digital platform services. This includes search engines, news
aggregators, instant messaging services, social media, web-forums, dating sites, and online peer-to-peer
marketplaces.

The powers would not apply to SMS and MMS (text messages sent via mobile telecommunications
networks), email, SVODs (subscription video on demand e.g. Netflix), and BVODs (broadcast video on
demand e.g. ABC iView).

Further information about how services are defined is in section 2.1.1 of the Guidance Note to the Bill
and clauses 3, 4, 5 and 6 of the Bill.

###### Private messages

**Private messages on a digital platform service are out of scope**

The ACMA powers would not apply to direct private messages sent from one user to one or more other
users on a messaging service or social media platform or the content of a closed group conversation on a
messaging service such as a family group chat.

**Group chats open to the public on an instant messaging service will be within scope**

The content of group chats that are open to the public or public “channels” on instant messaging services
are intended to be within scope of the ACMA powers. This is also the case for posts in a forum or message
board. In these cases, digital platform services will be responsible for ensuring they prevent and respond
to misinformation and disinformation on their services.


-----

**If private messages are exempt, how will the powers apply to instant messaging services?**

While the content of private messages will be exempt from the scope of the powers, the ACMA would be
able to use its information-gathering and recording keeping powers. This is to understand the measures
that digital platforms take on their services to combat the spread of misinformation and disinformation
and to gain a better understanding of the number of complaints made about such content on their
services.

These powers will not require providers of digital platform services to reveal the contents of private
messages or have requirements related to breaking encryption of private messages.

To strengthen their ability to combat misinformation and disinformation, providers of digital platform
services may choose to have systems and processes in place such as user reporting tools, complaints
handling and educative programs to empower users. These requirements may also be articulated in
industry codes and standards made under the Bill.

Further information on private messages refer to section 2.1.3 in the Guidance Note to the Bill, and
clauses 2 and 34, and subclauses 14(3), 18(4), 19(4) of the Bill.

## How the ACMA powers will be structured

#### Information-gathering and record keeping powers

###### Record keeping rules

The ACMA would have a power to make rules requiring providers of particular digital platform services
(or classes of services) to maintain and keep records relating to:

- misinformation or disinformation on their services

- measures implemented by digital platform services to prevent or respond to misinformation or
disinformation on their services, and the effectiveness of those measures

- the prevalence of content containing false, misleading or deceptive information provided on their
digital platform services.

Digital platforms providers may be required to periodically report on this to the ACMA. This would
enhance transparency and allow tracking of digital platforms’ progress in addressing misinformation and
disinformation on their services.

###### Information-gathering powers

The ACMA would have powers to obtain information, documents and evidence from providers of digital
platform services when needed for investigating matters relating to the same type mentioned above.

The ACMA may also obtain information from other persons to assist the ACMA monitor compliance with
misinformation codes, misinformation standards and digital platform rules. They could include factcheckers or other third-party contractors to digital platform service providers. The ACMA may only do this
if it considers it requires it for its monitoring and compliance functions.

###### Publication of information

To promote transparency, the ACMA would have the ability to publish information collected under its
information-gathering and record keeping powers on its website, including the identity of the provider or
service to which the information relates.

The ACMA would not be permitted to publish personal information and will be required to consult with
impacted digital platform service providers prior to publishing any information.


-----

Further information on the above powers is in section 3 of the Guidance Note to the Bill, and clause 25 of
the Bill.

#### Code and standard-making powers

Under the framework of the Bill, the ACMA would have reserve powers to register codes and make
standards to compel digital platform service providers to act against misinformation and disinformation
on their services.

These powers would be used in the event that the ACMA determines that existing industry efforts to
combat misinformation and disinformation on digital platform services do not provide adequate
community protections.

The ACMA would have a range of enforcement powers to ensure that digital platform providers comply.
Further information on these powers is detailed below and in section 4 of the Guidance Note to the Bill,
and part 3 of the Bill.

###### Examples of matters that may be dealt with in a registered code or standard

 Code of practice registration

Should the ACMA determine that stronger action is needed to protect Australians, it could request that a
section of the industry put in place a new and more effective code of practice (than the existing DIGI
voluntary code of practice, for example). Once the ACMA is satisfied a draft code presented to it by
industry meets a number of criteria, it may register it which makes compliance with it compulsory for all
digital services providers in the relevant segment of the industry. This would include those providers who
chose not to sign up to a voluntary code.

So basically ACMA could end up censoring the whole system the same way China does. We have not
chosen to live in a communist society, but you are trying to turn it into one. I do not agree with this
occurring. If people are saying the wrong thing and it is causing harm, then reporting to the police and
prosecution on the basis that they would have to prove it has caused harm would be a better option.
There should be no censoring from any services, freedom of speech should ensure this. But if it is proven


-----

to have caused harm, like people continuing to tell someone to kill themselves, and they do, then it
should be taken to court as assisted murder…

###### Standards

In the event previous efforts through a code had not been effective, or a code was not developed, or
otherwise in urgent and exceptional circumstances, the ACMA would have the power to make an
enforceable standard.

A standard would be a determination written by the ACMA that would require digital platform providers
to combat misinformation and disinformation on their services. Such a standard would have higher
penalties than registered codes and would generally reflect a determination that previous efforts had not
been effective.

Again, disagree, as the government has proven that many of the posts that were removed over the last 3
years in relation to covid, the jabs, injuries etc, have all proven to be true, and it was unjust to have
removed them or gaslit the people with injuries, deaths.

###### Consultation

Public consultation by the industry body or association producing a code is a requirement prior to the
ACMA registering it. If the ACMA were to make a standard, appropriate consultation, would also occur
under the provisions of the Bill.

#### Enforcement

In the event of non-compliance with the information-gathering and record keeping rules, codes or
standards, the ACMA would be able to choose from a range of formal enforcement actions.

These actions would generally be applied in a graduated manner, dependent on the harm caused, or risk
of harm and could include issuing formal warnings, infringement notices, remedial directions, injunctions
and civil penalties.

Criminal penalties would only apply to digital platforms or individuals knowingly making or retaining false
or misleading records under the record keeping provisions, or giving false or misleading information or
evidence under the information-gathering provisions of the new powers.

Again, many people quoted straight facts, I was even told by government departments when questioning
the mandates, using information straight from the government website, that it was only my opinion that
they were wrong. The fact that the statistics were said to be wrong, when I cited all of my government
sources, they could not justify the mandates at any stage. The government continuously contradicted
themselves and not once were they pulled over the coals for giving false or misleading information, like
saying getting the jabs will protect others (they had no evidence it stopped transmission).

Digital platform providers can face significant civil penalties under the Bill, and it is expected that the
ACMA will actively seek penalty orders against those providers who routinely contravene provisions in a
registered code or a standard, or fail to comply with remedial directions in particular.

The maximum amount of civil penalties is intended to deter systemic non-compliance by digital platform
providers and reflects the serious large scale social, economic and/or environmental harms and
consequences that could result from the spread of misinformation or disinformation.

The civil penalties for breaches of standards are greater than breaches of codes (or information-gathering
powers) as a standard is the highest level of regulatory action in the regulatory framework.


-----

**Maximum penalties – non-compliance with**
**registered code**


**Maximum penalties – non-compliance with**
**industry standard**


Maximum of 10,000 penalty units ($2.75 million
in 2023) or 2 per cent of global turnover
(whatever is greater) for corporations or 2,000
penalty units ($0.55 million in 2023) for
individuals.


Maximum of 25,000 penalty units What is a
penalty unit, we don’t speak in units, is this a sign
of things to come, that you are already planning
to get rid of cash? ($6.88 million in 2023) or 5 per
cent of global turnover (whatever is greater) for
corporations or 5,000 penalty units ($1.38 million
in 2023) for individuals.


Further details on the enforcement mechanisms are in section 5 of the Guidance Note to the Bill.

## Protecting privacy and freedom of expression

In seeking to implement regulatory measures to ensure digital platform providers actively combat
misinformation and disinformation on their services, the government is committed to achieving a balance
that upholds the rights and freedoms of Australians whilst protecting Australians from serious harm that
can come from the spread of misinformation and disinformation.

Treating everyone like babies and being a nanny state is the same as communism. Not allowing people to
have free speech is not protecting from serious harm. You are spreading fear just to try and justify
bringing in and enforcing communist ideology.

#### Private messaging

The Bill excludes the ACMA from being able to use its information-gathering powers to require a person
to give information or evidence, or produce a document that would reveal the contents of private
messages between users.

Similarly, the ACMA cannot create record keeping rules that require digital platform providers to make or
retain records of the contents of private messages. Misinformation codes and standards will not be able
to require platforms to break encryption or to monitor private messages.

#### Freedom of expression

The ACMA would have no role in determining truthfulness, nor will it have a role in taking down or
requesting action regarding individual pieces of content. But you are saying that if people post on a
particular topic and say something that you decide is misinformation, even if there are studies and
evidence that prove what is being said is true and accurate, that it has to be taken down. This is
misleading and spreads more disinformation. Many scientists, doctors and health professionals were DE
platformed around the world because of this, even when what they had to say was true, but it went
against the vaccine manufacturers point of view.

This takes away debate, and discussion which is part of Science, so “Trust the Science” when half of it was
removed was spreading more disinformation.

If the ACMA uses its reserve code registration or standard-making powers, it will be required to consider
whether there are any potential burdens on freedom of political communication, and if so, to consider
whether they are reasonable and not excessive, in view of intended the protection from serious harms.

As proposed in the Bill, the proposed ACMA powers will:

- focus on ensuring digital platform providers have systems and measures in place to combat
**misinformation and disinformation on their services which pose a risk of serious harm.**


-----

required to be authorised.

All this says is that anything that goes against the government narrative will be removed with no
justification or chance to prove it is actually correct and true. So called Fact Checkers or Opinion
staters, were often wrong in what they removed, and there was never an avenue to prove they
were wrong. Communism in the making.

- require digital platform services to continue to be responsible for the content they host and
promote to users.

- not apply to professional news content and the other types of excluded content (noted above).

When they have been proven to lie, and not retract, this is not ok. They embellish stories at times
to the point that they are clearly not telling the truth.

The code and standard-making powers will not apply to electoral and referendum communications that
are required to be authorised.

## Complaints mechanisms

In the first instance, any online user complaints about the content on a digital platform service or the
policies and the terms of service of a platform, should be directed to the digital platform provider.

The ACMA may investigate potential breaches of codes or standards made under the Bill. Complaints
about systemic or a regular pattern of misinformation or disinformation on a service may be a trigger for
the ACMA to investigate a digital platform provider’s compliance with a code or standard.

The record keeping and information-gathering powers could also enable the ACMA to determine whether
digital platform providers’ complaints handling procedures are effective in combatting misinformation
and disinformation on their services.

The code and standard-making powers could be used to require the platforms to have policies and
procedures for receiving and handling reports and complaints from end-users.

If anything is an issue in society where it harms people, this should be dealt with by the police and courts.
But as we have seen, many arrests over the last 3 years have also been bogus and fraught with contempt
towards the people. People were charged for being out of their homes, yet this was not technically
against the law, as none of it was done legitimately.

People are not policed when they talk in public. Digital platforms are public forums and it they need to be
policed, it should be through the police,

## Interaction with the voluntary code

#### Will voluntary codes in place before the ACMA powers come into effect be automatically replaced by the new powers?

No. The Bill seeks to incentivise and strengthen the voluntary framework. The ACMA would work with
industry to ensure continuous improvement to the voluntary code which is overseen by industry.

However, should those efforts prove inadequate, the ACMA would have the option to use the graduated
set of reserve powers to ask industry to make a new, registrable code, or if necessary, the ACMA could
make a standard.

#### Will a voluntary code need to adopt the definitions in the Bill?

No. As the ACMA has no role in determining the provisions within any voluntary codes, the industry does
not need to adopt definitions in the Bill.


-----

If the ACMA were to register a code, then it would need to draw upon the Bill’s definitions.


-----

