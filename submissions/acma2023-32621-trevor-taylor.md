# Response regarding the Communications Legislation Amendment
 (Combatting Misinformation and Disinformation) Bill 2023

I, Trevor Taylor firmly uphold the belief in the indispensable nature of freedom of speech as a

fundamental human right and a cornerstone of the Australian democratic framework. It is with

utmost concern that I express my reservations about the recently introduced Communications

Legislation Amendment (Combatting Misinformation and Disinformation) Bill 2023, presented by

the Labor Party. In my view, this proposed legislation is a direct attack on freedom of speech.

I assert the following:

Subjective Definition of Misinformation: The Bill's highly subjective definition of "misinformation"

grants the government arbitrary power to determine what constitutes misinformation. This opens

the door to the suppression of legitimate criticisms of the government, questioning of scientific

ideologies such as climate change, discussing immigration strategies, gender dysphoria, the

sexualisation of children, and other important matters.

Draconian Powers of ACMA: The Bill empowers the Australian Communications and Media

Authority (ACMA) with draconian powers to silence critics of the government. It allows for fines of

up to $6.8 million to be imposed on social media platforms if, in ACMA's opinion, they have not

done enough to prevent the dissemination of what ACMA considers to be misinformation or

disinformation. This creates a chilling effect on free expression and inhibits open dialogue.

Protection of Government and Mainstream Media: The proposed Bill establishes safeguards for

government, mainstream media, and approved organizations, thereby creating an imbalance in the

treatment of different voices and viewpoints. This not only undermines the principle of equality of

speech but also reinforces a two-party system at the expense of independent media and non
government political parties.

Page 1 of 10


-----

### 1) Excluded content 

Quote:

### “2 Definitions 

**_excluded content for misinformation purposes means any of the_**
following:

### (a) content produced in good faith for the purposes of 
 entertainment, parody or satire; 
  (b) professional news content;” End Quote

On page 5, under section "2 Definitions," it is concerning to observe that "Professional News

Content" is designated as excluded from the scope of this bill. While I acknowledge that they are

subject to regulation, it is essential to strongly emphasize that in today's rapidly evolving landscape

of information dissemination, professional news outlets should unquestionably be held accountable

for the propagation of "Misinformation and Disinformation" as determined by relevant authorities,

including ACMA.

The rationale behind this perspective is that globally, a recurrent trend emerges wherein a singular

force consistently diverts attention—the driving force being none other than the economy.

Such economic influence directly equates to power and the greater the authority conferred upon a

solitary corporate entity, institution, or individual, the more we witness the erosion of genuine

freedoms. This is a sobering reality exemplified by historical instances such as the sugar industry's

misleading portrayal as "Healthy" and the eventual revelation of the cigarette industry's profound

connection to cancer.

Hence, it is of utmost importance to contest the exemption of professional news content from the

bill's purview. The information age demands robust accountability across all avenues of

communication to safeguard against the undue influence that economic motivations can exert,

ultimately protecting the integrity of public discourse and ensuring the public's right to unbiased

and reliable information.

In light of these concerns, it becomes imperative to challenge the exemption of professional news

content from the bill's scope. The era of information necessitates robust accountability across all

channels of communication, in order to guard against the potential undue influence that economic

incentives can wield. By doing so, we can ultimately uphold the integrity of public discourse and

ensure that the public's entitlement to impartial and dependable information remains intact.

Page 2 of 10


-----

Consequently, this brings to the forefront one of the principal reasons why I believe the

Communications Legislation Amendment (Combatting Misinformation and Disinformation) Bill 2023

in its current form ought to be rejected. The responsible course of action entails acknowledging the

importance of holding all information disseminators to the same standard of accountability,

irrespective of their professional stature. In doing so, we uphold the principles of transparency,

truthfulness, and the unfettered access to information that is critical for an informed and

empowered society.

### 2) Harm

Quote

**_“harm means any of the following:_**

(a) hatred against a group in Australian society on the basis of

ethnicity, nationality, race, gender, sexual orientation, age,

religion or physical or mental disability;

(b) disruption of public order or society in Australia;” End Quote

A key focal point that demands attention is the preservation of political protest as a conduit for the

exercise of freedom of speech within our nation. This sustains the essence of democracy. The

utilization of the phrase "Disruption of public order or society in Australia," however, introduces a

level of ambiguity that merits addressing.

What precisely constitutes "Public order"?

Can a political protest that opposes a viewpoint held by a substantial portion of the community be

regarded as a disruption to public order?

The crux of the matter is that maintaining the legitimacy of political protest is vital for upholding

democratic principles.

Thus, the wording in question is vague and does not ensure that legitimate avenues for expressing

dissent and seeking change remain open. And so, I believe it is vital for us as a nation to reject this

Communications Legislation Amendment (Combatting Misinformation and Disinformation) Bill 2023

entirely.

Page 3 of 10


-----

### 3) Power

Quote:

_“Specifying digital services by instrument_
(6) The Minister may, by legislative instrument, specify that a kind of
digital service is a digital platform service if the Minister is
satisfied that it is appropriate to apply provisions of this Schedule
to the digital service to provide adequate protection for the

community.” End Quote

It is crucial to highlight the potential ramifications of granting such extensive authority to "The

Minister," as this could potentially compromise the freedom of speech that is integral to our

Australian way of life. The passage on page 11 raises concerns about the potential for "The

Minister" to wield the power to silence digital platforms based on their personal opinion, all in the

name of ensuring "adequate protection for the community." This prospect demands serious

contemplation as we engage in discussions about this Bill.

The possibility of a subjective interpretation of what constitutes "satire" by some, but holds different

implications for a minister, underscores the need for careful consideration. Relying solely on an

individual opinion, without any form of consultation, runs counter to democratic principles. Similar

concerns are echoed on both page 9 and page 11 in relation to the concept of a "Digital Service,"

which "The Minister" could potentially define as per the provisions outlined in the Communications

Legislation Amendment (Combatting Misinformation and Disinformation) Bill 2023.

These sections of the Bill convey the transfer of unregulated powers to a single individual, holding

ministerial privileges. This not only grants the authority to impose restrictions but also to arbitrarily

determine exclusions as they see fit. This situation has the potential to concentrate an excessive

level of power in one person's hands, which runs contrary to the principles of transparency, checks

and balances, and democratic decision-making.

Thus, it is another of the main reasons why I think the Communications Legislation Amendment

(Combatting Misinformation and Disinformation) Bill 2023 should be rejected entirely.

Page 4 of 10


-----

### 4. Fact checkers

Quote:

### “33 Examples of matters that may be dealt with by misinformation         codes and misinformation standards 

(1) This clause sets out examples of matters that may be dealt with by

misinformation codes and misinformation standards.

(2) The applicability of a particular example will depend on which

section of the digital platform industry is involved.

(3) The examples are as follows:
(a) preventing or responding to misinformation or disinformation
on digital platform services;

(b )using technology to prevent or respond to misinformation or
disinformation on digital platform services;

(c) preventing or responding to misinformation or disinformation

on digital platform services that constitutes an act of foreign
interference (within the meaning of the Australian Security
_Intelligence Organisation Act 1979);_
(d) preventing advertising involving misinformation or
disinformation on digital platform services;
(e) preventing monetisation of misinformation or disinformation
on digital platform services;

(f) supporting fact checking;” End Quote

I strongly oppose the notion of implementing misinformation codes and misinformation standards

as outlined above. While the intention to combat misinformation and disinformation might seem

justifiable, I believe that such measures pose significant risks to freedom of expression and

innovation. Here are my reasons for opposing this approach:

1. Enforcing misinformation codes and standards could stifle innovation in the digital platform

industry. The demand for platforms to employ technology to prevent misinformation might lead to

an over-reliance on automated systems that can inadvertently flag or remove accurate content.

This could harm smaller platforms that may not have the resources to implement sophisticated

moderation technologies.

2. The examples provided in the paragraph, such as preventing foreign interference, introduce a

complex international dimension. What might be considered misinformation in one country could

be considered legitimate expression in another. Implementing these measures could strain

international relations and create a patchwork of conflicting regulations that hinder the global

exchange of information.

Page 5 of 10


-----

3. The problem here is that there is too much potential for political manipulation. The concept of

preventing advertising involving misinformation or disinformation raises concerns about who gets

to decide what misinformation is. In a politically charged environment, there's a risk that such

measures could be used to suppress information that challenges the narrative of those in power,

effectively enabling governments or corporations to control the flow of information to the public.

In conclusion, the potential for censorship, lack of clear definitions, challenges to innovation,

international conflicts, and political manipulation could all have detrimental effects on free

expression and the open exchange of ideas in the digital realm. Thus, I reject the Communications

Legislation Amendment (Combatting Misinformation and Disinformation) Bill 2023. And I still think

the Bill should be thrown out entirely.

### 5. Limitations

Quote:

## “35 Limitation—electoral and referendum matters 

(1) The ACMA must not register a code (or part of a code), or

determine a standard, under this Part that contains requirements
relating to electoral and referendum content unless:

(a) the requirements relate to preventing or responding to

disinformation on a digital platform service; and

(b) the requirements do not relate to authorised content.

(2) In this clause:

**_authorised content means:_**

(a) electoral matter (within the meaning of the Commonwealth

_Electoral Act 1918) that contains the particulars required by_
section 321D of that Act to be notified; or

(b) referendum matter (within the meaning of the Referendum

_(Machinery Provisions) Act 1984) that contains the_
particulars required by section 110C of that Act to be
notified; or

(c) matter communicated or intended to be communicated for the

dominant purpose of influencing the way electors vote in a
State, Territory or local government election or referendum
that contains the particulars required to be notified by a State

or Territory law relating to the authorisation of such matter.” End Quote

We do possess a thoroughly democratic and unified amendment or declaration outlining the criteria

this Bill must adhere to. However, it's essential to remember that this framework solely applies to

social media platforms. It does not encompass political commentary nor does it extend to

Page 6 of 10


-----

professional news content media. The scrutiny surrounding the advertisement of "yes" campaigns

in referendums, as articulated on page 31, warrants careful consideration. The provision states,

"Unless matter communicated or intended to be communicated for the dominant purpose of

influencing the way electors vote in a state, territory or local government election or referendum."

If this assertion holds true, then any campaign with taxpayer funding associated, disseminated

through social media would come under the purview of ACMA's regulation. More significantly, if

one side of a referendum, which lacks funding, is constrained in expressing their perspective, while

the funded campaign remains unrestricted, this constitutes a direct assault on our freedom of

speech. As taxpayers, we continue to uphold our entitlement to unimpeded public discourse. This

principle is what contributes to Australia's greatness. Thus, I reject the Communications Legislation

Amendment (Combatting Misinformation and Disinformation) Bill 2023. And I still think the Bill

should be thrown out entirely, it’s not needed, and it never was!

### 6. Emerging circumstances

Quote:

### “50 ACMA may determine standards—emerging circumstances

(1) This clause applies if the ACMA is satisfied that:

(a) it is necessary or convenient for the ACMA to determine a
standard that:
(i) applies to participants in a particular section of the
digital platform industry; and
(ii) deals with one or more matters relating to the operation
of digital platform services by those participants;
in order to provide adequate protection for the community
from misinformation or disinformation on the services; and

(b) there are exceptional and urgent circumstances justifying the
determination of the standard under this clause; and
(c) it is unlikely that a code dealing with that matter or matters
could be developed under this Part within a reasonable period
in the circumstances.

(2) The ACMA may, by legislative instrument, determine a standard

that applies to participants in that section of the digital platform
industry and deals with that matter or those matters. A standard

under this subclause is to be known as a misinformation standard” End Quote (page 44)

This appears to be a contingency measure, envisioning potential scenarios where developments

do not proceed as intended. This clause seems to offer the possibility of swift intervention if

circumstances begin to spiral out of control. The pivotal question to address is the purpose for

which this provision might be employed. As a minister is granted augmented authority, so is

Page 7 of 10


-----

ACMA. The origin of such decisions also requires clarity. For instance, in a situation where public

discontent is being expressed vigorously through social media, providing a platform for their

voices, who ultimately determines the necessity of intervention?

Does this decision-making authority remain within Australia's jurisdiction or does it extend to

international bodies like the United Nations?

Does the passage of this Bill potentially enable the UN and its affiliated entities to influence the

classification of misinformation and disinformation? There appears to be a critical information gap

here that necessitates attention. Moreover, while a certain topic might be deemed suitable for

dissemination on social media initially, what if circumstances change? Perhaps due to a change in

government or an international organisation's attempt to amend global regulations, the citizens of

Australia may hold a contrasting viewpoint. If their opinions are at odds with these developments,

what alternative platform would they possess to express their dissent?

My apprehension stems from the potential for suppression arising from these uncertainties and

ambiguities. And so, I reject the Communications Legislation Amendment (Combatting

Misinformation and Disinformation) Bill 2023. And I still think the Bill should be thrown out entirely.

### 7. Security Risk

Quote:

“ 7 After subsection 4(3AB)
Insert:
(3AC) The Parliament also intends that digital platform services be
regulated, in order to prevent and respond to misinformation and
disinformation on the services, in a manner that:

(a) has regard to freedom of expression; and
(b) respects user privacy; and
(c) protects the community and safeguards end-users against

harm caused, or contributed to, by misinformation and
disinformation on digital platform services; and

(d) enables public interest considerations in relation to

misinformation and disinformation on digital platform
services to be addressed in a way that does not impose
unnecessary financial and administrative burdens on digital
platform providers; and

(e) will readily accommodate technological change; and
(f) encourages the provision of digital platform services to the

Australian community; and

(g) encourages the development of technologies relating to

digital platform services.” End Quote

Page 8 of 10


-----

I must say, this proposal seems to be cloaked in good intentions, but as someone who is

concerned about the potential repercussions, I find myself strongly opposed to it. Let's break down

the elements of this provision and explore why it raises red flags.

First and foremost, the intention to regulate digital platform services to counter misinformation and

disinformation is a slippery slope. While combating false information is important, there's a fine line

between ensuring accurate information and stifling freedom of expression. The notion of having

regard to freedom of expression (as mentioned in point a) is laudable, but in practice, it might not

be enough to prevent overreach. We've seen instances where well-meaning regulations morph into

tools of censorship, and that's a path we should be wary of treading.

Moving on to point (b), respecting user privacy is a commendable objective. However, the

challenge lies in striking the right balance between regulating digital platforms and safeguarding

user privacy. History has shown that increased regulation often comes with greater surveillance

and data monitoring, potentially compromising individual privacy rights. Striving for a harmonious

equilibrium between these goals is no easy feat.

Point (c) addresses the need to protect the community and end-users from harm caused by

misinformation and disinformation. While this goal is indisputable, the problem arises when the line

between protection and suppression blurs. Regulating information to protect citizens from harm

can inadvertently result in censorship and limit access to diverse perspectives. What is classified

as "harm" can be highly subjective, and this subjectivity opens the door to arbitrary decisions that

could impact legitimate discussions.

Point (d) acknowledges the importance of not imposing undue financial and administrative burdens

on digital platform providers. However, in practice, these regulations often translate into hefty

compliance costs, particularly for smaller players in the digital landscape. Such costs can stifle

innovation and restrict the entry of new competitors, ultimately leading to reduced diversity in the

digital platform ecosystem.

Lastly, points (e) and (f) aim to accommodate technological change and encourage the provision of

digital platform services to the Australian community. While on the surface this seems positive,

rapid technological advancements can outpace regulatory measures. Additionally, encouraging the

provision of digital platform services may inadvertently create a climate where platforms prioritize

conformity over diversity, as they work to align with the regulatory landscape.

In conclusion, while the intent behind this provision might seem justifiable on the surface level,

however, if you look a little deeper it is fraught with potential risks and uncertainties. Balancing

Page 9 of 10


-----

freedom of expression, user privacy, protection against harm, and technological innovation is a

complex endeavour that often ends up compromising one aspect in favour of another. As someone

who values open discourse and individual liberties, I cannot support a provision that might

inadvertently stifle these essential elements of a democratic society.

In light of these concerns, I call on the Parliament to:

Reject the Communications Legislation Amendment (Combatting Misinformation and

Disinformation) Bill 2023, recognising that it poses a threat to freedom of speech in Australia.

Safeguard the principles of freedom of speech and expression as cornerstones of Australian

democracy, ensuring that all individuals, media outlets, and political parties are equally protected in

exercising their right to free speech.

I call on all members of Parliament to heed this petition, listen to the concerns voiced by this letter,

and act in the best interests of upholding freedom of speech and protecting the individual rights of

all Australians.

Thank you for your attention to this matter.

Sincerely,

Trevor Taylor

Page 10 of 10


-----

