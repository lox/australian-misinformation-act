# Academic feedback on an exposure draft of the
 Communications Legislation Amendment (Combatting
 Misinformation and Disinformation) Bill 2023.

## La Trobe University Submission - Professor Andrea Carson and Professor
 Lawrie Zion, Melbourne.
 August 16, 2023

**This submission was prepared by:**

**Professor Andrea Carson, Department of Politics, Media and Philosophy, School of Humanities**
and Social Sciences, La Trobe University, Plenty Rd Bundoora, Vic Australia, 3083. E.

**Professor Lawrie Zion, Department of Politics, Media and Philosophy, School of Humanities**
and Social Sciences, La Trobe University, Plenty Rd Bundoora, Vic Australia, 3083. E.

_This submission may be made public._

## About the Authors 

As way of background, Professors Carson and Zion are La Trobe University media and
communication academics in the department of Politics, Media and Communication and both
have extensive past experience working as professional journalists.

Andrea Carson is a professor of political communication and political scientist. She examines the
media's role in democracies, journalism and political communication with special interests in
investigative journalism (high quality news) and mis and disinformation (low quality information
and fake news). She is also a member of Public Interest Journalism Initiative’s (PIJI) research
advisory group. She is on Meta's Misinformation and Disinformation Global Working Group that
meets 4-5 times a year with experts from across the globe and Meta’s internal policy experts on
the subject.

Professor Carson was consulted by DIGI at various times during the development of the
Australian Code of Practice on Disinformation and Misinformation. She has undertaken specific
research on mis and disinformation and its effects in Australia and in the Asia Pacific region. Her
research work on this subject is listed at the end of this submission. Of particular note is her
studies with colleagues examining the role elected political actors and the mainstream media play
in dissemination of disinformation, which informs this submission.

Lawrie Zion is Associate Dean, Research and Industry Engagement of the School of Humanities
and Social Sciences, and Professor of Journalism. He led the recently completed ARC-funded
research project, New Beats (2014-2022), which investigated the aftermath of job loss for
journalists whose roles were made redundant.

**1 | P a g e**


-----

## Introduction

Thank you for the opportunity to contribute to this consultation.

We thank the Department for providing various occasions to respond to the exposure draft
bill through recent expert roundtables, of which Professor Carson has participated, and
through public consultation.

We commend the Department of Infrastructure, Transport, Regional Development,
Communications and the Arts on its work to combat misinformation and disinformation by
considering new Australian Communications and Media Authority (ACMA) powers to tackle
this global problem.

Firstly we want to acknowledge that we think the Minister and her department are heading in
the right direction by making the DIGI Code or its equivalents mandatory. We agree with the
Minister’s representatives that there is still further refinement to be undertaken on the draft
bill.

To that end, this submission deals with issues relating to:

_- freedom of expression_

_-definitions_

_- the complexity of content exemptions_

_- the scope of the private message exemption_

_- Other matters._

**1.** **Freedom of expression**

Australia is a highly successful liberal democracy that is based on an open society that
enables freedom of responsible speech. Public access to diverse perspectives and accurate
information in the public sphere is a prerequisite of our functioning democracy. To avoid
unnecessary censorship concerns about the Communications Legislation Amendment
(Combatting Misinformation and Disinformation) Bill 2023, we recommend a statement of
high level principles at the outset of the bill to reinforce Australia’s commitments to the value
of open, pluralistic communication in a liberal democracy.

**2.** **Definitions of misinformation and disinformation**

We know through experience that misinformation and disinformation can cause real-world
harms and this was clearly evident during the COVID-19 pandemic, when false information
about causes and treatments of the novel coronavirus led to hospitalisations and deaths in
some instances.[i] Yet, despite the gravity of the problems, there remains a lack of conceptual
clarity. Terms such as false and fake news, misinformation, disinformation, alternatives facts,
post-truth and hoaxes (common in Indonesia) are often used interchangeably sowing further
confusion about their meaning. Our past studies show that existing definitions have been
developed in “information silos”.[ii]

This is a problem as the absence of uniform definitions poses a range of challenges for
multitudinal actors tackling the problems of mis- and disinformation. It creates difficulties for

**2 | P a g e**


-----

scholars analysing political discourse, technology platforms implementing mitigation
measures, journalists in their role as gate-keepers of quality information, governments
implementing anti-fake news laws, and policy makers and civil society actors seeking to
tackle complex global problems such as racism, migration and gender discrimination that are
vulnerable to misinformation and disinformation. It is therefore critical that key actors work
together to develop policy solutions to this vexed problem of false information online. If
decision-makers cannot agree on basic definitions about what it is, then attempts to mitigate
and counter its effects may lead to poor policy implementation or, on the other side of the
spectrum, government heavy-handiness.

  - Under the draft bill, these two categories are defined in a similar way in that the

content needs to be ‘false, misleading or deceptive’ and not ‘excluded content’, and is
‘reasonably likely to cause or contribute to serious harm’. A point of difference is that
to be disinformation it must also be the case that the person disseminating it ‘intends
that the content deceive another person’.

From our studies on this topic (see publications listed below), we find the definitions are
problematic in that it is difficult to divine what one’s intention is – which is the primary
factor differentiating misinformation from disinformation.

One way to address this is to focus more on harm and where necessary to examine
motivation, operationalised by what a digital platform user’s behaviour reveals about
intention.

In this regard, the existing DIGI code does this well in its sections 3.2 relating to
‘disinformation’; 3.4 relating to ‘harm’, 3.5 relation to ‘inauthentic behaviour’ and 3.6
relating to ‘misinformation’.

We recommend better harmonisation with the existing DIGI definition and the one applied by
ACMA that will take in to account the difficulty of ‘intention’ by focusing instead on
_decisive actions that spread information that can mislead, deceive or otherwise cause_
emotional, physical, political, financial or intangible harm. These decisive actions may follow
the label that platforms use such as ‘inauthentic behaviours’. In any case, we recommend
consideration be given to operationalising the behaviours that show intent in order to
differentiate ‘disinformation’ from ‘misinformation’.

**3.** **Content exemptions**

**_Professional news_**

  - Under the draft bill the content exemptions are established partly via a concept of

‘excluded content for misinformation purposes’. This category includes professional
news; entertainment, parody and satire; content produced by certain educational
institutions; and content authorised by the Commonwealth and state, territory and
local governments.

We have some concern about the exclusion of ‘professional news’ as research shows that
mainstream media companies can perpetuate and disseminate misinformation – for example
the false claim that the ALP would introduce a ‘death tax’ in the 2019 election (see
publications list). The DIGI code currently notes that “professional news content

**3 | P a g e**


-----

disseminated by a news aggregation service is excluded from the definition of
Misinformation but may fall within the definition of Disinformation if propagated by
Inauthentic Behaviours.” We recommend that the draft bill be refined to have a similar
provision and to include professional news content if disseminated on a digital platform if
propagated by inauthentic behaviours.

**_Authorised and unauthorised electoral and referendum content_**

Similarly, we also have concerns about the different treatments in the draft bill regarding
authorised and unauthorised electoral and referendum content and how to best deal with the
interrelationship between misinformation and disinformation.

  - At this stage, “Unauthorised electoral or referendum content that is misinformation” is

not in scope for code and standard power, yet “Unauthorised electoral or referendum
content that is disinformation” is. This is made most apparent in the slide below
provided by the department.

We believe this poses a problem when the key difference in definition relies on intent (see
definitions above). Past studies show that harmful falsehood spread without intent (i.e.
‘misinformation”) can easily switch to being “disinformation” when spread with intent, and
vice versa (for an example of this see Carson, A., Gibbons, A., & Martin, A. (2021).
Recursion theory and the “death tax”: Investigating a fake news discourse in the 2019
Australian election. Journal of Language and Politics, 20(5), 696-718.)

**4.** **The scope of the private message exemption**

**_Instant Messaging Services_**

We are pleased to see the coverage of the bill has exemptions relating to certain services, like
broadcasting services, email, SMS and MMS. However, we think consideration should be
given to greater clarity in defining Instant messaging services, particularly on what
‘messages in a publicly open conversation sent using an instant messaging service’ is. Our
reading of 2.1.3 in the explanatory notes on private messages suggests it should be clearer
about what constitutes a ‘group’, ‘social media’ and publicly open conversation’.

**4 | P a g e**


-----

_For example a family group chat is exempt from the powers but ‘a social media group for a particular_
_interest or hobby’ is included._

This may be a problem if we are thinking about a small Facebook Messaging groups that
revolve around a shared hobby through a group chat.

It seems at odds with the exemption that ACMA has in place that it could not require the
production of information that would reveal the content of private messages sent over instant
messaging services or require platforms to keep records of the content of private messages,
and that it can’t register a code with provisions about the content or encryption of private
messages. In other words, without further clarification, the example in the explanatory notes
appears to pave the way for a loophole to include private messaging. If this is the correct
reading of this scenario, we think this oversteps the balance needed with any new regulation
in relation to personal privacy.

**_5._** **Other matters – standard making and harmonisation of terms with similar bills**

The Bill gives ACMA the power to make a standard to cover ‘emerging circumstances’,
although the actual terms of s50 talk of ‘exceptional and urgent circumstances’. We think
there needs to be some definitional criteria and harmonisation of these terms. We also
recommend that a ‘reasonable period’ be clarified.

On the issue of harmonisation, where there is similar legislation in place that uses similar
terms such as “digital platform services”. Where possible consistency of definitions is
preferable to assist with compliance.

**Appendix**

**Research publications on mis and disinformation in Australia and beyond**

  - Carson, A. & A. Gibbons. (2023). The Big Chill? How Journalists and Sources Respond to Fake News
Laws in Indonesia and Singapore, Journalism Studies, Online first: DOI:
10.1080/1461670X.2023.2192299.

  - Carson, A. & S. Wright (2022). Fake news and democracy: definitions, impact and response,
_Australian Journal of Political Science, 57(3), 221-230. DOI: 10.1080/10361146.2022.2122778._

  - Gibbons, A. & A. Carson. (2022) What is misinformation and disinformation? Understanding multistakeholders’ perspectives in the Asia Pacific, Australian Journal of Political Science, 57(3), 231-247.
DOI: 10.1080/10361146.2022.2122776.

  - Carson, A., Gibbons, A., Martin, A., & J. Phillips (2022). Does Third-Party Fact-Checking Increase
Trust in News Stories? An Australian Case Study Using the “Sports Rorts” Affair, Digital Journalism,
10(5), 801-822.

  - Carson, A., Gibbons, A., & Martin, A. (2021). Recursion theory and the “death tax”: Investigating a
fake news discourse in the 2019 Australian election. Journal of Language and Politics, 20(5), 696-718.

  - Farhall, K., Carson, A., Wright, S., Gibbons, A., & Lukamto, W. (2019). Political Elites' Use of Fake
News Discourse Across Communications Platforms. International Journal of Communication, 13(23),
4353-4375.

**5 | P a g e**


-----

  - Carson, A., & Farhall, F. (2018). Understanding Collaborative Investigative Journalism in a “PostTruth” Age. Journalism Studies, 19(13), 1899-1911. DOI:10.1080/1461670X.2018.1494515

  - Carson A. and L. Fallon. (2021). Fighting Fake News: A Study of Online Misinformation Regulation in
_the Asia Pacific. Melbourne: La Trobe University, 137 pages._

  - The Fake News Crisis: Lessons for Australia from the Asia-Pacific. University of Melbourne, 8 pages.

**Opinion piece**

Carson, A. (2023, 14 July) More stick, less carrot: Australia’s new approach to tackling fake news on
digital platforms, The Conversation. https://theconversation.com/more-stick-less-carrot-australias-newapproach-to-tackling-fake-news-on-digital-platforms-209599

i Andrews, Travis M., and Danielle Paquette. 2020. “Trump Retweeted a Video with False Covid-19 Claims.
One Doctor in It Has Said Demons Cause Illnesses.” Washington Post, June 29, 2020.
https://www.washingtonpost.com/technology/2020/07/28/stella-immanuel-hydroxychloroquine-video-trumpamericas-frontline-doctors/.

ii Gibbons, A. & A. Carson. (2022) What is misinformation and disinformation? Understanding multistakeholders’ perspectives in the Asia Pacific, Australian Journal of Political Science, 57(3), 231-247. DOI:
10.1080/10361146.2022.2122776.

**6 | P a g e**


-----

