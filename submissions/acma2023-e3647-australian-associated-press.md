**Australian Associated Press**

Suite A, 188 Oxford Street

Paddington NSW 2021

Australia

**t +61 2 9322 8000**

**abn 94 641 582 121**

**aap.com.au**

# Submission:

## Exposure draft of the Communications Legislation Amendment (Combatting Misinformation and Disinformation) Bill 2023

August 2023

### Introduction

Australian Associated Press (AAP) is Australia’s only independent national newswire.

In 2019 AAP established AAP FactCheck as a self-contained unit within the newsroom to address the
growing problem of mis and disinformation online.

AAP has built its reputation on fact-based, objective journalism over almost nine decades, and under
our not-for-profit structure with objectives around serving and educating all Australians, AAP
FactCheck has grown from being a successful project into a core service, with a dedicated staff of
journalists in Australia and New Zealand.

AAP is responsible for the majority of fact-checking on social media platforms in Australia.

We produce the highest number of fact-check articles addressing Facebook and Instagram posts in
this region, and are the only organisation formally fact-checking TikTok videos in our region.

AAP FactCheck is currently the only Australian fact-checking organisation fully accredited with the
[International Fact Checking Network (IFCN)[1], which rigorously assesses accredited fact-checkers](https://www.poynter.org/ifcn/)
annually to ensure compliance with stringent requirements designed to ensure our objectivity,
fairness, transparency and accuracy.

Our experience in this rapidly evolving area cannot be easily replicated.

In addition to our platform work, we routinely produce public interest fact-check articles that sit outside
our platform contracts. This work involves identifying and analysing claims made by public figures,
regardless of where the comments appear.

We welcome the opportunity to give feedback to the draft bill and believe increased action on mis and
dis-information is essential to Australian democracy.

1 The IFCN carefully scrutinises the legitimacy of fact-checkers world-wide. Accreditation with the IFCN is a
shorthand way to establish that a fact-checking organisation operates according to world’s best practice.
IFCN-accredited fact-checkers are a world-wide community of highly-skilled journalists, academics and
trainers who frequently collaborate and share intelligence about the misinformation and disinformation
landscape, and the challenges confronting fact-checking work. IFCN accreditation was a prerequisite for
AAP FactCheck’s third-party fact-checking agreements with both Meta (covering Australia, New Zealand
and the Pacific region), and TikTok (in Australia only, with Pacific coverage on demand).


-----

### AAP FactCheck’s work

AAP FactCheck is one of two Meta fact-checking partners in this region, and the sole Australian
fact-checker for TikTok.

AAP FactCheck only addresses claims that meet our criteria of being verifiable, widely seen, broadly
relevant, timely and consequential. We retain full editorial independence, and select from a pool of
problematic claims that have been identified by the platforms, or independently by our staff.

Once identified, the claims are thoroughly researched, experts are contacted, and a fully referenced
article is written and carefully edited by multiple members of our team. Our detailed and fact-driven
debunks are accompanied by simple, accessible verdicts summarising the statement's veracity.

We also provide condensed advice directly to our platform partners.

Our fact-checking work with Meta and TikTok informs their interventions in relation to fact-checked
content and related accounts. Those actions can include labelling harmful content with fact-check
articles, restricting the reach of a post, and restricting users who repeatedly disseminate such content.

All AAP FactCheck articles are freely available on our website, promoted via our social channels, and
prioritised in related Google searches.

Human fact-checking is critical in ensuring fact-checking programs maintain the implied constitutional
rights of Australians to free expression and political communication.

Unlike humans, algorithmic and artificial intelligence moderation struggle to determine whether
content is misleading, missing context, partly false, mostly true or satirical. It’s also mostly unable to
authenticate whether visual content such as images and videos have been altered.

Non-human moderation often results in arbitrary and proscriptive actions against users, particularly
those who have no intention to deceive, which risks undermining their rights to free expression and
political communication.

On the other hand, the ability of human fact-checkers to perceive nuances in content allows for the
protection of users and society from harms, and improves the quality of the digital information
environment while preserving fundamental rights.

This includes nuances in cultural or political context, underscoring the importance of engaging
Australian fact-checkers to check Australian content.

The platforms amplify the value of AAP’s fact-checking work by exponentially increasing the number
of posts addressed by our articles and advice.

[For example, according to Meta’s latest transparency report to DIGI, articles written by third party fact](https://digi.org.au/wp-content/uploads/2023/05/Meta_2023-AU-Misinformation-Transparency-report_v1.pdf)
checking partners lead to warnings being displayed on more than nine million distinct pieces of
content on Facebook in Australia (including reshares) in 2022. It is not clear what overall percentage
of problematic content on the platform this represents.

We can see the significant impact of our work through our independent tracking of individuals and
groups that produce the harmful, adversarial disinformation narratives that originate and are
disseminated in Australia.

This is critical work, as ACMA found, “Online misinformation narratives have resulted in a wide range
of acute and chronic harms, including undermining public health efforts and eroding trust in
democratic institutions over time”.[2]

2
ACMA misinformation report - Factsheet 1: key research findings,
https://www.acma.gov.au/sites/default/files/2022-03/ACMA%20misinformation%20report_Fact%20she
et%201%20-%20key%20research%20findings.pdf


-----

### Misinformation and disinformation in practise

AAP FactCheck’s insights regarding disinformation, and in relation to this draft legislation, are borne
out of years of experience in the fact-checking niche.

From our experience, the major harm to society of misinformation and disinformation is not from
content that explicitly incites users into real world actions, such as committing crimes against
individuals or groups, vandalising critical infrastructure, harming their own health or harming the
economy.

This type of content is less common, and more likely to be removed by the platforms for breaching
community guidelines, rather than being dealt with through fact-checking programs.

The greater risk comes from the cumulative effect of unchecked misinformation and disinformation
that on its own may not meet the threshold outlined in this Bill, but with repeated exposure is capable
of causing real world serious harms, for example, by eroding trust in government or healthcare, as
experienced during the peak of the COVID-19 crisis.

The ACMA has said platforms should be taking action on misinformation and disinformation
contributing to both acute and chronic harm.

_“The need to address misinformation with a high risk of acute harm does not imply that this is the only_
_misinformation over which platforms should be taking action. Although responses to chronic harms_
_may be less urgent, the harms are not necessarily less severe._

_Societies around the world are grappling with coordinated campaigns designed to sow confusion and_
_distrust and to undermine democratic institutions over time. There is a substantial risk to Australian_
_society and its security if misinformation contributing to chronic harms is not adequately addressed.”[3]_

The public share the regulator’s concerns regarding the potential harms of misinformation on digital
platforms.

About 88 per cent of Australian users either agreed or strongly agreed misinformation was “generally
harmful to individuals, groups and society” in the ACMA’s most recent survey.[4]

In that same report, 78 percent of users also agreed or strongly agreed that misinformation was
prevalent on digital platforms in Australia.

Users were generally satisfied with the ease of reporting harmful misinformation on platforms and the
timeliness of an outcome, but they’re overwhelmingly dissatisfied with transparency and actions.

Only 44 per cent were strongly dissatisfied with the actions taken in response to their reports and 48
per cent were concerned about the transparency of platform processes.

The sentiments of these Australian users about the actions of platforms in response to their reports for
us reinforces the value of fact-checking operations as a proactive solution or antidote to harmful misand disinformation online.

3
Misinformation and news quality on digital platforms in Australia: A position paper to guide code
development, ACMA, June 2020.
https://www.acma.gov.au/sites/default/files/2020-06/Misinformation%20and%20news%20quality%20p
osition%20paper.pdf

4
_Harmful content on digital platforms: reporting and complaints, ACMA July 25,_
2023.https://www.acma.gov.au/publications/2023-07/report/harmful-content-digital-platforms-reporting
-and-complaints


-----

### Draft Bill:

 Risk of disincentivising fact-checking

Misinformation and disinformation are defined in the draft bill as being "reasonably likely to cause or
contribute to serious harm".

By defining misinformation and disinformation in relation to ‘serious harm’ in this way, we are
concerned the bill may discourage and disincentivise fact-checking of any content that does not meet
that threshold.

It is important that the bill and voluntary codes encourage increased action on harmful misinformation
and disinformation broadly, and does not have the unintended impact of narrowing the breadth of
content that action is taken on to protect Australians online.

‘Serious harm’ is not defined in the draft bill, however, based on the examples of serious harm in the
Guidance Note, a large proportion of content AAP FactCheck addresses, when considered in
isolation, may fall outside the bill’s ‘serious harm’ parameters. This misinformation and disinformation
is still problematic and harmful - and left unchecked, results in a cumulative undermining of truth and
facts, and confidence in critical systems and institutions.

The lack of a clear definition of ‘serious harm’ in the bill, and the examples provided separately, could
lead to an excessively narrow interpretation by platforms to imply only ‘acute’ or ‘imminent’ harms.

Whereas, the ACMA is unambiguous about the need of a harm definition to be sufficiently broad to
capture ‘a range of chronic harms that can result from the cumulative effect of misinformation over
_time, such as reductions in community cohesion and a lessening of trust in public institutions’[5]._

In addition, the qualifier of ‘likely’ in the draft bill could excessively narrow the scope of the ACMA’s
proposed information-gathering powers. We suggest the use of the word 'foreseeably' to better fulfil
the ACMA's 2021 recommendations.

The European Digital Services Act (2022) requires digital services to identify, analyse and assess any
‘systemic risks’ from the design, function and use of their platforms.

It defines four broad categories of systemic risk: illegal content, any actual or foreseeable negative
effects on fundamental rights, any actual or foreseeable negative effects on civic discourse and
election processes and public security; any actual or foreseeable negative effects in relation to
gender-based violence, the protection of public health and minors and serious negative
consequences to a person’s physical health and wellbeing.

The inclusion of the words ‘actual or foreseeable’ gives EU regulators scope to understand evolving
misinformation and disinformation risks.

The ACMA should be afforded a similarly broad scope to gather information on the range and volume
of harmful content that could contribute to serious harm in the future.

Some international fact-checkers already report changes to commercial fact-checking arrangements
to exclude all but the most serious tier of misinformation and disinformation. In its current format, this
bill may encourage such reductions to fact-checking, which would also serve to limit access to
factually accurate information countering misinformation and disinformation themes.

5
A report to government on the adequacy of digital platforms’ disinformation and news quality
measures. ACMA, June 2021.
[https://www.acma.gov.au/sites/default/files/2021-11/Adequacy%20of%20digital%20platforms%20disin](https://www.acma.gov.au/sites/default/files/2021-11/Adequacy%20of%20digital%20platforms%20disinformation%20and%20news%20quality%20measures.pdf)
[formation%20and%20news%20quality%20measures.pdf](https://www.acma.gov.au/sites/default/files/2021-11/Adequacy%20of%20digital%20platforms%20disinformation%20and%20news%20quality%20measures.pdf)


-----

### Reporting provisions

To effectively tackle misinformation and disinformation in Australia, it is important to understand both
the prevalence of false, misleading or deceptive information on digital platform services (mis and
disinformation broadly) and to expand 14(1)(a) to include the proportion of this content acted upon.

Quantitative reporting is critical in order to understand how well the platforms are responding to
misinformation and disinformation.

The records made and retained by the digital platforms must enable ACMA to understand the number
of pieces of content on the platform that are identified as mis and disinformation (defined broadly). As
well as the number of pieces of content and types of content that are addressed via its various
mitigations.

Further, these figures must be understood as a percentage of all content on the platform.

### General principles relating to misinformation codes and misinformation standards

It is vital that the codes are compulsory and wholly applicable to all members of the digital platform
sector to which they relate.

33(3)(f) - Supporting independent fact checking is extremely important, as is giving end-users
information regarding verdicts where applicable, to build a trusted, transparent process.

33(3)(i) - It is important that the platforms respond to complaints/notifications regarding misinformation
and disinformation. Reporting avenues should be simple and publicised, and include an appeal/review
function.

### Third-party fact-checking

This bill positions fact-checkers as stakeholders, with Section 19 allowing for organisations like AAP
FactCheck to be called upon to provide “information, documents and evidence” to ACMA in relation to
misinformation and disinformation on digital platform services.

As a third-party fact-checker we report to the platforms and would do so in line with any record
keeping requirements. It is possible Section 19.1 could discourage platforms from engaging third party
fact-checking partners in the first place, for fear they may be compelled by ACMA to reveal otherwise
confidential information.

Third-party fact checking is crucial in protecting users and society from harm and improving the quality
of online information while protecting aforementioned fundamental rights. It ensures there is a system
of checks and balances in the moderation of mis- and disinformation content. Fact-checkers assess
and verify content while platforms take actions.

Fact-checkers also respond to users lodging disputes regarding rating labels placed on harmful,
deceptive content. This guarantees users with the right to independently appeal any measures taken
by platforms and/or the right to full remission if they correct their content.

This separation of roles ensures greater transparency of platform processes and decision-making,
while protecting users from arbitrary actions, ensuring fair process and preserving their rights to
expression and communication.


### News Source


‘A newswire’ should be added to the list of news sources.


-----

