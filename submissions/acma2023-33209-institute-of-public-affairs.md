#### Research report provided to the Public Consultation  on the Communications Legislation Amendment  (Combatting Misinformation and Disinformation) Bill 2023

##### AUGUST 2023


###### Morgan Begg Director of Research

 John Storey Director, Legal Rights Program


-----

## Contents

###### Foreword 1

 Executive summary 3

 Introduction 4

 Misinformation laws are an assault on freedom of speech 8

 The definition of misinformation is broad and subjective, and truth is not a defence 9

 Big tech companies would become the censorship enforcement arm of the federal government 11

 The Bill would not apply to government, but would apply to critics of the government 12

 Big tech companies would be incentivised to censor first, ask questions later 13

 Coercive information gathering powers violate fundamental legal rights 14

 Recommendations 15


-----

## Foreword

The proposed Communications Legislation Amendment
(Combatting Misinformation and Disinformation) Bill
would be the single biggest attack on freedom of
political communication in Australia’s peacetime history,
and could be used to outlaw disagreement, dissent, and
criticism of government policy.

Never before has an Australian government sought
to weaponise its bureaucracy by compelling a private
digital organisation to shut down the speech
and communication of Australian citizens.

Describing these laws as illiberal and undemocratic barely
scratches the surface of just how insidious the provisions in
this Bill are. This Bill takes the very worst features of Section
18C and the abandoned Finkelstein laws, supercharges
them, removes any protections that Australians have, or
would have had, and would empower a vast and secretive
bureaucracy to hunt and shut down Australians who
disagree with contentious government policies.


Under the Bill, exempt entities, such as government, would
be permitted to spread misinformation, yet citizens who
share that same information could be censored, including
through imprisonment under certain circumstances. That
an Australian government would even contemplate a
scenario whereby one of its citizens could be censored and
potentially jailed for merely expressing an opinion which
they hold to be true violates every principle of human rights
and is an affront to human dignity and respect.

Further, the Bill would permit government to spread its
messages on highly contested public policy issues, such
as the Voice to Parliament, but prohibit Australians from
then criticising or questioning the government. This would
create a two-track society with one set of rules for the
powerful elite, and another set for mainstream Australians. If
misinformation and disinformation are truly problems in our
society, as is the presupposition of this Bill, then it is unclear
why the source of that misinformation or disinformation has
any bearing on the purported resultant societal harms.

###### 1


-----

Under the laws, an unelected and unaccountable starchamber bureaucracy in the Australian Communication
and Media Authority (ACMA) would be empowered
to produce the official definition of the truth. This is
because, under the proposed laws, ACMA would be
required to make determinations in relation to the extent
to which social media companies have properly enforced
misinformation codes. As such, ACMA would be required
to adjudicate on whether something is ‘misinformation’ or
‘disinformation’. Yet, as ACMA itself has previously noted,
online ‘misinformation’ and ‘disinformation’ are ‘relatively
novel and dynamic phenomena’ with ‘no established
consensus on the definition of either term.’

On top of this, ACMA would be given the unprecedented
power to enforce on big tech companies an obligation
to adopt measures to prevent misinformation. In effect,
the big tech companies will become the censorship
enforcement arm of the federal government.

The scope of what could be considered harmful is so
broad that it could potentially capture any difference
of opinion. For instance, criticism of government policy
positions such as the proposed Indigenous Voice, could
be labelled as ‘hatred’. Criticism of public health measures
during a declared pandemic could be labelled as harmful
to the health of Australians. Debate about the quality
of climate science could be labelled as harmful to the
Australian environment.

Of perhaps even greater concern, is that under the
proposed laws, not even the truth would be a defence. For
instance, if a citizen were to disseminate information which
was factually true, but ACMA or a tech company labelled
it as ‘misleading’ or ‘deceptive’, then that information
would fall within the scope of these laws. In other words, if
ACMA’s perspective was verifiably false, and the accused
disseminator of misinformation’s perspective was verifiably
true, it would be ACMA’s perspective which prevails and
which would, in effect, become the official ‘truth’.

###### 2


Under the proposed laws, ACMA can even bypass the
big tech companies and directly target Australian citizens.
For example, Division 3 of the draft Bill would empower
ACMA to compel citizens to provide information to ACMA
and to appear before ACMA in what could be described
as a kangaroo-court style arrangement. Failure to follow
this process in the specified manner could lead to 12
months imprisonment.

At the same time, the Bill removes critical legal protections,
such the privilege against self-incrimination (which dates
to seventeenth century English common law), and the
vagaries of the Bill are such that no Australian could be
sure if at any point in time they are following the law. A
foundational principle of the rule of law is that for law to
be followed, it must be capable of being understood. Yet
terms such as ‘misleading’ and ‘deceptive’ are inherently
vague and evolving and subject to interpretation.

It may be a cliché, but it is true that debate and discussion
are the lifeblood of democracy. Every Australian has
the right to express their opinion, even if that opinion is
considered controversial by the powers that be at the
time. The human progress enabled by the institutions and
culture of Western Civilisation has often been propelled
and accelerated by those who challenged the received
wisdom of their age, and, in doing so, enlightened
humanity. This Bill, though, is reflective of a common
practice of the Dark Ages which weaponised censorship
to protect established interests, chief among them the main
governing institutions of the time.

Only a government scared of debate and its own citizens
would seek to revert to such suppressive and undemocratic
means to control debate and the flow of information
through our society.

The Bill must be scrapped.

Daniel Wild
Deputy Executive Director


-----

## Executive summary


###### 3


-----

## Introduction

The Institute of Public Affairs (IPA) has a longstanding
commitment to conducting research into the fundamental
human right to freedom of speech. In 2012, the IPA exposed
through its research how the recommendations of the
Finkelstein Report into Media and Media Regulation would
censor, regulate, and licence the printed and online press.
The IPA’s research and analysis explained why Finkelstein’s
recommendations—which failed to be enacted into law—
were a significant threat to freedom of speech.

In 2016, the IPA published The Case for the Repeal of
_Section 18C, which explored the fundamental philosophical_
and practical flaws of laws that prohibit ‘harmful’ speech.
This analysis has been applied not only to section 18C of
the federal Racial Discrimination Act 1975, which makes it
unlawful to offend, insult, humiliate, or intimidate a person
or group of people because of their race, but has also been
used in the context of state-based proposals to expand antivilification laws.[1]

It is because of the depth of this research that the
IPA recognises how broad and subjective laws can
invite government overreach and threaten the freedoms
of Australians. It is in this context that the IPA has
prepared this research report to scrutinise the federal
government’s Exposure Draft of the Communications
Legislation Amendment (Combatting Misinformation
and Disinformation) Bill 2023 (the Bill).


The Bill would give extraordinary new powers to the
Australian Communications and Media Authority—a
federal government agency—to oversee and enforce the
development of codes that digital platforms such as Twitter,
Facebook, and Google would need to adopt. The codes
would outline the measures the platforms will adopt to
prevent or respond to misinformation and disinformation.

The broad framework of the Bill follows the outline
that was developed by ACMA in its 2021 Report to
_government on the adequacy of digital platforms’_
_disinformation and news quality measures (ACMA_
Report). After the report was released in March 2022,
the IPA noted ACMA’s proposed measures would mean
the government would be responsible for defining the
‘official’ truth and controlling acceptable opinion.
We noted further the broad and subjective nature of
ACMA’s proposal would make it operate as an allpurpose, universal restriction on freedom of speech
equivalent to section 18C to censor speech about
almost anything controversial on the internet. The
analysis of the Bill reveals the same concerns, though
as the report will explore, in some cases the threshold
for misinformation is even lower in the Bill compared
to ACMA’s original proposal.

This research report provides an analysis of the Bill,
but it is important to acknowledge that this proposal is
not happening in a vacuum. In recent years Western
governments have taken significant steps to directly
and indirectly regulate the dissemination of information
in digital spaces. In what some have labelled the
‘censorship industrial complex’,[2] an assortment of
government, intelligence, big tech, and academic
interests have co-ordinated to censor online speech
under the guise of removing harmful misinformation.


1 See Morgan Begg, IPA Research into Anti-vilification Protections in Victoria (Institute of Public Affairs, June 2020).

2 See Michael Shellenberger’s testimony to the Congress of the United States: The Censorship Industrial Complex: US Government Support for

_Domestic Censorship and Disinformation Campaigns, 2016-2022 (Testimony of Michael Shellenberger to the House Select Committee on the_
Weaponization of the Federal Government, 118th Congress, 9 March 2023).


-----

In Australia linkages between government and the big
tech companies has been in place for some time. In
February 2021, it was reported that the Department of
Home Affairs, despite having no regulatory oversight of
social media or public health responsibilities, had at that
time sent more than 500 takedown requests to Facebook
relating to covid misinformation—more than even the
health department or communication department.[3] By
May 2023, the federal government had requested social
media companies to censor at least 4,213 posts during
the pandemic.[4] In a specific example, the public release
of 18 emails sent by the Extremism Insights and
Communication branch of the Department of Home
Affairs to Twitter’s main office in San Fransisco collectively
demanded 222 Twitter posts be taken down. Among
the affected posts was content making fun of Premier
of Victoria Daniel Andrews, criticism of former Minister
for Health Greg Hunt, and content that ‘undermined
confidence in the Covid-19 vaccination program.’[5]

In 2021, the federal government passed the Online
_Safety Act 2021 to in part expand the role of the_
eSafety Commissioner (formerly the Children’s eSafety
Commissioner). This role forms an integral part of the
governmental infrastructure that gives the executive,


and in particular the Minister for Communications,
the perceived legitimacy to pressure digital platforms
to self-censor content the government would like to
see minimised.[6]

For instance, The Guardian reported in April 2023 the
communications minister and eSafety Commissioner
were to

... meet the eSafety Advisory Committee, including 

members of the digital industry and government,
which will discuss the role of digital platforms in
protecting and supporting Indigenous Australians
during the [Aboriginal and Torres Strait Islander
Voice] referendum.

The group is engaging with Twitter, Microsoft,

Google, TikTok and others around the referendum.

[eSafety Commissioner Julie] Inman Grant said the
committee was seeking information from the tech
giants about their policies on the vote, and would
provide ‘guidance about what more we expect
them to do’.[7]


3 See Josh Taylor, ‘Australia’s Department of Home Affairs made most requests for Covid misinformation takedowns’, The Guardian (17 February

2021): https://www.theguardian.com/australia-news/2021/feb/17/australias-department-of-home-affairs-made-most-requests-for-covidmisinformation-takedowns.

4 Chris Kenny, ‘Antic probe reveals Canberra silenced 4213 Covid posts’, The Australian (22 May 2023): https://www.theaustralian.com.au/
nation/antic-probe-reveals-canberra-silenced-4213-covid-posts/news-story/9afc4362197af63454bd3fa89285c282.

5 Adam Creighton, ‘Government sought removal of tweet making fun of Daniel Andrews’, The Australian (24 May 2023): https://www.

theaustralian.com.au/nation/politics/government-sought-removal-of-tweet-making-fun-of-daniel-andrews/news-story/3363e77338dead6b
ac69e70084f352f5.

6 Morgan Begg and John Storey, Voice to Parliament: Research report provided to the Parliamentary Joint Committee into the Aboriginal and

_Torres Strait Islander Voice Referendum (Institute of Public Affairs Research Report, April 2023) 14-15._

7 Josh Butler, ‘Government puts social media giants on notice over misinformation and gate speech during voice referendum’, The Guardian

(29 March 2023): https://www.theguardian.com/australia-news/2023/mar/29/government-puts-social-media-giants-on-notice-overmisinformation-and-hate-speech-during-voice-referendum.

###### 5


4


5


-----

In March, the federal government agency responsible
for overseeing elections and referendums—the
Australian Electoral Commission—announced that it
was considering partnering with third party ‘fact
checking’ organisations reportedly to counter
misinformation during the Voice referendum debate.[8] The
prominent fact-checking organisations include AAP Fact
Check, RMIT FactLab, and RMIT ABC Fact Check, and
are typically non-government organisations, affiliated
with academic institutions, or in the latter case directly
affiliated with a government broadcaster.

Big tech platforms such as Facebook will rely on the third
party factcheckers to assist in enforcing their own rules on
misinformation: if for instance RMIT ABC Fact Check make
a determination that content is false, Facebook will rely
on that determination to restrict the posting and sharing of
that content.

The big tech platforms have for the most part voluntarily
participated in this arrangement. Meta (parent company
of Facebook and Instagram), Google, Twitter, Microsoft,
TikTok, Apple, Adobe, and Redbubble are signatories to a
voluntary code on misinformation and disinformation under
a process overseen by ACMA,[9] and social media platforms
have a demonstrated record of suppressing or restricting
the expression of opinions relating to critical public policy
matters. For example, during the declared pandemic
YouTube’s ‘Covid-19 medical misinformation policy’ was
defined to mean the platform would not allow content that
‘contradicted local health authorities’ or the World Health
Organization’s medical information about Covid-19.
This meant that assertions challenging the efficacy of
lockdowns, face masks, or other mandatory pharmaceutical
interventions were not allowed because it was inconsistent
with government public health officials.


These decisions to censor debate were made by digital
platforms in the absence of legislative coercion or
regulatory obligation. Under the Bill, the digital platforms
will be required to continue to censor, and the exorbitant
financial penalties attached to failing to do so will mean
platforms are incentivised to excessively censor to minimise
risk. It is a critical failure of the Bill that it does not—and
probably cannot—address the problem of over-compliance.

The promise to defeat lies and falsehoods is admirable in
the abstract sense, but is impossible to achieve practically.
As the IPA noted in the 2022 research letter:

The suggestion that government officials could be
employed as reliable arbiters of truth is idealistic but
unrealistic. More realistic is that the ‘official’ truth would
be determined not by reference to its accuracy, but
according to whether it is politically uncomfortable or
unacceptable for certain opinions to be expressed.[10]

This is reinforced not only by the history of misinformation,
but also by human nature. When people are presented with
information, they interpret it in light of their individual values
and experiences. Two different people presented with
the same information might come to two entirely different
conclusions based on their subjective interpretations. While
these interpretations might be disputed, it is not for these
disputes to be adjudicated—they are matters of debate.
The effort then of central authorities to make determinations
about the information being circulated is not an issue of
accuracy, but one about controlling which interpretations
are allowed to be drawn from the information.


8 Sam Buckingham-Jones and Mark Di Stefano, ‘AEC eyes tie-up with fact checkers for Voice referendum’, The Australian Financial Review (19 March

2023): https://www.afr.com/companies/media-and-marketing/aec-eyestie-up-with-fact-checkers-for-voice-referendum-20230317-p5ct0r.

9 See Australian Communications and Media Authority, Digital platforms’ efforts under the Australian Code of Practice on Disinformation and

_Misinformation: Second report to government (July 2023)._

10 Morgan Begg, Federal government must abandon plan for internet censorship (Institute of Public Affairs Research Letter to the Minister for

Communications, Urban Infrastructure, Cities and the Arts, 12 May 2022) 3-4.

###### 6


8


-----

With this wider context in mind, the IPA has analysed the Bill
and found that

- The meaning of misinformation in the Bill is so broad

and subjective that it would be impossible for a person
to know how the rules would be enforced over time.
It would be open to regulators to pick and choose
which perspectives qualify as meeting the definition of
misinformation, and truth would not be a defence.

- The Bill would also give ACMA extraordinary new

powers to directly interpret and apply the meaning
of misinformation, and enforce on big tech companies
an obligation to adopt measures to prevent
misinformation. In effect, the big tech companies
would become the censorship enforcement arm of
the federal government.

- Under the Bill, the meaning of misinformation would

not apply to government authorised content, but
would apply to critics of the government. Also
protected are professional media entities and
academia, which are collectively the most powerful
potential conveyers of false information in society.

- The structure of the Bill and the potential penalties

would incentivise big tech companies to over-comply
with their obligations to censor. ACMA, who is
imposing the obligation, would not be accountable
to Australians who have no right of appeal or review
if their communications are wrongly censored.


There is no legal, moral, or political justification for any
large entity—whether multinational digital platforms or
Australian governments—to be entrusted with this kind
of power over online communications. It is a repudiation
of the idea of Australia as a democratic society, where it
is acknowledged that people inevitably have a variety
of different perspectives about any issue, and that it is
important to give everyone a chance to have their say.
Giving government the draconian and authoritarian power
to police the internet for ‘accurate’ content will mean some
opinions and perspectives will be unfairly excluded from the
debate. It has no place in the free society that Australia has
historically been.

The Bill should be abandoned.

###### 7


-----

## Misinformation laws are an  assault on freedom of speech


Misinformation laws require power to be transferred to a
central authority—the government—to adjudicate on the
quality of information being shared by members of the
public. That a government could wield the power to make
pronouncements on the validity of expressions based on
subjective assessments relating to accuracy would have a
chilling effect on the speech of all Australians.

Freedom of speech is fundamental to individual liberty
and a healthy democracy. A precondition of individual
liberty is a recognition that each person possesses beliefs
and convictions that makes them unique. These beliefs
and convictions inform a person’s worldview and informs
what a person believes to be right. The ability to speak
and act in accordance with those convictions is freedom of
conscience.

The respect for individual autonomy underlying freedom
of conscience implies that the ability to give action to
individual thought and conscience is limited only to the
extent that doing so interferes with the autonomy or
rights of others. If ‘misinformation’ is truly a problem that
requires a solution in the law, then this is an admission that
individual autonomy is not recognised: if a recipient of
alleged misinformation is not assumed to be capable of

###### 8


independently and autonomously accepting or rejecting the
information according to their own judgement, the law is
operating under the assumption that people need protection
from themselves, rather than the actions of others.

Australia, as a democratic society, depends on the freedom
of people to have and to express their perspectives on
matters of public policy that affect them. If democracy is
a mechanism by which the preferences of members of the
body politic are aggregated, it follows that individuals
must have the ability to not only express their preferences,
but also to access the ideas of others so as to form their
preferences. Misinformation laws require restricting the
boundaries of public debate, which comes at a cost to
all who participate in it. The costs of restricting freedom of
speech are therefore high because it harms the practice of
democracy itself. This has been acknowledged by the High
Court of Australia under its jurisprudence on the implied
right to the freedom of political communication.


-----

## The definition of misinformation is broad and subjective, and truth is not a defence


It is cornerstone of the rule of law that the people who
are subject to the law are able to know what the law is
and how it will be applied. The vague and subjective
definitions of concepts such as misinformation mean it will
be almost impossible to predict how the legislation will be
enforced and applied. The digital platforms will be required
to predict what AMCA may or may not consider to be
misinformation in order to design and enforce their own
codes on misinformation. Users will similarly not be able to
anticipate how the digital platforms will make and apply
these decisions.

ACMA has itself acknowledged, in a 2021 report to
the federal government on the adequacy of existing
misinformation measures, that online ‘misinformation’
and ‘disinformation’ are ‘relatively novel and dynamic
phenomena’ with ‘no established consensus on the
definition of either term.’[11] Despite the acknowledged
uncertainty about what the terms mean, ACMA nonetheless
asserted that there is an ‘emerging consensus’ on the need
to give government the power and responsibility to ensure
Australians don’t engage in it. To meet this responsibility,
ACMA would be required to make determinations about
what types of content should be regarded as misinformation
so that it can assess the adequacy of how digital platforms
are performing.


The Bill defines ‘misinformation’ under clause 7:

(1) For the purposes of this Schedule, dissemination of

content using a digital service is misinformation on
the digital service if:

(a) the content contains information that is false,

misleading or deceptive; and

(b) the content is not excluded content for

misinformation purposes; and

(c) the content is provided on the digital service to

one or more end-users in Australia; and

(d) the provision of the content on the digital service

is reasonably likely to cause or contribute to
serious harm.

(2) For the purposes of this Schedule, dissemination

of content using a digital service is disinformation
on the digital service if:

(a) the content contains information that is false,

misleading or deceptive; and

(b) the content is not excluded content for

misinformation purposes; and

(c) the content is provided on the digital service to

one or more end-users in Australia; and

(d) the provision of the content on the digital service

is reasonably likely to cause or contribute to
serious harm; and

(e) the person disseminating, or causing the

dissemination of, the content intends that the
content deceive another person.

…


11 Australian Communications and Media Authority, A report to government on the adequacy of digital platforms’ disinformation and news

_quality measures (June 2021) 7._


###### 9


-----

The above definition is an expansion of what was
originally proposed in ACMA’s 2021 report. Under the
Bill, the threshold for what is misinformation has been
lowered from ‘verifiably false’ to ‘false, misleading
and deceptive.’ The new wording introduces added
subjectivity to the interpretation of the provision.
Moreover, the terms ‘false, misleading or deceptive’
are not defined in the Bill, nor does the Bill provide for
a transparent process for determining if content is ‘false’
or not. Proof that online information was true may not
be defence under the Bill. Evidence of the content’s
accuracy may not be accepted by the platform, or the
platform may nonetheless regard the accurate content as
being misleading or deceptive. For example, accurately
citing an academic or scientific paper might ‘lack
context’ and thus still be considered ‘misleading’.

Also expanded is the element of misinformation relating to
harm. In the ACMA Report, harm was proposed to refer to
harms which cause an imminent and serious threat to

A. democratic political and policy making processes

such as voter fraud, voter interference, voting
misinformation; or

B. public goods such as the protection of citizens’

health, protection of marginalised or vulnerable
groups, public safety and security or the environment.


Under the Bill, content will be misinformation if ‘it is
reasonably likely to cause or contribute to serious harm’,
which severs the causative standard of ‘imminent and
serious threat’. In addition to the lower threshold, the
definition of harm is proposed to be extended to have
broader application. The Bill defines harm as:

(a) hatred against a group in Australian society on

the basis of ethnicity, nationality, race, gender,
sexual orientation, age, religion or physical or
mental disability;

(b) disruption of public order or society in Australia;

(c) harm to the integrity of Australian democratic

processes or of Commonwealth, State, Territory
or local government institutions;

(d) harm to the health of Australians;

(e) harm to the Australian environment;

(f) or financial harm to Australians, the Australian
economy or a sector of the Australian economy.

The scope of what could be considered harmful is so broad
that it could potentially capture any difference of opinion.
For instance, criticism of government policy positions such
as the proposed Aboriginal and Torres Strait Islander Voice
in the Constitution, could be labelled as ‘hatred’. Criticism
of public health measures during a declared pandemic
could be labelled as harmful to the health of Australians.
Criticism of the quality of climate science could be labelled
as harmful to the Australian environment.

The proposal that debate needs to be controlled to
protect against the vague notion of harm to the integrity
of the vague notion of ‘democratic processes’ is a farreaching claim, and one that is inconsistent with Australia’s
democratic traditions which have historically placed a high
value on the freedom of political communication.


-----

## Big tech companies would become the  the censorship enforcement arm of the  federal government


Under the Bill, digital platforms would be under an
obligation to remove or restrict content that meets the vague
and subjective definition of ‘misinformation’. ACMA—a
federal government agency—would be responsible for
enforcing this obligation on the digital platforms.

To fulfil this role, AMCA will be granted coercive powers
to compel digital platforms to enter into codes of practice
to outline the measures the platform will implement to
prevent or respond to misinformation and disinformation.

- The codes are not voluntary. Under clause 38

of the Bill, ACMA can compel digital platforms
to develop a code if it is satisfied a code is
necessary or convenient to ‘prevent or respond
to misinformation or disinformation’.

- ACMA can make determinations about what

is in the code. If ACMA is satisfied that a code
developed by a platform is deficient, it can determine
‘misinformation standards’. Under clause 53, digital
platforms are required to comply with the standards
that apply to them.

- If ACMA considers the digital platforms are not

enforcing the rules, or are not effectively addressing
misinformation and disinformation, ACMA can issue
the platforms with heavy financial penalties. Clause
43 of the Bill makes it a civil penalty for a digital
platform to fail to comply with the code.


In order to give effect to its responsibilities under the
Bill, ACMA would be required to make determinations
about whether a code is adequate, or whether a
platform is enforcing the code adequately. Making these
determinations means ACMA will inevitably be required
to determine the intended application of concepts such
as misinformation and harm.

The key enforcement mechanism is the power to register
codes and financially penalise platforms for failing to
enforce codes. In order to make determinations about
whether a platform is failing to address misinformation,
ACMA will be required to make findings about content
a platform has allegedly failed to take action against.
Platforms must anticipate the findings and standards of
AMCA to minimise the risk of enforcement actions.


-----

## The Bill would not apply to government, but would apply to critics of the government


Clause 2 of the Bill excludes content produced by
federal, state, and local governments, professional
news entities, and academia, from the definition of
misinformation or disinformation.

This means that content posted by ordinary Australians
will be subject to censorship, but the same rules won’t
apply to the following types of content listed under
clause 2:

_excluded content for misinformation purposes means_
any of the following:

(a) content produced in good faith for the purposes

of entertainment, parody or satire;

(b) professional news content;

(c) content produced by or for an educational institution

accredited by any of the following:

(i) the Commonwealth;

(ii) a State;

(iii) a Territory;

(iv) a body recognised by the Commonwealth,

a State or a Territory as an accreditor of
educational institutions;

(d) content produced by or for an educational institution

accredited:

(i) by a foreign government or a body recognised

by a foreign government as an accreditor of
educational institutions; and

(ii) to substantially equivalent standards as a

comparable Australian educational institution;

(e) content that is authorised by:

(i) the Commonwealth; or

(ii) a State; or

(iii) a Territory; or

(iv) a local government.


The effect of these provisions would mean that
where a government, media, or academic institution
isseminates false information, their content would be
exempt from the same rules that apply to individuals
expressing the same speech.

Notably, the AMCA report did not include the above
exceptions. The purpose of the Bill is purportedly to
prevent the dissemination of harmful false information,
but it has not been explained or justified why differential
treatment according to the source of the information
is desirable. For instance, it cannot be explained by
reference to the above sources being incapable of
producing false, misleading, or deceptive content, nor
can it be contended that government, the media, and
academia are not capable of causing serious harm—
the opposite is true. Government, academia, and media
institutions are among the most powerful sources of
information disseminated in society, and their status as
organs of power and expertise give them significant
influence. For this reason they have the greatest potential
to cause harm when communicating false information.


-----

## Big tech companies would be incentivised  to censor first, ask questions later


In a media release published in June 2023, the Minister
for Communications asserted the ‘proposed powers will
bring greater transparency to efforts by digital platforms
to respond to misinformation and disinformation on their
services, while balancing freedom of expression which is
at the heart of democracy.’[12] The structure of the Bill
however incentivises over-compliance with obligations to
censor, whereas digital platforms are under no obligation
to protect freedom of speech.

Under the Bill, digital platforms will be required to censor
content, while the financial penalties for failing to comply
with vague misinformation standards will incentivise
platforms to excessively censor to mitigate risk. This is
known as over-compliance.

While the Bill imposes obligations and penalties for
failures to censor inaccurate content, similar obligations
and penalties do not apply in situations where a platform
censors content that is not misinformation.

Additionally, the defences in the Bill are narrow to
non-existent.

- The exclusion relating to ‘content produced in good

faith for the purposes of entertainment, parody or
satire’ only applies to a narrow range of activities, and
depends on a decision maker considering the content
being made in good faith. As IPA research has shown
in relation to section 18C of the Racial Discrimination
_Act 1975, the good faith defences are subjective and_
difficult to consistently prove.[13]

- The limitation relating to ‘electoral and referendum

matters’ is narrow: it only applies to ‘authorised content’,
referring to a specific range of content, such as ads
for a political candidate prior to an election, not
expressions by individuals generally about an election.

- The consideration that ACMA must give to the freedom

of political communication is unlikely to be legally
meaningful. ACMA must only consider the freedom of
political communication, but it remains at their discretion
whether to act in accordance with the principle.


Further, the quasi-privatisation of internet censorship
actions means the government will not be accountable
for decisions made under the Bill. The effect of the Bill is
to restrict what Australian can say and share online. The
restrictive actions are undertaken by digital platforms
under a legislative obligation enforced by ACMA. It is
government censorship, but Australians who have their
speech restricted would have no right of appeal or review
against ACMA’s decision making.

An aggrieved Australian may lodge a complaint with the
digital platform, but the platforms are private entities and as
such are not bound by the rule of evidence and the common
law protections for procedural fairness. This Bill is designed
in such a way that the government ensures censorship takes
place, while avoiding any responsibility for the actions taken,
and denying Australians an effective right of appeal.

The absence of defences for freedom of expression, the
absence of accountability for censorship decisions, and the
absence of penalties for wrongful censorship demonstrates
that the Bill would not strike any amount of balance between
free speech and minimising misinformation. At the very least
this would require the big tech companies to be held equally
accountable for wrongly censoring honest opinions as they
would be for failing to censor misinformation.

The Bill represents a conflict between censoring content
to address misinformation and the principle of freedom of
speech. For the digital platforms, the material risk is only on
one side of the conflict. If contentious information is being
circulated on a digital platform, censoring that information
comes at no cost to the platform. But there is a significant
potential cost for the same information being left to circulate.
If in doubt, the platforms are incentivised to censor so as to
mitigate risk.


12 Michelle Rowland, ‘Consultation opens on new laws to tackle online misinformation and disinformation’ (Media release, 25 June 2023):

https://minister.infrastructure.gov.au/rowland/media-release/consultation-opens-new-laws-tackle-online-misinformation-and-disinformation.

13 Chris Berg et al., The Case for the Repeal of Section 18C (Institute of Public Affairs Research Report, December 2016) 32-35.


-----

## Coercive information gathering powers  violate fundamental legal rights


Under the Bill, ACMA would be granted a range of
coercive information gathering powers. There are broadly
two separate but concerning categories of information
gathering powers in the Bill:

- The first category refers to the use of information

gathering powers against the platforms to determine
whether a platform had failed to comply with a code.
Concerningly, the ACMA Report that these powers
would not merely be used as investigative tools, but as
a weapon to name and shame companies for failing
to meet ACMA’s standards.
As the ACMA Report noted at the time, the information
gathering powers would ‘incentivise behavioural
change across the industry’ as part of ACMA’s efforts
to regulate online content. Using coercive information
gathering powers for a secondary regulatory purpose
invites abuses of power.

- The second category refers to the use of information

gathering powers against an individual, such as a
person who uses a digital platform service. Under
clause 19, ACMA can require a person to give to
ACMA any such information or document within
the period and in the manner and form specified in
a written notice. A person’s failure to comply with
ACMA’s written notice can result in the person being
subject to a civil penalty, amounting to $8,250 every
day the contravention continues.
ACMA can request and require a person to give
information and produce documents as specified in the
written notice. The written notice can also request and
require a person to ‘appear before the ACMA at a
time and place specified in the notice to give any such
evidence.’ The combination of ACMA’s strict powers,
absence of obligation to respect legal rights, and
secretive proceedings, would make this process akin to
a ‘star chamber’.

The provisions remove the right to silence and abrogate the
privilege against self-incrimination. Under clause 21(1),
a person is not excused from complying with ACMA’s
broad information gathering powers even if to do so would
tend to incriminate the individual in relation to a criminal

14 _Sorby v Commonwealth (1983) 152 CLR 281, 288._


offence. Provisions which abrogate the right to silence and
the privilege against self-incrimination violate fundamental
legal rights which protect people against potential abuses
by the state. As former Chief Justice of the High Court Sir
Harry Gibbs noted in Sorby v The Commonwealth, it is:

a firmly established rule of the common law, since the
seventeenth century, that no person can be compelled
to incriminate himself.[14]

IPA has previously identified the right to silence and
the privilege against self-incrimination as fundamental
legal rights that are routinely violated in modern federal
legislation.[15] It is never appropriate to abolish the legal
rights of Australians.

The Bill also imposes criminal penalties that could mean a
person would be imprisoned in relation to the operation of
the proposed information gathering powers.

The powers contained in clauses 19, 21, and 22 are broad
and the safeguards are minimal. Given this, it is necessary
to consider the potential abuses of power that may occur.
For instance, under the laws as currently drafted, it is
possible that a person could be jailed for expressing a
view that regulators consider misinformation.

To illustrate this, an individual who has shared alleged
misinformation could be targetted by ACMA under clause
19 to produce that information. Given ACMA already
considers the information false or misleading (hence the
investigation) complying with the request will expose the
person to liability of a criminal offence. In the example,
simply by exercising its information gathering powers,
ACMA escalates the matter to a criminal matter. This
bizarrely unfair arrangement is exacerbated because
subclause 22(2)(b) would exonerate the person complying
with the information request if the individual ‘identified to
ACMA’ that the information is false or misleading. This
would operate as a powerful incentive for users to confess
that the information is false or misleading in order to avoid
liability. This would have the effect of vindicating ACMA’s
investigation and censorship of the targetted information. In
effect, the threat of prison sentences could be used to force
confessions and censor opinions an official disagreed with.


15 See Morgan Begg and Kristen Pereira, Legal Rights Audit 2019 (Institute of Public Affairs Research Report, February 2020).


-----

## Recommendations

On the basis of the analysis contained in this submission,
the Institute of Public Affairs is recommending the federal
government not proceed with the Bill in any form.

The IPA shares the concerns about the dissemination of
information on digital platforms. Namely, the behaviour of
the digital platforms to inappropriately censor content.

On no fewer than eight occasions that the IPA is aware of
between September 2022 and July 2023, attempts by the
IPA to share its research and analysis with the public were
restricted by social media companies. In several cases, the
social media companies relied on determinations by third
party fact-checking organisations that the IPA’s content was
‘false’, with reference to the opinions of individuals who
disagree with the IPA’s analysis.

The Institute of Public Affairs has recommended that the
federal government should ensure large digital platforms
are restrained from engaging in censorship by amending
the Broadcasting Services Act 1992.[16] Currently,
Schedule 2, Part 2, Section 3 of the Broadcasting
_Services Act 1992 requires broadcasters to offer political_
parties the opportunity to broadcast election material
during an election.


The most urgent priority for regulators is to address
the censorship efforts taking place in relation to the
Aboriginal and Torres Strait Islander Voice referendum
(in all cases of censorship of IPA content, it has been
in relation to referendum research). For this reason, the
federal government ought to extend Schedule 2, Part 2,
Schedule 3 so that it

- applies during the referendum period.

- expands the definition of broadcasters to digital

platforms.

- Applies the requirement to give opportunity to

broadcast referendum material to all referendum
participants (presently the law applies to political
parties and election candidates, but this standard
would be inappropriate during a referendum because
political parties are not seeking election, and every
Australian has a direct stake in the debate).

- Clarifies that digital platforms censoring referendum

content is unlawful.


16 See Morgan Begg and John Storey, Voice to Parliament: Research report provided to the Parliamentary Joint Committee into the Aboriginal

_and Torres Strait Islander Voice referendum (Institute of Public Affairs Research Report, April 2023) 13-15._


-----

-----

## About the Institute of Public Affairs


The Institute of Public Affairs is an independent, non-profit
public policy think tank,dedicated to preserving and
strengthening the foundations of economic and political
freedom. Since 1943, the IPA has been at the forefront of
the political and policy debate, defining the contemporary
political landscape. The IPA is funded by individual
memberships, as well as individual and corporate donors.

## About the authors

Morgan Begg is the Director of Research at the IPA.
Morgan joined the IPA in 2014 to advance the IPA’s work
on legal rights, the rule of law, and extending the rights
and freedoms of Australians. Since joining the IPA, Morgan
has been published on a variety of topics, from judicial
appointments, public health restrictions and emergency
powers, and the preservation of constitutional government.


The IPA supports the free market of ideas, the free flow
of capital, a limited and efficient government, evidencebased public policy, the rule of law, and representative
democracy. Throughout human history, these ideas have
proven themselves to be the most dynamic, liberating and
exciting. Our researchers apply these ideas to the public
policy questions which matter today.


-----

www.ipa.org.au


-----

