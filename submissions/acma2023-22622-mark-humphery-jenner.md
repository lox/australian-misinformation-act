# An overbroad risk to free speech and intellectual inquiry: Submission on the “Communications Legislation Amendment (Combatting Misinformation and Disinformation) Bill”

Author: Mark Humphery-Jenner

**Summary**

Governments must exercise care and restraint when restricting speech. The restrictions must go no
further than is necessary and must be precisely and narrowly defined. However, the proposed bill casts
a wide net. Its definition of “misinformation” is broad, ill defined, and arbitrary. It risks partisan, value
laden and ideological restrictions on speech. The Bill incentivizes content platforms to overly suppress
speech lest they be named and shamed but has no such incentivize for allowing ‘innocent’ speech. It
exempts the media and government from the “misinformation” provisions. These is even though
Australians rely on such institutions for correct information, such institutions are well resourced, and
they are precisely the institutions that should not spread “misinformation”. The Bill also fails to grapple
with the changing state of knowledge and the fact that what was once “misinformation” or
“controversial” might emerge to be true: this is inherent in the scientific method and this is not in the
exclusive domain of educational institutions. The proposed Bill presents an unacceptable risk to free
speech and to ordinary intellectual inquiry. The Bill requires heavy revisions if not abandonment.

## 1 Introduction 

It was once commonly believed that the Earth was the center of the universe. However, in the 1600s,
Galileo changed this, defending and evidencing ‘heliocentrism’: the belief that the Earth revolves around
the Sun. So controversial was this, that it was deemed heretical. In 1622, Galileo was deemed
“vehemently suspect of heresy”. It was once ‘misinformation’ or ‘disinformation’ to claim that the Earth
orbits the Sun. But, today we take that knowledge for granted. Unfortunately, the proposed approach to
‘misinformation’ risks repeating the same mistakes of old.


-----

Free speech is essential in a democracy and to human knowledge. However, free speech has limits.
These include existing prohibitions on defamation. However, any restriction on speech must be precise,
limited, and must not be open to political interference. Restrictions must be nuanced and carefully
balanced. Unfortunately, The Communications Legislation Amendment (Combatting Misinformation and
Disinformation) Bill 2023 (hereafter, “Misinformation Bill”) does not strike this balance. The
Misinformation Bill is overly broad, open to politically motivated abuse, and would undermine free
speech. Such curbs on free speech risk making Australia an international pariah.

The Misinformation Bill empowers the regulator to force content platforms to monitor, report on, and
suppress alleged “misinformation”. The Bill defines misinformation broadly to include content that is
merely “misleading” and that “contributes to” “harm”, which is broadly defined. The Bill’s ambit is both
vague and broad. The regulator could name and shame platforms for having Misinformation. In so
doing, it incentivizes platforms to take an aggressive stance on content, potentially suppressing swathes
of content even if they are not “misinformation” as defined by the Bill. The Misinformation Bill also
prioritizes media and the government by exempting them from monitoring or suppression provisions. In
so doing, it enables organizations that are supposed to be trusted, and that are well resourced, to be the
most lax with their content.

This Submission outlines several areas in which the Misinformation Bill falls short. The thesis is that the
Misinformation Bill should be halted. This is because it covers such a broad range of speech, would
suppress even accurate speech, fails to acknowledge that human knowledge changes over time, and
inappropriately exempts already powerful and well-resourced entities from its ‘misinformation’
provisions. In so doing, it imposes an unnecessary risk to free speech.

## 2 The Misinformation Bill in brief

The Misinformation Bill empowers to regulator (ACMA) to impose rules onto ‘digital platform providers’
in relation to ‘misinformation’ and ‘disinformation’. Digital platform providers are those who provide a
“digital platform service”. A digital platform service is any online service with content aggregation or
media sharing.[1] It would include YouTube, Twitter, Facebook, Instagram, TikTok, and Substack.
Presumably, it could also include certain blogs.

The Misinformation Bill proposes to collect and publish information on misinformation and steps taken
against it. ACMA may impose rules requiring the service provider to keep and provide records in relation

1 Communications Legislation Amendment (Combatting Misinformation and Disinformation) Bill 2023 Section 4.


-----

to “misinformation”, its prevalence, and what the provider is doing to combat misinformation.[2] ACMA
may also force service providers to prepare reports on misinformation at a periodicity that it specifies
and in a manner that it specifies.[3] ACMA may then publish this information, including specifics of the
nature and type of misinformation on each service provider and steps the service provider takes to
combat misinformation.[4]

The Misinformation Bill loosely defines what “misinformation” is. However, it does so loosely and in
broad terms, as explained below. The Misinformation Bill also exempts some content from
consideration: for example, “professional news content” and content from educational institutions and
the government need not be considered. That is, content from those groups is deemed to not be
misinformation by default and there is no evaluation into its accuracy or lack thereof.

The Misinformation Bill does not explicitly outlaw deemed “misinformation” but it does so implicitly and
indirectly. This is because service providers can be ‘named and shamed’ if their platform has
misinformation and/or if their content moderation is deemed lax. This encourages platforms to suppress
misinformation and disinformation.

The Misinformation Bill is framed as attempting to remove ‘harmful’ or ‘false’ information. However,
this is question begging. Major questions include what is misinformation. It also raises the question of
whose conduct is excluded from the bill; and thus, whose speech is implicitly assumed not to be
misinformation.

## 3 What is Misinformation?

The definition of “misinformation” is overly broad and chills not only political speech but also ordinary
investigative inquiries. This is because the definition of “misinformation” is itself question begging and is
vague. In turn, this could encompass good faith communications that turn out to be wrong, potentially
at a later time. It could also encompass communication that merely challenges the status quo.

The Bill defines “misinformation” as content “that is false, misleading or deceptive” and that “is
reasonably likely to cause or contribute to serious harm” (Section 7(1)). There are several issues.

2 Communications Legislation Amendment (Combatting Misinformation and Disinformation) Bill 2023 Section 14.
3 Communications Legislation Amendment (Combatting Misinformation and Disinformation) Bill 2023 Section
14(5).
4 Communications Legislation Amendment (Combatting Misinformation and Disinformation) Bill 2023 Section 25.


-----

To be clear, there is no inquiry into the person’s state of mind when disseminating content. The
definition contains no mens rea or state of mind. This is a strict liability. It is unnecessary to prove that
the purveyor acted intentionally, recklessly, or even negligently. The bill effectively charges platforms
with policing speech. Thus, platforms would render individuals liable for making a factually false
statement even if they genuinely believe the statement to be true. Strict liability is generally to be
avoided unless there is a strong policy reason for doing so and that strong policy reason outweighs the
potential unfairness of the strict liability.

### 3.1 What is “false” under the Bill?

The definition of what is “false” is a problem area. The bill does not define what is “false”. Rather, the
administrator will determine this.

This includes in ordinary investigative work. And, such investigative work can be done by private
businesses and individuals. Consider the example of data driven empirical research. Empirical
techniques are complex. Analyzing data requires significant skills, time, and resources. However, if a
researcher uses incorrect techniques, they can produce incorrect results that lead to incorrect policy
conclusions. This is the case even if the researcher acted in good faith.

A concrete example illustrates the point: Consider the technical area of “difference in difference” (DiD)
tests. This is an empirical technique used to identify whether variable A causes a change in variable B.
Researchers have DiD tests frequently. However, recent research suggests that standard DiD tests have
econometric problems. [5] Previous research undertaken in good faith might yield misleading conclusions.
Much of that research has significant policy implications. And, thus, if it is false, it could cause serious
harm. Under this bill, the concern is whether the prior research is now “false”; and thus, is
misinformation. Further, it appears that disseminating the potentially “false” findings now
“misinformation”. This is the case even if discerning whether prior research is accurate is a technical and
complex area. This creates a chilling effect disseminating such findings.

The Bill has no apparent remedy for this situation. The only purported remedy is that The Bill does
exclude Educational Institutions from its ‘misinformation’ prohibitions. However, this would not solve
the issue. Educational Institutions do not have a monopoly on research. Indeed, The Australian
Government has emphasized industry-university linkages. Myriad PhD graduates work at standard

5 Andrew C Baker, David F Larcker and Charles CY Wang, ‘How Much Should We Trust Staggered
Difference-in-Differences Estimates?’ (2022) 144 Journal of Financial Economics 370.


-----

businesses. Myriad businesses produce research and analyze data. However, the Misinformation Bill
could chill research activity in the private sector as inadvertently producing or disseminating false
information could enliven liability.

Let us take a concreate example. Disseminating false information about corporate governance could
cause companies to hire bad quality CEOs; thereby seriously harming shareholders. However, it is not
always easy to know what is false. Researchers conflict over what is ‘good’ governance. And, knowledge
evolves over time. Thus, factors that people perceived as bad might emerge to have a more nuanced
effect. But, these provisions penalize information that is disseminated in good faith merely because it
subsequently emerges that the information is incorrect. This creates an overly broad chilling effect on
communication.

### 3.2 What is “misleading”?

The Bill’s reference to “misleading” content raises issues. Misleading could be deemed to be
‘misinformation’ under the Misinformation Bill. The term “misleading” is undefined. In some cases, this
will be clear cut: It would be misleading to say that a dog is really a cat or that a cat is really a dog. In
other situations it might involve a value judgment.

The clear danger is that people deem content to be ‘misleading’ merely because they disagree with it.
This is a concern surrounding political speech. For example, it is not uncommon for political opponents
to accuse each-other of being ‘misleading’. There are ongoing examples of this in Australia that are
occurring simultaneously with the Misinformation Bill.

The Misinformation Bill is contemporaneous with a referendum in Australia. Both supporters and
opponents of the referendum assert the other side is being misleading. The referendum has presented
several controversial examples of arguably ‘misleading’ statements. The referendum would create a
body (“The Voice”) that would make representations on behalf of indigenous Australians to parliament
and the executive. However, there are arguments over misleading conduct on both sides of the
referendum.

One example is in the Second Reading speech to the enabling legislation for Australia’s indigenous voice
referendum. Mark Dreyfus stated that the proposed referendum would create an Indigenous body that
would make representations on matters that impact “Aboriginal and Torres Strait Islander peoples


-----

**_differently to other members of the Australian community” (emphasis added).[6] This is false. The_**
proposed body could make representations on all matters “relating” to Indigenous Australians. This has
been interpreted broadly to include almost all matters and it is not restricted to matters that differently
impact indigenous Australians.[7] Were that to be outside of parliament, that would be ‘misleading’ under
the Misinformation Bill.

Another example is in relation to the argued powers of the Indigenous Voice. Some assert that The
Voice body would only be advisory because it can only ‘make representations’ to the parliament and
executive government. Others argue that unless contrary arguments are given the same level of access,
funding, and political clout, empowering The Voice is akin to empowering one side of a case in a
litigation: the empowered side might ‘only’ be making representations, but because the other is
disempowered, it can drive decision-making and outcomes. Both sides believe the other is misleading.
And, this creates a conundrum under legislation such as the Misinformation Bill.

The problem is then that the Misinformation Bill could be used to suppress ‘unpopular’ speech. By
deeming such speech to be ‘misleading’ on the basis of a value judgment, regulators, or platforms, could
suppress undesirable speech. This could be the case regardless of whether the speech is ‘harmful’ given
that platforms are incentivized to over-police speech rather than under-police it. This is because the
Misinformation Bill does not require platforms to report when they have suppressed speech
erroneously.

### 3.3 What is “harmful”?

The ’harm’ component in Section 7(1)(d) is broad. It requires only that the content be “reasonably likely
to cause or contribute to serious harm”. This induces several problems.

The Bill states that content need only be “reasonably likely” to have the relevant effect. It is not
necessary to prove this with any degree of certainty. The standard of proof is unclear and vaguely
defined. It is unclear whether this would merely be a matter of supposition or it must be based on
empirical evidence: It is not clear whether the service provider (or regulator) would base this on
whether such speech has caused harm in other contexts or whether it is merely asserted to do such.

6Second Reading Speech:
[https://parlinfo.aph.gov.au/parlInfo/search/display/display.w3p;query=Id%3A%22chamber%2Fhansardr%2F26436](https://parlinfo.aph.gov.au/parlInfo/search/display/display.w3p;query=Id%3A%22chamber%2Fhansardr%2F26436%2F0005%22)
[%2F0005%22 .](https://parlinfo.aph.gov.au/parlInfo/search/display/display.w3p;query=Id%3A%22chamber%2Fhansardr%2F26436%2F0005%22)
[7 For the full amendment text, see: https://www.niaa.gov.au/indigenous-affairs/referendum-aboriginal-and-torres-](https://www.niaa.gov.au/indigenous-affairs/referendum-aboriginal-and-torres-strait-islander-voice)
[strait-islander-voice](https://www.niaa.gov.au/indigenous-affairs/referendum-aboriginal-and-torres-strait-islander-voice)


-----

The definition of “harm” is over-broad. The Misinformation Bill does not define what the difference is
between “serious harm” and ordinary “harm”. The Misinformation Bill defines harm as:

_harm means any of the following:_

_(a)_ _hatred against a group in Australian society on the basis of ethnicity, nationality, race,_

_gender, sexual orientation, age, religion or physical or mental disability;_

_(b)_ _disruption of public order or society in Australia;_
_(c)_ _harm to the integrity of Australian democratic processes or of Commonwealth, State,_

_Territory or local government institutions;_

_(d)_ _harm to the health of Australians;_
_(e)_ _harm to the Australian environment;_
_(f)_ _economic or financial harm to Australians, the Australian economy or a sector of the_

_Australian economy._

The broadness of this definition is troubling. The Misinformation Bill deems content to be harmful if it
disrupts “public order” or “society” in Australia. In so doing, Bill seeks to protest Australians’ ability to
protest. The Bill could suppress content that harms the “integrity” of the democratic process. But, this
would suppress content that validly questions election integrity even if the concerns are genuine and
fact based (cf. mere supposition). This is because fact-base critiques are a precursor to genuine inquiries
and The Bill would suppress those first step critiques. These are just several of many possible examples.

The definition of “harm” is also question begging and fails to reflect that knowledge changes over time.
For example, the Bill would suppress content that harms the “health” of Australians. But, our knowledge
about what harms “health” changes over time. For example, our knowledge about the efficacy of
vaccines has changed over time (i.e., in relation to the extent to which vaccines might prevent covid and
its spread). Similarly, in the financial sphere, our knowledge about corporate governance evolves over
time. This includes in relation to matters such as board independence, executive compensation, and
board composition. The Bill would suppress content that questions the status quo even if the status quo
emerges subsequently to have been ill-informed. This change in knowledge is manifest in how peer
reviewed journals investigate and re-investigate topics over time.

The Bill does not indicate whether this is physical, emotion, or financial harm. Given the broadness, it
presumably includes all types of ‘harm’. The bill does not specify whether the harm must be direct (i.e.,
emotional distress to the viewer) or indirect (i.e., encouraging bad behavior). The Bill does not indicate
how it would determine what is ‘harmful’. The Bill does not indicate how it would assess arguments that
weigh pros and cons.


-----

The Misinformation Bill requires only that the content “contribute to” the specified harm. It does not
require that the content “cause” the harm. This is over broad. Presumably, content can “contribute to”
harm even if it is not causally linked. It appears that repeating controversial comments as part of a
genuine critique could “contribute to” harm merely because the comments are reported or reiterated.
Similarly, defending a person’s right to have or state controversial beliefs might relevantly “contribute
to” harm even if the defender disagrees with those underlying beliefs. Further, unrelated content that
generates revenue of an organization that is deemed to produce misinformation would presumably
“contribute to” harm. If the bill is to indirectly suppress speech, that speech should at least be causally
linked to a specified harm.

Let us take a concrete example: Suppose several pieces of content promote the use of fossil fuels in the
short term because the author believes there is little immediate source of energy. Some might argue
that this could ‘contribute to serious harm’ to the environment; and thus, to people. Some of the
content providers might be nuanced. Some might lack a solid grasp of how quickly climate change is
progressing or of precisely how damaging coal fired power plants are. Then, in this case, the speech
could be misinformation. But, in such a large and complex set of content, platforms would lack the tools
to parse nuance. Thus, given the perceived reputational risk of being ‘named and shamed’ platforms
would suppress any content on this topic, nuanced or otherwise. In turn, platforms would be tempted to
suppress speech even if it is nuanced in order to risk providing speech that lacks that nuance.

## 4 Who is excluded from the Misinformation Bill?

There are significant concerns about who is excluded from the Misinformation Bill. The bill states that
excluded content is

_excluded content for misinformation purposes means any of the following_

_(a)_ _content produced in good faith for the purposes of 13 entertainment, parody or satire;_
_(b)_ _professional news content;_
_(c)_ _content produced by or for an educational institution accredited by any of the following:_

_(i)_ _the Commonwealth;_
_(ii)_ _State;_
_(iii)_ _a Territory;_
_(iv)_ _a body recognised by the Commonwealth, a State or a Territory as an accreditor_

_of educational institutions;_

_(d)_ _content produced by or for an educational institution accredited:_

_(i)_ _by a foreign government or a body recognised by a foreign government as an_

_accreditor of educational institutions; and_

_(ii)_ _to substantially equivalent standards as a comparable Australian educational_

_institution;_


-----

_(e)_ _content that is authorised by:_

_(i)_ _the Commonwealth; or_
_(ii)_ _a State; or_
_(iii)_ _a Territory; or_
_(iv)_ _a local government_

The core problem is who the bill covers and who is exempted. The bill does not justify why some bodies
are excluded from the bill. For example, why is ‘professional news’ content exempt and why is
‘professional news’ content allowed to spread misinformation? Why is the government allowed to
spread misinformation? Why are educational institutions allowed to spread misinformation? Second,
the bill does not justify why other bodies are not excluded: increasingly many Australians obtain their
news and information from YouTube, blogs, and the professional trade press. Why are ordinary small
business subject to the ‘misinformation’ probation but news organizations are not? Why are YouTubers
– who have fewer resources – subject to the prohibitions, but newscasters are not?

Excluding professional news organizations is curious. The bill defines those organizations as ones with
“rules or internal editorial standards” either covered within, or analogous to, those in professional
bodies. However, it is not clear why those editorial standards should allow news organizations to spread
‘misinformation’ more than ordinary individuals. Indeed, professional news organizations should
arguably be held to a higher standard given that they purport to follow editorial standards and can use
such standards as a symbol of authority. In this case, prohibiting misinformation from journalistic
organizations would be more paramount than prohibiting it from ordinary citizens.

Excluding government is curious. The misinformation prohibitions explicitly do not apply to information
stemming from the government. This appears to give the government license to spread misinformation.
This sends the wrong signal to the Australian public and the international community. It implies that
government communications are less trustworthy than are independent communications as
independent communications are prohibited from spreading misinformation whereas the government is
not. This exclusion also evinces a legislative intent to allow the government to communicate false or
misleading information. This is odd given that the government is better resourced than are ordinary
citizens; and thus, should be more able to ensure that it is accurate. In turn, enables an unscrupulous
government to spread misinformation while – as is discussed elsewhere – defining truthful rebuttals as
such.

The overall effect of the ‘exclusions’ is to exempt supposedly trusted authorities from misinformation
prohibitions. These institutions are better funded, purport to be trusted and accurate, and have
significantly greater institutional power. Thus, the exclusions are badly calibrated. Indeed, given that
institutional power, funding, and cache, it would be more appropriate to exclude ordinary citizens and
business from the bill and include media and government.


-----

## 5 What about overreach? Is it not reported? 

When seeking to identify misinformation there are two types of error: There is the risk of wrongly
flagging information as misinformation when it is not. And, there is the risk of failing to identify
misinformation when it exists. The Misinformation Bill specifically targets attempts to address the
second issue by requiring reports on misinformation and measures taken against it. However, as
indicated above, it is broad and could result in ordinary speech being flagged as misinformation.

The foregoing sections highlight how the legislation could cause ‘overreach’. This is due to the definition
of ‘misinformation’ being over-broad. This in turn is because it defines misinformation as being content
that is ‘false’ or ‘misleading’ and that ‘reasonably likely’ to cause ‘harm’. All aspects are vague. And,
given that the regulator is empowered to ‘shame’ platforms if it deems them to be inadequately strict,
there is an incentive to err on too much suppression rather than too little.

The Misinformation Bill does not have steps to address the overreach that it incentivizes. The
Misinformation Bill enables the regulator to request reports into ‘the prevalence of’ misinformation
(other than that by exempted bodies) and the measures taken to ‘prevent’ or ‘respond to’
misinformation and the ‘effectiveness’ thereof. However, this is targeted at the effectiveness of
suppressing ‘misinformation’, which is broadly defined. It does not explicitly pertain to whether the
measures – while effective – have the unintended consequence of suppressing ‘innocent’ content that is
not misinformation. It also does not require any reporting into misinformation by the ‘exempt’ bodies,
thereby allowing the ‘exempt’ bodies to spread misinformation unchecked.

## 6 Conclusions: What should the government do with The Bill?

The Misinformation Bill in its current form is unworkable, overly broad, and presents an unacceptable
risk to free speech. The Bill indirectly suppresses speech merely because it “contributes to” “serious
harm” if that speech is deemed “misleading” or “false” or “deceptive”. In so doing, The Bill casts a wide
net. The Bill does not adequately define what makes speech “misleading”. It fails to acknowledge that
knowledge changes over time and what was believed false at one time might emerge to be true. And,
that questioning the status quo a natural part of discourse.

The Misinformation Bill further presents an unacceptable risk to ordinary discourse. The Bill would
suppress speech even if it is not misinformation. This is because it incentivizes platforms to show that
they have suppressed misinformation. But, it does not incentivize platforms to do so accurately. Given
that the regulator would name and shame platforms for airing alleged ‘misinformation’, it encourages a


-----

broad brush approach to suppression. There is no audit or scrutiny of whether those measures
inappropriately suppress ‘ordinary’ speech.

The Misinformation Bill is also flawed in who it excludes. The Bill specifically indicates that content from
the government, media, and education providers cannot be misinformation under the law. It excludes
their content from Misinformation data gathering, reporting, and suppression. Ironically, these
institutions are the best resourced to ensure their content is accurate. Thus, the Bill appears to enable
certain organizations to espouse false and misleading information without restriction while excessively
suppressing the speech of ordinary citizens.

The concerns about this Bill are so deep and significant that it should be shelved and should not be
revived. If the Bill were to be refined, it must cover all Australians and there should be no exclusions for
media, government, or education providers. It must also focus on a significantly narrower and more
specific set of content. It further must incentivize platforms to avoid suppressing ‘innocent’ content.
However, even with these fixes, it is not clear that the Bill is desirable as a matter of policy or is
workable.


-----

