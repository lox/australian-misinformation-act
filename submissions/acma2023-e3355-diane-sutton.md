# Submission re the Misinformation Bill 2023

**1. Introduction**
I have worked in & owned microbusinesses in the digital services industry for over 10 years. I believe
this Bill is poorly conceived in principle, poorly written, ineffective for its stated purpose and likely to
create significant harm.

My concerns include:

  - failure to identify who or what will decide whether content is mis/disinformation, or how this
will be done

  - contrary to multiple common law principles & freedoms

  - achieves nothing of benefit to the people of Australia that current legislation does not

  - vague, ill defined and open to abuse

  - facilitates unidentified, unaccountable entities defining ‘truth’ & controlling information online

  - no mechanism for appeal

  - no protection against erroneous, vexatious or malicious complaints & factchecks

  - supports anti mis/disinformation action that affects all Australians’ access to online content,
even if the perceived at-risk-of-harm group is tiny

  - while allegedly protecting us from mis/disinformation: permits governments, governmentapproved educators & professional news media to disseminate such content without limitations

  - destroys the founding concept of the Internet as a medium of open communication

  - burdensome & technically impractical reporting requirements

  - excessive penalties

  - does not distinguish between complaints made to a provider, and confirmed publication of
‘mis/disinformation’

  - gives the ACMA considerable extra power, and the capacity to extend its power without
reference to Parliament

  - disproportionate burdens for smaller digital platform providers

  - a document of domination and control, not fit for any democracy.

This Bill places government & selected commercial interests where they should never be: intervening
in & controlling the process of public debate, enquiry, discussion and interaction of ideas. Neither
governments nor corporations can be trusted with the power the Bill gives them.

**2. Not Needed**
Wherever there is potential to cause real harm via online content, eg incitement to violence: there are
already laws in place.

Even the Government’s own factsheet can’t come up with realistic examples that are not covered
under existing legislation.

The factsheet claims that, ‘Misinformation and disinformation spread via digital platform services is a
major issue worldwide. The rapid spread of false, misleading and deceptive information online has
resulted in a multitude of harms from disrupted public health responses to foreign interference in
elections and the undermining of democratic institutions.’

Even if this claim is true, the factsheet does nothing to address the vital question of whether this Bill,
with its extraordinary exclusions for news media, educators and governments, will improve matters;
or whether it will cause more harm than any supposed mis/disinformation.

**3. Imagined Possibilities Turned into Legal Offences**


-----

The Bill relies on assertions (which might be guesses, informed estimates or malicious attacks on free
speech) about how Aussies or ‘a group’ of Aussies might respond to, or might be harmed by, online
content. It twists imagined potential response into actual wrongdoing.

Just because something is published online does not mean anyone will believe it or respond to it in
any way, good or bad. To enforce high penalties on the basis of subjective, perceived ‘possible’ (not
actual) harm is not justice.

**4. Who Judges Content as ‘Mis/Disinformation’?**
If the Bill is enacted, freedom of speech online for Australians will rely on defining whether specific
content is mis/disinformation. The Bill ignores this key issue.

The Bill inevitably fosters development of (perhaps faceless, unaccountable) individuals or entities
that effectively control information flow online, and powerfully influence public debate and Australian
lives. The Bill either turns every digital platform provider into an arbiter of truth; or it turns them into
agents for whatever entity gains the privilege of deciding ‘truth’ and ‘mis/disinformation’.

The publicity material claims that the ACMA will not define truth about specific content. However, in
practice the ACMA or any government agency has considerable power to influence online content.
They can target digital platform providers that permit specific content, creating & submitting high
volumes of complaints. Government agencies have done so before (see Senate committee hearings
2023).

There is no provision for accountability on decisions about mis/disinformation status of content, or for
openness about the procedures, expertise & sources used to classify content. There is no requirement
for appeal processes or reinstatement where authors or others believe that content has been wrongly
classified.

As to suggestions that the task of identifying mis/disinformation could be undertaken by factcheckers,
AI bots or other entities… These have no demonstrated competence, objectivity, loyalty or
accountability to Australians, to our wellbeing, to truth or to democratic process in this country.

The more that a singe view predominates online, the more that factcheckers & AI bots will ‘find’ only
that view & the more they will foster it as the ‘main’, ‘true’, or ‘generally accepted’ view. Because
there is no sure capacity for review & correction, the process of (rightly or wrongly) assessing certain
content as mis/disinformation becomes a self-feeding loop.

_Factcheckers_

i. Internet factcheckers are largely owned or funded by the big social media giants. ‘He who pays
the piper calls the tune.’ Their findings are susceptible to influence from their major
clients’/owners’/employers’ policies, which in turn depend on those entities’ ultimate
ownership.

ii. Factcheckers have published blatantly false ‘fact checks’ showing ignorance of the subject

matter, of scientific data & of the actual content being checked.

iii. Factcheckers need no known expertise, no proven qualifications & bear no accountability for

the accuracy or the consequences of their published work. They can hide behind pseudonyms
or create fake online IDs. Yet the future of all Australians could rely on their pronouncements?

_Peak bodies_
Industry peak bodies’ codes of conduct are only binding on members. They help enforce conformity &
compliance on some providers; that has nothing to do with competency in deciding truth of content or
protecting free speech.


-----

_AI bots_
AI does not guarantee objective fact; it merely means no one is held accountable, and that we don’t
know the degree or direction of underlying prejudices or influences. They are certainly there. AI chat
bot software is not created or operated cheaply. There has to be subtantial gain in sight for its
corporate owners.

AI responses:

i. vary depending on the questioner’s recorded history of enquiries

ii. can deliberately be tilted by wording of the question or prior questions
iii. are a conglomeration of information/claims published online and ranked, rated or ignored

by the IT company which codes the specific AI bot, using (usually secret) algorithms. The
algorithms are designed by flawed/ prejudiced/ambitious/not guaranteed truthful humans,
not to protect Australians from harm, but to meet the objectives of the owner corporation.

AI technology is not designed as an arbiter of truth or a custodian of facts. It is an abuse of
Australians’ freedoms and abuse of our right to unprejudiced and fair legal procedures, to treat it as
such.

**5. Open to Abuse**
The Bill makes it too easy to brand dissension from a favoured policy or from a highly profitable
project as ‘mis/disinformation’, and to keep uncomfortable facts quiet for a time. Big Tech providers
have an obvious interest in pleasing government & large corporate advertisers, & little or no
commercial interest in supporting truth at potential financial loss to themselves.

To operate without harming free speech, the Bill would require:

(i) That all digital platform providers (whether Australian or overseas), professional news
media, educators, governments & government agencies hold firmly to free speech ideals &
moral integrity.

(ii) That there are readily identified reliable, objective, disinterested sources to arbitrate justly
on the truth, harm potential & mis/disinformation status of disputable online content on any
subject matter.

(iii) That whoever is relied upon to label content as mis/disinformation, can & will:
◦ take due care to access complete, accurate & unbiassed knowledge;
◦ apply that knowledge without prejudice, without thought of gain, & without coercion or

any pressure personally, politically or financially;

◦ welcome and give due consideration to public submissions questioning the

mis/disinformation status of content;

◦ give due weight to free speech considerations; and
◦ update ‘mis/disinformation’ claims as soon as valid contrary evidence comes to light.

The very existence of laws & of public debate - and of elections & other constitutional mechanisms to
remove governments - is because such assumptions about all human beings, corporate entities &
institutions are never valid.

Corporations & IT businesses exist purely for their own purposes. These include profitability of parent
or affiliated companies that may (and in the case of some social media, do) have major investments in
other industries. Digital platform providers gain large revenues from advertising. This creates obvious
conflict of interest in assessing whether content contrary to their advertisers’ desires is
‘mis/disinformation’, and how they deal with it.


-----

The Bill depends on digital platform providers and their factcheckers &/or AI software to judge,
report, manage & block/allow information, on subjects in which they are not and cannot be either
expert or objective.

**6. Poor Wording**
Subjective and ill-defined wording means the Bill’s effects cannot cover fully, or be limited to, its
stated intentions.

This Bill would trigger long legal arguments over the veracity and authority of factchecks, ‘reasonable
likelihood’, perceived intention of content authors & relative ‘seriousness’ of possible harm. Its
endemic vagueness is a money spinner for lawyers, but no use for protecting Australians.

Eg:

i. ‘harm’ is defined as ‘harm...’ in several subclauses, a circular definition and legally unusable;

ii. there can be no objective measure of ‘reasonable likelihood’. In my judgment as an Australian

_citizen with reasonable English & logic skills, all of the ‘harms’ envisaged by the Bill & its_
publicity information are unreasonable and unlikely. Obviously others disagree;

iii. ‘can cause or contribute to...’ is wideranging and not provable;
iv. ‘serious harm’ is ill-defined, & unless harm has actually occurred, it is a subjective assessment.

Content that naturopaths regard as truthful & highly beneficial, a pharmaceutical manufacturer
may brand as misleading & seriously harmful. And vice versa. Scientific studies can be
devised & their results presented in ways to support either position;

v. ‘disinformation’ - how can a digital platform provider prove an author’s intention to deceive &
cause serious harm?

The Bill’s vague language gives broadbrush powers to the ACMA to take decisions and actions
without guidance from the Bill itself and, it seems, without accountability. Here are some indicative
quotes from the fact sheet, guidance note & the Bill:

  - ‘Should the ACMA determine….’

  - ‘If the ACMA is satisfied that a body or association represents…’ [What competence could the
ACMA have to decide this?]

  - ‘...the ACMA may consider...’

  - ‘The ACMA may decide to... Alternatively the ACMA may choose to...’

  - ‘...any circumstances the ACMA considers relevant...’

**7. Contradictions & Absurdities**
The Bill pretends that:

i. someone, somewhere knows precisely what is ‘reasonably likely’ to be mis/disinformation and
what isn’t;

ii. this anonymous Someone is superior to most of us Australians, who can’t safely be exposed to

such mis/disinformation to judge it for ourselves without being ‘reasonably likely’ to suffer
terrible harm. The mysterious Someone is apparently impervious to such effects;

iii. however, if the same information is published offline, it would not be ‘reasonably likely’ to

cause the same harm to anyone in Australia. So no legislation is needed to cover that risk.

The whole scenario is absurd.

Uncertainty & different angles on truth are part of real life. It is a tenet of science that science is
always a struggle towards truth, it never attains the full picture or is ‘settled’. Similarly for many other
areas of life. Content that a leftleaning young person regards as false or misleading, and significantly
harmful, is truthful & beneficial in the eyes of an older person. We see this disparity of views in our
own families, let alone across an entire nation. It is in the ‘marketplace of ideas’ through free speech,


-----

enquiry, discussion, disagreement and honest debate that truth, mutual understanding and best
community decisions are reached.

_Contrary to this reality, the Bill assumes that:_

i. there is one unassailable, unquestionable truth on selected medical, public health & other
topics;

ii. dissent, questions or apparently contrary facts are potentially harmful; and
iii. Australians need to be ‘protected’ from them.

This is either a useless Bill which can’t be applied to any online content at all; or it is fully intended to
serve the interests of one side in public debate, by allowing narratives to be deceptively or recklessly
branded as mis/disinformation.

The Bill also makes unwarranted distinctions between who is and isn’t permitted to spread content
that could be classed as ‘mis/disinformation’. The Bill irrationally assumes that although harm is
‘reasonably likely’ to result from publication by some, that risk is always removed – or is no longer
important – if the same content is published by governments or by approved news media & educators.

  - ‘Professional’ news media can publish content that, if others published it online, would be
mis/disinformation; ‘nonprofessional’ news media can’t.

  - ‘Professional news media’ can; professional social/political commentators can’t.

  - An MP can in Parliament. News media can report that speech, & can abbreviate it to put the
alleged mis/disinformation out of context; but social media platforms can’t publish a video of
the full speech for Australians to hear what was actually said in our own Parliament.

  - Educators can freely provide online content to minors which is false, misleading & likely to be
harmful. If non educators publish the same material online, targetting adults: we are spreaders
of mis/disinformation.

The Bill differentiates between online content and content delivered by other means. Why? If content
is ‘reasonably likely’ to seriously harm online, why is it not ‘reasonably likely’ to harm offline? This
suggests an intention behind this Bill which has nothing to do with supposed risk of harm to
Australians, and much to do with online platform – Government relationships. One possible reason is
to facilitate control & manipulation of public discourse by far-from-independent online factcheckers
&/or by AI.

**8. Unclear & Unpredictable Scope**
It is not clear who will be caught in the net. In its publicity, the government only gives examples of
digital platform providers, not a full listing.

The Bill allows the Minister to extend or narrow down the scope of ‘digital platform provider’ by
legislative instrument. The term is a movable feast. Where exactly are the lines drawn (today), and
why is it so unclear?

Possibly the Bill already includes the owner of any website (even the smallest personal website)
which allows public or even only member-restricted comments on a webpage, as a ‘digital platform
provider’. Is a webhost also a ‘digital platform provider’? What about the web developer who builds
the site, or the developer & licensor of content management or other software that allows the owner as
licensee &/or online users to post content?

It’s impossible to know how extensively this proposed legislation might be used. It leaves individuals
and microbusinesses vulnerable to sudden, unmanageable compliance & recordkeeping requirements,
& huge penalties.

**9. Arbitrary Power Without Accountability**


-----

Who is to decide what is and isn’t mis/disinformation to be hidden from 26 million Australians? Who
would assess the ‘truth’ of specific content or the ‘reasonable likelihood’ of harm? On what basis?

Under the Bill, we don’t know.

We do know that ‘they’ are not accountable to Australians to justify their decisions. They are not
subject to independent assessment, review or Parliamentary guidelines. Yet their word would be
powerful enough to close down a social media page, a website or a business, or silence an online
protestor.

What is acceptable online content under this Bill can change any time, any day or never. Acceptable
content one day might be in breach of law the next.

‘Mis/disinformation’ vs truth is apparently not for ordinary Australians to decide, or have any input to.
But whatever the distinction is, will control us totally online.

Fear, uncertainty, timidity to speak up online & capacity for online intimidation (a form of
cyberbullying) are the inevitable outcomes.

**10. Complaints Process Open to Abuse**
The Bill opens a wide door for mischievous complaints & malicious or wrongful cancellations of
content or of authors. There is no penalty or deterrent for these actions.

This is an invitation for people without conscience or without loyalty to Australian values or other
entities to pressure digital platform providers to shut down debate via spurious, high volume
complaints. They can effectively pressure providers to censor views they dislike or to bar publication
of embarrassing comments.

Senate committee enquiries in 2023 revealed extensive ‘misinformation’ complaints registered with
social media providers by government agencies. There is no reason to suppose this will not recur. One
outcome of this Bill will be that governments, issues & policies cannot be freely scrutinised and
critiqued online.

Spurious ‘mis/disinformation’ complaints can & will be used to bring down a business competitor or
other rival. This behaviour is attested already online, in strategies such as distributed denial of service
attacks. I have seen this firsthand in my work, used against an Australian business. In the case of
mis/disinformation, the target could also be competing or innovative digital platform providers.
Unscrupulous & ambitious businesses, groups or individuals can easily submit (or fund 3[rd] parties to
submit) 1000s of false or mischievous complaints, to swamp selected digital platform providers’
resources. ACMA investigations can be based on volume of complaints; not on valid complaints
upheld. So a high volume of fake complaints can trigger investigation of the digital platform provider
(not the perpetrators) by the ACMA, at great cost, inconvenience, lost business reputation and lost
time for an innocent digital platform provider.

**11. Harms to Free Speech**
_Impingement on Personal Freedoms_
The Bill interferes with freedom of conscience and freedom of religion, and removes responsibility
from human individuals to respond to information & the world as they see fit. To abrogate that
responsibility is to take away human agency and what it means to be human. That is outside any
government’s ambit.

There is a token nod to freedom of ‘democratic processes’, not defined. But the Bill gives no overt
protection, except to authorised electoral content. Its protection of democratic freedoms appears


-----

limited to exempting authorised content at times of election & referenda from misinformation
provisions. However, democracy & democratic process are far wider than elections & referenda.

Without any guidelines, definitions, or objective review or appeal process, the Bill is unlikely ever to
protect any freedom of speech. Yet if properly applied, common law religious & democratic freedom
exceptions would release a huge amount of content from its mis/disinformation controls.

_Promotes Overreaction_
From the guidance note: ‘The Bill is not intended to curtail freedom of speech, nor is it intended that
powers will be used to remove individual pieces of content on a platform.’

This is nonsense. What else does the ACMA or the government imagine would happen? It might not
be ‘intended’ that way; but curtailment of free speech & content removal will certainly result from the
threat of ‘remedial action’ enforced by the ACMA & from the threat of very large penalties.

The Bill creates considerable incentive & no disincentive for digital platform providers to act overconservatively and treat overly-broad classes of content as mis/disinformation. It would cost digital
platform providers far more to let one mis/disinformation post through, than to falsely label much
innocent content.

Providers will be self-protective when they assess ‘reasonable likelihood of ‘harm’ from a post and
author’s intention. They will base their judgments on ‘guilty until proven innocent’. As has been seen
in the past few years: one easy fast way to do this is to ban a content author or an account. This
blatantly prejudices democratic process and destroys free speech & open debate.

In effect, the Bill encourages online censorship on basis of commercial risk assessment. Real risk of
community harm, falsehood or perceived intention to deceive might have little to do with many
decisions at the coalfront.

_How the Bill Impedes Freedom of Speech_
The Bill fosters control of public interaction and debate between free (not criminal) citizens of a
democracy. It pretends to ‘protect’ democracy but can only stifle open debate. This Bill is a ready
weapon for unscrupulous or ideologically driven operators to manipulate the minds of a population.

Currently, any website owner or digital platform provider (such as X, Meta, Gab etc) can decide who
can publish on their site, under what conditions, and what kind of content can be published. Service
providers set their Terms in accordance with their own views and the aims of their website/platform.

Such Terms are not binding on all platforms or all providers. They are part of the diversity in a
thinking, creative, intelligent and educated population. Authors can go elsewhere if they want to get
rejected content published. They can build their own website, change webhosts, or use an alternative
digital platform.

But it’s different if content is barred from one platform apparently under the provisions of a
misinformation Act, even if the provider or their factcheckers acted in error or in bad faith. It then
becomes difficult to publish online on any platform. Unless, that is, the content author & their new
provider are willing to risk lengthy expensive proceedings and possible fines. Even if the case
eventually goes their way, the damage is done. Information has been withheld from the public,
perhaps at a crucial time politically, commercially or for social influence.

_Controlling ‘Truth’_
Governments, & Big Tech & other commercial interests, & even nameless or known factcheckers, are
not & cannot be the arbiters & minders of truth. This endangers human freedom.


-----

Once ‘mis/disinformation’ censorship starts, it self-propagates. Internet users & AI bots will find a
higher & higher proportion of online content that proffers the accepted ‘narrative’ because alternative
views & even contrary evidence are deleted or marked as unreliable. Under the bots’ modus operandi,
that narrative gains ever higher status.

Thus a false appearance of ‘truth’ or ‘reliability’ can be created by erroneous or deceptive use of
mis/disinformation status, hiding content which does not match some powerful entity’s preferred
narrative.

In this way, the Bill can be one step along the road to ‘AI’ dictating reality to humans. Of course AI is
only really a tool wielded by people; but it can become a powerful hidden influence on society,
without most people ever realising how they are being played.

**12. Severe Penalties**
‘Digital platform providers that contravene record keeping rules, or who fail to comply with remedial
directions, will face civil penalty proceedings and may be fined up to 5,000 penalty units ($1,375,000
in 2023) for corporations or 1,000 penalty units ($275,000 in 2023) for individuals. A digital platform
provider will commit a separate contravention in respect of each day during which the contravention
continues.’ (Guidance note)

Why such huge penalties for a record keeping failure? Or evenfor noncompliance with remedial
directions? Remember that many small & microbusinesses in the digital services sector, and even all
websites and website owners, could one day be subject to misinformation provisions and to these
penalties. The Bill says so.

Actual penalties depend upon assessment by ACMA of factors such as actual harm caused or risk of
harm. How can ACMA judge this, especially when ‘harm’ includes subjective items such as ‘hatred’?
What is ACMA’s competence in this?

A digital service provider may in good faith satisfy itself that specific content is not
mis/disinformation, and therefore not remove it or mark it as such. What if ACMA disagrees? Could
the ACMA pressure a provider to take action despite the provider’s own assessment, under the threat
of these insupportably heavy penalties for ‘noncompliance’?

By contrast, the EU Act cited in the guidance note sets penalties consistently in proportion to the size
of the provider and its capacity to pay. That (if some form of Misinformation Bill is adopted) seems
fairer.

**13. Reporting**
Digital platform providers are to provide Australia-specific data about reports & complaints.

This looks impractical technically. How does a provider know that a complaint or a user or
mis/disinformation content is Australian? Any method is between a very rough estimate and
guesswork.

  - All websites that could have an EU audience, must provide an optout from session cookies &
trackers under GDPR rules. The optout has to come into effect before cookies trace or record a
user’s IP address. Australians can make use of that option too, to prevent their IP addresses
being recorded.

  - Australian platform users & complainants can have email addresses without .au, overseas IP
addresses, VPNs obscuring their location or use a false online ID.

  - Overseas users & complainants can fake an Australian email address.

  - Anyone can tick ‘Australia’ as easily as ‘Sweden’, if a complaints form asks for location.


-----

  - No malicious complainant will provide true details about themselves.

  - No one can know what proportion of users truthfully indicate Australian status on any digital
platform.

  - Similar objections apply for content authors.

The Bill burdens providers with an impossible task. In my judgment (and I majored in maths),
resulting records & statistics would be statistically invalid as ‘Australia-specific data’. From my
experience working in public service: governments would quote them regardless.

**14. ACMA**
_Investigations_
Complaints of (not proof of) systemic or patterns of mis/disinformation on a service may trigger an
ACMA investigation. The ACMA can also investigate digital platform providers merely on volume of
complaints, regardless of their validity.

This is liable to abuse.

Ideologically convinced crusaders or paid actors will target any digital platform providers that
regularly publish what these complainants regard as mis/disinformation. That will force numbers up.
But a complaint is only an allegation about mis/disinformation. Existence or prevalence of complaints
is no reason for the ACMA to swing into action against a digital platform provider. If it does, it has
made a judgment about the truth of these complaints, and thus about the truth of specific content;
which the fact sheet tells us the ACMA will never do.

Whether the ACMA would/could verify complaints before investigating a digital platform provider,
and how this is done, are not clear.

_Codes, Standards & Peak Industry Bodies_
From the guidance note: ‘The ACMA may examine the codes it has previously registered when it
considers a code for potential registration to avoid conflict between a new code and existing code.’

In other words, the ACMA may ensure little or no variation between registered codes of industry
bodies that represent different groups of digital platform providers, with different capacities & needs.
This ‘first in, best dressed’ approach would give smaller providers little say in codes governing our
affairs. Digital Industry Group Inc (DIGI),which only represents very large corporate digital platform
providers, has a considerable headstart with its existing voluntary code. It would be very likely to be
the first code registered. As an industry body for the largest digital platform providers, DIGI of course
establishes a code to suit its own members. Large corporations can dedicate resources for reporting,
factchecking & complaints handling in ways that small players cannot. They also benefit through
partnerships, communication & influence at government level, from which small businesses are
excluded. The DIGI code was developed in consultation with government; it is unlikely to be rejected
by the ACMA.

Smaller digital platform providers need legislative assurance that the ACMA must take our situation &
needs fairly into account.

Small & microbusinesses scattered nationwide cannot be expected to meet, agree on shared views &
form an independent peak body in anything less than 1 year. This Bill allows the ACMA to require
such a process to be completed within 6 months after any start date the ACMA chooses. Worse, if
those businesses fail to organise into a peak body, or fail to develop an acceptable code to the ACMA’s
deadlines, they face being subjected to the ACMA’s own invented standard and they face bigger
penalties for noncompliance than if a registered code is breached. This is blatantly prejudicial against
smaller digital platform providers.


-----

The public consultation clause for ACMA-imposed standards is a furphy. The Bill puts the ACMA
under no compulsion to take any notice of public input; it is free to set whatever standards it wants.

**15. IT Innovation, Marketplace Competition & Small Business**
If it actually covers, or is later extended to cover, smaller local digital service providers, the
Misinformation Bill would work against them in favour of the global giants. The latter can easily
afford complaints handling & compliance (reporting) costs & stafftime which are beyond small
business resources.

Our own Internet related business would be at risk. We would be under strong financial pressure to
handpick our clients for their likely innocuousness, not adding to our compliance costs and not likely
to trigger [genuine or nuisance] complaints. That is effectively a hidden form of online censorship, as
well as interference with free trade.

Government intervention like this can only serve to stifle innovation and technical excellence locally.
As local businesses fail under the compliance load, or their prices are forced too high, more Australian
data & customers and income will be diverted to global corporations.

Then we Australians would be more easily controlled via public-private (global corporate)
partnerships, from which smaller operators are excluded.

**16. Divisive**
The Bill creates an environment of fear, suspicion and dobbing. It sets people & corporate entities
policing one another, in fear of being blamed for others’ online actions: a cancel culture injurious to all
Australians and our way of life. It supports the divisive & restrictive cancel culture already operating
in social media, and entrenches it as law.

**17. Clashes with Common Law**
The Government is established under a Constitution founded upon common law & its legal actions are
limited by common law. This Bill contravenes common law in many respects. In my view, common
law would render much of it void if enacted.

_Uneven Application_
One of common law’s foundations is that individuals & legal entities are equal under common law.

But this Bill differentiates between government/professional news media/government approved
educators, and all other legal entities/individuals. What is treated as 100% acceptable & legal
behaviour for the former, is 100% illegal for the latter.

There is no excuse for Governments to spread misinformation online; still less ‘disinformation’, that
is, with the deliberate intent of harming Australians. Yet this Bill grants governments leeway to do
exactly that. Similarly for professional news media. There is no restriction in the Bill of context in
which professional news media could legally spread ‘mis/disinformation’, eg no requirement that it be
as a quote or report of an event (or alleged event). Perversely, readers who comment on the same news
article can have their comments removed as mis/disinformation. This skews the news media’s
presentation of public opinion.

_Responsibility for Own Actions_
The Bill contravenes a basic principle of law by holding a digital platform provider accountable for
dealing with alleged actions & even alleged intentions of its users. This breaches the fundamental
legal principle of responsibility & accountability of adults for one’s own actions.


-----

_Treats Adults Under the Law as Infants or Mentally Incapable of Managing our Affairs_
The Bill sets up governments, peak IT industry bodies, digital platform providers & their chosen
sources to ‘check facts’ as if they know more than most Australians about what information is sound
or not, & as if they should make the ‘right’ decisions ‘for us’.

This could only be needed if 3 untenable assumptions held true:

i. Australians are incapable of functioning online without ‘harm’ unless these bodies intervene to
protect us;

ii. adult Australians ought to be treated under law as babies or toddlers, without capacity to make

informed judgments & decisions about how they live & interact with the world; and

iii. government & social media companies are benevolent parent figures, whose desire and

responsibility is to protect us ‘children’ under their care.

It is not the government’s responsibility to ‘protect’ us in this fashion. Nor is it any private
corporation’s role. The government does not have authority to decide, or to confer the power to any 3[rd]

party to decide, what is mis/disinformation and prevent us from viewing it online.

Under our Constitution, Government is the servant of the people of this Commonwealth. We the
people are responsible to rule over & judge governments’ words and actions. We as free people
remove them from office if they fail to act for the good of ‘us, the people’. The Bill tries to reverse
this, so that we become subservient to the decisions of 3[rd] parties appointed at the Government’s
behest (even if not directly by government) about what is good for us, and what we are allowed to
publish or find out online.

_Right not to self-incriminate_
The guidance note trots out the usual excuses for trying to remove this common law right. If a person
can’t be forced to self-incriminate on a murder accusation, why on a mis/disinformation accusation?

Opining that removing this right ‘might only affect a few people’ is irrelevant. It is also misleading,
given that the Minister can seek at any time to extend the definition of digital platform provider to
include other digital service providers: eg every website owner.

_The Bill’s ‘Freedom under the Constitution’ Clause_
I reasonably expect Bills to be drafted by persons competent in Australian law. I see no occasion for
including an ‘If any of this isn’t legal under the Constitution, please just ignore’ clause.

Freedom of speech is not given to Australians by the letter of the Constitution, as the drafters of this
Bill ought to know. The Constitution links us to our common law heritage, and common law
_recognises (not confers) our freedoms of speech, association & religion. These freedoms cannot_
legally be removed.

Submission by Diane Sutton
(contact details supplied)


-----

