# Submission to the Department of Infrastructure, Transport, Regional Development, Communications and  the Arts

 Response to consultation on proposed new ACMA powers to combat misinformation and disinformation

## August 2023


-----

### Summary of recommendations

_Recommendation 1_

_That the definition of ‘private message’ in the Draft Bill be clarified in the text, as a note or in the_
_Explanatory Memorandum so that it also includes messages addressed to limited groups of_
_people, even where those people have not been individually selected (eg. private group_
_messages). This clarification could be given specific limitations, such as that a group cannot_
_exceed 200 people, to give certainty to the Government’s clear expectation that a ‘private_
_message’ must genuinely be accessible to a very small number of individuals only._

_Recommendation 2_

_That the Draft Bill be amended so that messaging in small and temporary online environments_
_such as video game worlds, servers and lobbies also be considered private messages, or_
_otherwise treated as lower-risk content under the proposed new regulation._

_Recommendation 3_

_That subclause 4(1) of the Draft Bill be amended to include the specific exclusion of ‘an online_
_video game service’ from the definition of ‘digital platform service’, such as through the addition_
_of a new paragraph (h). An ‘online video game service’ could then be defined as a “service that_
_enables end-users to play online games with other end-users”, terminology already used by the_
_Online Safety Act 2021._

_Recommendation 4_

_That the ‘primary function’ test at paragraph 4(3)(a) of the Draft Bill be amended so that it is_
_limited to online communication between 2 or more end-users, rather than online interaction._
_‘Communication’ should be clearly defined in the Draft Bill as meaning the sharing of content_
_(with ‘content’ have already been defined in the Draft Bill)._

_Recommendation 5_

_That paragraph 4(3)(b) of the Draft Bill be amended so that it covers digital services that allow_
_end-users to ‘communicate with, or share information with’, other end-users, rather than ‘link to,_
_or interact with’._

_Recommendation 6_

_That the Government consider whether the definition of ‘content’ at clause 2 of the Draft Bill is_
_impracticably broad and should be narrowed to only include forms of content that can carry_
_misinformation or disinformation._

_Recommendation 7_

_That the Government explicitly exclude VoIP from the definition of ‘content’ at clause 2 of the_
_Draft Bill._

_Recommendation 8_

_That for the avoidance of doubt, the definition of ‘media sharing service’ in subclause 4(4) of the_
_Draft Bill be amended to also include ‘interactive content’. Alternatively, should the Government_
_consider that this may be confusing given the different use of ‘interactive’ elsewhere in the Draft_
_Bill, that the Explanatory Memorandum note that digital game distribution platforms and game_
_streaming services are intended to be covered by the definition._


-----

_Recommendation 9_

_That the ACMA’s powers related to record keeping and reporting (Division 2) and information_
_gathering (Division 3) be amended so that they can only be exercised if the ACMA is satisfied,_
_to a reasonable extent, that there is misinformation or disinformation on a particular digital_
_platform, or that it is at serious risk of misinformation or disinformation._

_Recommendation 10_

_That the Government provide further clarity around the statement of regulatory policy in terms_
_of how it applies to digital platforms or subgroups of digital platforms that present a_
_demonstrably low risk for misinformation and disinformation such as video game services._

_Recommendation 11_

_That the Government clearly state in clause 37 the Draft Bill that multiple codes by bodies or_
_associations representing different subgroups within a section of a digital platform industry can_
_also be registered. Other similar amendments should also be made elsewhere in the Draft Bill,_
_such as around compliance by participants in a particular section of a digital platform industry_
_and ACMA’s power to determine standards covering sections of the digital platform industry._

_Recommendation 12_

_That clause 38 of the Draft Bill be amended to clarify that the ACMA may request codes covering_
_subgroups of a section of the digital platform industry. Paragraph 38(3)(a) should also be_
_amended so that before exercising its power to request codes, the ACMA must also consider_
_whether such a request would be unreasonably burdensome to all of the participants within the_
_relevant section._

_Recommendation 13_

_We recommend that the Government give full consideration to the recommendations made by_
_DIGI in its response to the present consultation._


-----

### Introduction

The Interactive Games & Entertainment Association (IGEA) is the industry association
representing and advocating for the video games industry in Australia, including the
developers, publishers and distributors of video games, as well as the makers of the most
popular gaming platforms, consoles and devices. IGEA also organises the annual Games
Connect Asia Pacific (GCAP) conference for Australian game developers and the Australian
Game Developer Awards (AGDAs) that celebrate the best Australian-made games each year.
IGEA has over a hundred members, from emerging independent studios to some of the largest
technology companies in the world.

IGEA welcomes the opportunity to provide our feedback to the Department of Infrastructure,
Transport, Regional Development, Communications and the Arts (the Department) on the
exposure draft of the Communications Legislation Amendment (Combatting Misinformation
and Disinformation) Bill 2023 (the Draft Bill). We note that the Draft Bill, if passed in its current
form, will provide the ACMA with several new powers concerning misinformation and
disinformation, including the powers to gather information from digital platform providers, to
enable the ACMA to request industry bodies representing digital platform providers to
develop codes of practices, and to enable the ACMA to create industry standards.

We have reviewed the Draft Bill in detail, together with the guidance note and fact sheet also
released by the Department, and we are pleased to be able to provide our response, which
comprises the rest of this submission. In our submission we have chosen to focus on several
specific concerns that we have identified with the interplay between the Draft Bill and some
video games and gaming-related platforms within our industry. While we recognise that video
game platforms are not likely to be the intended target of the proposed reform, this also means
that the manner in which these platforms operate are not likely to have been specifically
considered during the design of the Draft Bill, potentially leading to unintended consequences
including impractical regulatory impacts to gaming platforms that present little to no risk of
misinformation or disinformation. We have provided recommendations for changes to the
Draft Bill. Finally, in this submission we also acknowledge our support of DIGI’s submission.

### Feedback on elements of the Draft Bill

**Definition of ‘private message’**

Under the definitions set out in clause 2 of the Draft Bill, a ‘private message’ is defined as:

_“an instant message sent using a digital platform service from one end-user of the_
_service (the sender) to one or more other end-users of the service (the recipients) where_
_the message is only observable to end-users of the service selected by the sender or any_
_of the recipients.”_

This definition is critical because, for the most part, the Draft Bill does not apply to private
messages and codes must not contain any requirements related to their content. While the
drafting of this definition has likely been specifically informed by the operation of the most
popular social media and communications platforms used by Australians, the extent to which
it will cover some video games and gaming platforms is unclear. We also note that no definition
has been provided for a ‘public message’.

While direct messaging between game players within gaming environments appears to be
covered by the definition of ‘private message’, it is unclear whether other kinds of


-----

communications in the gaming environment would also be covered. We have highlighted
some examples below.

**Form of in-game messaging** **Example(s)** **Is it a ‘private**
**message’?**


1) Direct messages to a game
player known to the messenger.

2) Direct messages to a game
player not personally known to the
messenger.

3) Group messages to players
personally known to the

messenger.

4) Group messages to players not
personally known to the

messenger (or a combination of
known and unknown persons).

5) Posting messages within a
particular game server, world or
lobby, mostly populated by players
not personally known to the player.
These kinds of messages are
typically impermanent and often
only last for a few seconds.

Messages to members of a group


Sending a message to a known friend in
the messenger’s contact list within a
game (eg. saying “hi” to your real-life
friend’s avatar).

Sending a message to a specific player in
a battle game (eg. saying “defend the left”
to a randomly-assigned unknown

teammate).

Sending a group message to the
members of an invite-only team or clan
(eg. asking “are we playing tonight?” to a
clan’s chat forum).

Group messaging within a 3 v 3 strategy
game where teammates and opposition
team members are chosen randomly
from available online players (eg. sending
”good luck” to the opposite team through
a ‘send to opponents’ chat option).

Engaging in the scrolling chat feature for
an open world game that the player has
been placed in by the game’s servers (eg.
posting a “hello” message to the 50-100
players in a particular game server).


**Yes,** **this** **is** **a**

**private message.**

**Yes,** **this** **is** **a**

**private message.**

**Send a message**
**to the members of**
**a small group is**
**likely** **a** **private**

**message, but not**
**entirely clear.**

**Send a message**
**to the members of**
**a small group is**
**likely** **a** **private**

**message, but not**
**entirely clear.**

**Possibly** **not** **a**
**‘private message’**
**under the existing**
**definition.**


In our view, we expect that it is the Government’s intention that examples 3 and 4 above should
be considered private messages. However, we believe that there is some uncertainty
surrounding whether a message to a group, where the messenger has not specifically selected
each recipient individually, would meet the definition of a private message under the current
wording of the Draft Bill. We recommend that this be specifically addressed.

_Recommendation 1_

_That the definition of ‘private message’ in the Draft Bill be clarified in the text, as a note or in the_
_Explanatory Memorandum so that it also includes messages addressed to limited groups of_
_people, even where those people have not been individually selected (eg. private group_
_messages). This clarification could be given specific limitations, such as that a group cannot_
_exceed 200 people, to give certainty to the Government’s clear expectation that a ‘private_
_message’ must genuinely be accessible to a very small number of individuals only._


-----

Posting in small and temporary online environment

It is our interpretation that example 5 above may not be considered a ‘private message’, even
if the message was limited to a small audience, and clarity around this is needed.

Communications in video game worlds, servers and lobbies as described in example 5 above
differ from general online public communications in the following significant ways:

   - These environments have limited capacity (often limited to 100 players or fewer)
because they exist to primarily facilitate gameplay, not mass communication. They are
‘public’ only in the sense that theoretically any game player can be added to them.

   - They are often temporary environments that may only last for as long as a particular
game lasts (eg. 5 to 30 minutes). This is in stark contrast to most other non-gaming
online forums, chatrooms or message boards, which can last for years.

   - They are closed loop communication environments so messages within them are not
viewable to end-users not within the particular world, server or lobby. This means that
members of the public cannot discover, browse or view these messages.

   - Messaging in these environments are almost always limited to text chat, unlike most
other non-gaming platforms and services, and always employ text filters, also unlike
most other non-game platforms and services. Even hyperlinks cannot be shared.

   - Messages within these environments are also typically transient, often lasting no
longer than a few seconds until they are replaced by other messages. This significantly
erodes the risks, impacts and harms of any potential misinformation or disinformation.

   - These environments are often not specifically accessible, meaning that players cannot
search for a particular environment. Instead, game players will be randomly allocated
to a world, server or lobby populated by other available players. This is in contrast to
most non-gaming digital environments that are easily found and attract communities.

It is our strong view that the kinds of online gaming environments with ancillary
communications capabilities described in this part of our submission should also be
considered ‘private messages’, or otherwise differentiated from the higher risk online
environments that the Draft Bill is targeted. We believe that their semi-private and low risk
nature make the risk of misinformation and disinformation on their platforms minimal.

_Recommendation 2_

_That the Draft Bill be amended so that messaging in small and temporary online environments_
_such as video game worlds, servers and lobbies also be considered private messages, or_
_otherwise treated as lower-risk content under the proposed new regulation._

**Definition of ‘digital platform services’**

A digital platform services is defined in subclause 4(1) of the Draft Bill as a digital service that
is:

_(a)_ _a content aggregation service (see subclause (2)); or_

_(b)_ _a connective media service (see subclause (3)); or_

_(c)_ _a media sharing service (see subclause (4)); or_

_(d)_ _a digital service specified by the Minister in an instrument under subclause (6);_


-----

_but does not include a digital service to the extent to which it is:_

_(e)_ _an internet carriage service; or_

_(f)_ _an SMS service; or_

_(g)_ _an MMS service._

This definition of ‘digital platform service’ is so broad that it essentially covers anything online,
regardless of whether they present any practical risk of misinformation or disinformation.
Specifically in relation to our industry, video game services, including those of which that may
have a limited or rudimentary communications functionality, are simply not a category of
service that raises, or will likely raise, community concerns around the creation, communication
and spread of misinformation and disinformation. We are not aware of video games being
used as a conduit for misinformation or disinformation and we simply see no evidence base
for these services being captured by the scope of the reforms.

A requirement for low-risk categories of digital services such as online video game services to
be immediately captured by the scope of the proposed reforms is likely to only complicate and
delay the development of online codes by adding participants and industry bodies that will
dilute the drafting and negotiation of codes between sectors that actually do present a risk of
misinformation or disinformation. Importantly, we note that should the Government ever
consider that one or more online video game services present a risk of misinformation or
disinformation, the Minister can use its powers to specify that a particular digital service - such
as a video game with a significant social communications functionality – should be considered
a digital platform service and thereby become covered by the scope of the Draft Bill.

_Recommendation 3_

_That subclause 4(1) of the Draft Bill be amended to include the specific exclusion of ‘an online_
_video game service’ from the definition of ‘digital platform service’, such as through the addition_
_of a new paragraph (h). An ‘online video game service’ could then be defined as a “service that_
_enables end-users to play online games with other end-users”, terminology already used by the_
_Online Safety Act 2021._

**Definition of ‘a connective media service’**

Under subclause 4(3) of the Draft Bill, a digital service is a ‘connective media service’ if it
satisfies the following criteria:

_(a)_ _a primary function of the digital service is to enable online interaction between 2 or more_
_end-users;_

_(b)_ _the digital service allows end-users to link to, or interact with, some or all of the other_
_end-users;_

_(c)_ _the digital service has an interactive feature; and_

_(d)_ _such other conditions (if any) as are set out in the digital platform rule._

Regarding the proposed definition of ‘connective media service’, we have concerns with
paragraphs 4(3)(a), (b) and (c) of the proposed definition, which we will explore in turn.


-----

The ‘primary function’ test

First, while we in-principle support the ‘primary function’ test at paragraph 4(3)(a), we believe
that it should be tightened to cover digital services that enable online communication, rather
than mere online interaction. For example, a video game where players can race each other in
virtual cars, but have no ability to share text, audio, images, files or other forms of
communication – and therefore present zero risk of misinformation or disinformation – would
fall potentially within the scope of paragraph (a) because the online competitive racing could
arguably be considered to constitute online interaction. On the other hand, a website that
enables users to purchase items from a shop but also allows them to write and share free text
product reviews (or any other text) would arguably not satisfy the primary function test – even
though it does present a risk of misinformation or disinformation – because the primary
function of the website is not online interaction between 2 or more end users.

_Recommendation 4_

_That the ‘primary function’ test at paragraph 4(3)(a) of the Draft Bill be amended so that it is_
_limited to online communication between 2 or more end-users, rather than online interaction._
_‘Communication’ should be clearly defined in the Draft Bill as meaning the sharing of content_
_(with ‘content’ have already been defined in the Draft Bill)._

Meaning of ‘link to, or interact with’

We believe that the inclusion of ‘link to, or interact with’ at paragraph (4)(3)(b) is unnecessarily
broad and vague. Similar to our views expressed above, it is not clear to us why this limb of the
definition cannot be limited to digital services that allows end-users to ‘communicate with, or
share information with’ other end-users, given that misinformation or disinformation cannot be
possible without communication. Under the current wording, paragraph (b) would be satisfied
by the same example as described above of a video game where end-users can race against
each other, even if there is no possibility for communication. This should similarly be rectified.

_Recommendation 5_

_That paragraph 4(3)(b) of the Draft Bill be amended so that it covers digital services that allow_
_end-users to ‘communicate with, or share information with’, other end-users, rather than ‘link to,_
_or interact with’._

The ‘interactive feature’ test and scope of ‘content’

Pursuant to paragraph (4)(3)(c), a ‘connective media service’ must have an interactive feature.
Under clause 5 of the Draft Bill, a digital service has an interactive feature if at least one of the
following applies:

_(a)_ _the digital service allows end-users to post content on the digital service;_

_(b)_ _the digital service provides a means for end-users to share, using the digital service,_
_content that is provided on the digital service with another end-user of the digital service;_

_(c)_ _the digital service makes:_

_i._ _interaction between end-users; or_

_ii._ _(ii) interaction by end-users with content provided on the digital service;_

_observable to other end-users._


-----

Further, ‘content’ is defined under clause 2 of the Draft Bill as content whether in the form of
text, data, speech, music or other sounds, visual images (animated or otherwise), any other
form or any combination of forms. This definition is extremely broad and raises a considerable
degree of uncertainty for the video games environment. For example, it would appear to us
that the definition of content would include circumstances where a player selects and posts a
generic pre-written game message (eg. “good luck!”) or an emote (eg. a ‘laughing face’),
thereby satisfying the ‘interactive feature’ requirement. Further, we believe that under the
current wording, ‘content’ could potentially even be satisfied by features in some games that
allow players to share in-game items with other players (eg. where a player finds a shield in a
game and gives it to another player). Clearly these examples offer no risk of misinformation or
disinformation and should be more explicitly excluded from the scope of the Draft Bill.

_Recommendation 6_

_That the Government consider whether the definition of ‘content’ at clause 2 of the Draft Bill is_
_impracticably broad and should be narrowed to only include forms of content that can carry_
_misinformation or disinformation._

Finally, we do not consider that it has been explicitly made clear enough that voice over IP
(VoIP) is out of the scope of the Draft Bill, even though it would be our expectation that this is
the case. There is a potential that the near-limitless scope of ‘content’ and the specific inclusion
of ‘speech’ could be interpreted to cover such services, which in our sector includes gaming
platforms that allow players to talk in real time with one another, even though we are confident
that the Government would not intend for these services to be in the scope of the Draft Bill.

_Recommendation 7_

_That the Government explicitly exclude VoIP from the definition of ‘content’ at clause 2 of the_
_Draft Bill._

**Definition of ‘media sharing service’**

Under subclause 4(4) of the Draft Bill, a digital service is a ‘media sharing service’ if “a primary
function of the digital service is to provide audio, audio-visual or moving visual content to endusers”. Under clause 6, a ‘media sharing device’ that does not have an interactive feature is an
excluded service for misinformation purposes. While it is our understanding that a ‘media
sharing device’ would include services that distribute video game content, such as digital game
distribution platforms or game streaming services, this is not without some uncertainty. For
example, while the Department’s fact sheet mentions that SVODs, BVODs and podcasting
services are not covered, there is no mention of analogous video game content services.

_Recommendation 8_

_That for the avoidance of doubt, the definition of ‘media sharing service’ in subclause 4(4) of the_
_Draft Bill be amended to also include ‘interactive content’. Alternatively, should the Government_
_consider that this may be confusing given the different use of ‘interactive’ elsewhere in the Draft_
_Bill, that the Explanatory Memorandum note that digital game distribution platforms and game_
_streaming services are intended to be covered by the definition._

**Exercise of ACMA powers**

The Draft Bill provides the ACMA with a wide range of powers to obtain information from
digital platform service providers for the purposes of record keeping and reporting (Division


-----

2) and information gathering (Division 3). We are concerned with the low threshold for the use
of these powers and the regulatory impact that this may have, particular for low risk services.

For example, for the ACMA to exercise its powers under clause 14 to make digital platform
rules in relation to records, the authority only needs to consider the privacy of end-users and
whether the rule is required for the performance of a range of functions under the Australian
_Communications 24 and Media Authority Act 2005 (subclause 2). This is a very low bar. For the_
ACMA to use its powers to obtain information and documents from digital platform providers
under clause 18, the authority need only believe that the digital platform provider has
information or can give evidence that is relevant to misinformation or disinformation on the
service, measures on the platform to prevent or respond to misinformation or disinformation
on the service, or the prevalence of content containing false, misleading or deceptive
information provided on the service (subclause 2). This is again a very baseline requirement.

Given how strong and intrusive these new ACMA powers are, we believe that it is reasonable
and appropriate for the authority to also have a reasonable belief that there is misinformation
or disinformation on the service before it can exercise its powers under Divisions 2 and 3.

_Recommendation 9_

_That the ACMA’s powers related to record keeping and reporting (Division 2) and information_
_gathering (Division 3) be amended so that they can only be exercised if the ACMA is satisfied,_
_to a reasonable extent, that there is misinformation or disinformation on a particular digital_
_platform, or that it is at serious risk of misinformation or disinformation._

**Statement of regulatory policy**

At clause 32, the Draft Bill provides a statement of regulatory policy, being that Parliament
intends that “one or more bodies or associations that the ACMA is satisfied represent sections
of the digital platform industry” should develop misinformation codes. It is important to note
that under clause 30 of the Draft Bill, a ‘section of the digital platform industry’ specifically
means:

_(a)_ _digital platform providers who provide content aggregation services;_

_(b)_ _digital platform providers who provide connective media services;_

_(c)_ _digital platform providers who provide media sharing services._

These sections are very broadly scoped, as particularly discussed, particularly the section of
connective media services. This is important as it is not clear whether the Government expects
that a section must entirely be covered by codes. For example, if a code already exists covering
social media services and online forums, would the ACMA consider that the section of
‘connective media services’ has been sufficiently covered as a section, given that the highest
risk platforms have been covered? Or would the ACMA interpret this statement of regulatory
policy to mean that the code should be expanded to cover all connective media services,
including to very low-risk subgroups within that section? These are questions that we would
appreciate clarity on, particularly given how broadly scoped the sections of digital platforms
industry are and how diverse their participants are in terms of the risks that they present.


-----

_Recommendation 10_

_That the Government provide further clarity around the statement of regulatory policy in terms_
_of how it applies to digital platforms or subgroups of digital platforms that present a_
_demonstrably low risk for misinformation and disinformation such as video game services._

**Sections of the digital platform industry**

Clause 37 deals with the registration of codes. Among other requirements, the ACMA must be
satisfied that a code has been developed by ‘a body or association representing a particular
section of the digital platform industry’ before it can be registered. Assuming that ‘section of
the digital platform industry’ continues to be defined by the meaning provided at clause 30
discussed above, a definition that is very broad and includes a variety of distinct subgroups of
platforms, this leads to several practical questions.

First, if a body or association only represents a subgroup of ‘connective media services’, for
instance, would the ACMA be satisfied that it represents that whole section if no other body
exists? Second, if multiple bodies or associations representing different subgroups of the
digital platform industry, would they need to agree on a single code, could multiple bodies cosponsor a code, and could multiple codes exist in relation to a section of the digital platform
industry (eg. with each code representing a different subgroup)?

While clarity on these above questions is critically needed, our primary recommendation for
this part of the Draft Bill is for it to be made absolutely clear that codes written by different
bodies and associations representing different subgroups of the digital platform industry can
be registered, not just the three sections as defined in clause 30.

We believe that this is a lesson directly learned from the Government’s Online Safety Industry
Codes process as set out in the Online Safety Act 2021. Under that piece of legislation, industry
codes were required to cover eight specific ‘sections’ of the online industry. Some of these
sections were very broad and unusual in scope, including the section called ‘Relevant
Electronic Services’ that among other things includes email, dating services, instant messaging
apps and online games, despite their significant differences from each other. While IGEA
sought to develop a code solely covering video games, the eSafety Commissioner, following
its reading of the Act, mandated that only a single code could be registered for each section.

The risk of such a requirement is that a single code faces the challenge of needing to be
molded to cover a voluminous and diverse range of participants, and most critically, creates a
situation where even if just one part of the code prevents the regulator from registering a code,
the entire code fails to be registered. This is exactly what occurred in the end with the Relevant
Electronic Services code because while the eSafety Commissioner was largely satisfied with
the elements of the code relating to gaming services, it identified deficiencies elsewhere in the
code which led to the result that the entire code has not been able to be registered, nullifying
the 18 months of work that industry put into the development of that code.

_Recommendation 11_

_That the Government clearly state in clause 37 the Draft Bill that multiple codes by bodies or_
_associations representing different subgroups within a section of a digital platform industry can_
_also be registered. Other similar amendments should also be made elsewhere in the Draft Bill,_
_such as around compliance by participants in a particular section of a digital platform industry_
_and ACMA’s power to determine standards covering sections of the digital platform industry._


-----

**ACMA’s power to request codes**

Under Clause 38 of the Draft Bill, the ACMA may request a body or association that it is satisfied
represents a particular section of the digital platform industry to develop a code covering
participants in that section. Under paragraph 38(3)(a), the ACMA must first be satisfied that the
development of the code is “necessary or convenient to prevent or respond to” or to “address
systemic issues” in relation to misinformation or disinformation on the digital platform services
of participants in that section of the digital platform industry. We understand that this power,
along with the power to make standards under Division 5, are considered reserve power to be
exercised only if required.

This power leads to several questions related to the issues we have raised above surrounding
how ‘section of the digital platform industry’ will be practically interpreted and applied by
ACMA. For example, if the authority were to identify ‘systemic issues’ regarding misinformation
or disinformation found on a small number of social media services, we are worried that the
ACMA would be able to request an industry code covering the whole category of connective
media service, which obviously extends well beyond those social media services. Even more
concerningly, the wording of this power could suggest that the ACMA must only request an
industry code covering the whole category of connective media services as defined in the Draft
Bill. This is obviously of great relevance to video game platforms, being a part of the connective
media service section that is generally of minimal risk of misinformation or disinformation.

The implementation of a far more targeted and risk-based exercise of the ACMA’s power to
request codes is a necessity. It will also ensure that the power can be more tactically exercised
in circumstances where the authority is satisfied that an existing industry code is adequate with
respect to a subgroup of a section of the digital platform industry but not another. In other
words, the clause 38 power should be able to be exercised to make industry codes severable.

_Recommendation 12_

_That clause 38 of the Draft Bill be amended to clarify that the ACMA may request codes covering_
_subgroups of a section of the digital platform industry. Paragraph 38(3)(a) should also be_
_amended so that before exercising its power to request codes, the ACMA must also consider_
_whether such a request would be unreasonably burdensome to all of the participants within the_
_relevant section._

### Broader industry concerns with the Draft Bills

**Support for DIGI’s submission**

As an association representing the video games sector, a distinct subgroup of digital services,
we have chosen to focus our submission on our specific concerns with the potential impact of
the Draft Bill on our sector. However, we are aware of broader industry concerns with the Draft
Bill and have engaged in close dialogue with our fellow industry associations that represent
other parts of the digital industry that may be more directly affected. This includes DIGI, which
we are aware has been closely involved in the policy discussion around misinformation and
disinformation for many years, and we have had the opportunity to review their submission.

We will therefore end our submission by conveying to the Department our general support for
DIGI’s submission and in particular, the thoughtful recommendations that they make
concerning the Draft Bill. Among others, we highlight the following concerns raised and
recommendations made by DIGI for the Draft Bill to be amended so that:


-----

  - It explicitly makes clear that the ACMA’s powers do not extend to regulating individual
instances of misinformation or disinformation.

  - The ACMA’s codes and standards-related powers be limited to disinformation and not
misinformation.

  - The definition of disinformation be more tightly drafted, noting that the scope of the
current proposal arguably extends to content that is not commonly considered to be
disinformation.

  - It include appropriate checks and balances, including that the ACMA’s powers be
exercised in a proportionate manner based on objective indicators of risk.

  - The maximum penalties under the Bill, which are excessive, be recalibrated.

_Recommendation 13_

_We recommend that the Government give full consideration to the recommendations made by_
_DIGI in its response to the present consultation._


-----

### Any questions?

**For more information on any issues raised in this submission, please contact IGEA’s**
**[Director of Policy & Government Affairs, Ben Au, at ben@igea.net](mailto:ben@igea.net)**

**[For more on IGEA and what we do, visit igea.net or follow us on Twitter below:](https://igea.net/)**

**[IGEA: @igea](https://twitter.com/igea)**

**[Game Connect Asia Pacific: @GCAPConf](https://twitter.com/GCAPConf)**

**[The Australian Game Developer Awards: @The_AGDAs](https://twitter.com/The_AGDAs)**


-----

